{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Yuygfgg's collection for vapoursynth video filtering and encoding stuff.</p>"},{"location":"API/utils/","title":"<code>y5gfunc.utils</code>","text":""},{"location":"API/utils/#y5gfunc.utils","title":"utils","text":"<p>Functions:</p> Name Description <code>ranger</code> <p>Generates a sequence of numbers similar to range(), but allows floats.</p> <code>PickFrames</code> <p>Return a new clip with frames picked from input clip from the indices array.</p> <code>resolve_path</code> <p>Resolves a path to an absolute path and ensures necessary directories exist.</p>"},{"location":"API/utils/#y5gfunc.utils.ranger","title":"ranger","text":"<pre><code>ranger(start: Union[int, float], end: Union[int, float], step: Union[int, float]) -&gt; List[Union[int, float]]\n</code></pre> <p>Generates a sequence of numbers similar to range(), but allows floats.</p> <p>Creates a list of numbers starting from <code>start</code>, incrementing by <code>step</code>, and stopping before <code>end</code>.</p> <p>Parameters:</p> Name Type Description Default <code>Union[int, float]</code> <p>The starting value of the sequence (inclusive).</p> required <code>Union[int, float]</code> <p>The end value of the sequence (exclusive). The sequence generated will contain values strictly  less than <code>end</code> if <code>step</code> is positive, or strictly greater than <code>end</code> if <code>step</code> is negative.</p> required <code>Union[int, float]</code> <p>The step/increment between consecutive numbers. Must not be zero. Can be negative for descending sequences.</p> required <p>Returns:</p> Type Description <code>List[Union[int, float]]</code> <p>A list of numbers (integers or floats) representing the generated sequence.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>step</code> is 0.</p> Source code in <code>y5gfunc/utils.py</code> <pre><code>def ranger(start: Union[int, float], end: Union[int, float], step: Union[int, float]) -&gt; List[Union[int, float]]:\n    \"\"\"\n    Generates a sequence of numbers similar to range(), but allows floats.\n\n    Creates a list of numbers starting from `start`, incrementing by `step`, and stopping before `end`.\n\n    Args:\n        start: The starting value of the sequence (inclusive).\n        end: The end value of the sequence (exclusive). The sequence generated will contain values strictly \n            less than `end` if `step` is positive, or strictly greater than `end` if `step` is negative.\n        step: The step/increment between consecutive numbers. Must not be zero. Can be negative for descending sequences.\n\n    Returns:\n        A list of numbers (integers or floats) representing the generated sequence.\n\n    Raises:\n        ValueError: If `step` is 0.\n    \"\"\"\n\n    if step == 0:\n        raise ValueError(\"ranger: Step cannot be zero.\")\n    return list(map(lambda i: round(start + i * step, 10), range(int((end - start) / step))))\n</code></pre>"},{"location":"API/utils/#y5gfunc.utils.ranger(start)","title":"<code>start</code>","text":""},{"location":"API/utils/#y5gfunc.utils.ranger(end)","title":"<code>end</code>","text":""},{"location":"API/utils/#y5gfunc.utils.ranger(step)","title":"<code>step</code>","text":""},{"location":"API/utils/#y5gfunc.utils.PickFrames","title":"PickFrames","text":"<pre><code>PickFrames(clip: VideoNode, indices: list[int]) -&gt; VideoNode\n</code></pre> <p>Return a new clip with frames picked from input clip from the indices array.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input clip where frames are from.</p> required <code>list[int]</code> <p>The indices array representing the frames to be picked.</p> required <p>Returns:</p> Type Description <code>VideoNode</code> <p>New clip with frames picked from input clip from the indices array.</p> Source code in <code>y5gfunc/utils.py</code> <pre><code>def PickFrames(clip: vs.VideoNode, indices: list[int]) -&gt; vs.VideoNode:\n    \"\"\"\n    Return a new clip with frames picked from input clip from the indices array.\n\n    Args:\n        clip: Input clip where frames are from.\n        indices: The indices array representing the frames to be picked.\n\n    Returns:\n        New clip with frames picked from input clip from the indices array.\n    \"\"\"    \n    return clip.std.SelectEvery(cycle=clip.num_frames, offsets=indices)\n</code></pre>"},{"location":"API/utils/#y5gfunc.utils.PickFrames(clip)","title":"<code>clip</code>","text":""},{"location":"API/utils/#y5gfunc.utils.PickFrames(indices)","title":"<code>indices</code>","text":""},{"location":"API/utils/#y5gfunc.utils.resolve_path","title":"resolve_path","text":"<pre><code>resolve_path(path: Union[Path, str]) -&gt; Path\n</code></pre> <p>Resolves a path to an absolute path and ensures necessary directories exist.</p> <p>Parameters:</p> Name Type Description Default <code>Union[Path, str]</code> <p>The input path string or Path object to resolve and for which to ensure directory structure exists.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>The absolute, resolved pathlib. Path object corresponding to the input path, after ensuring the relevant directory structure exists.</p> Source code in <code>y5gfunc/utils.py</code> <pre><code>def resolve_path(path: Union[Path, str]) -&gt; Path:\n    \"\"\"\n    Resolves a path to an absolute path and ensures necessary directories exist.\n\n    Args:\n        path: The input path string or Path object to resolve and for which to ensure directory structure exists.\n\n    Returns:\n        The absolute, resolved pathlib. Path object corresponding to the input path, after ensuring the relevant directory structure exists.\n    \"\"\"\n    path = Path(path).resolve()\n    if path.suffix:\n        path.parent.mkdir(parents=True, exist_ok=True)\n    else:\n        path.mkdir(parents=True, exist_ok=True)\n    return path\n</code></pre>"},{"location":"API/utils/#y5gfunc.utils.resolve_path(path)","title":"<code>path</code>","text":""},{"location":"API/encode/chapter/","title":"<code>y5gfunc.encode.chapter</code>","text":""},{"location":"API/encode/chapter/#y5gfunc.encode.chapter","title":"chapter","text":"<p>Functions:</p> Name Description <code>get_bd_chapter</code> <p>Extracts chapters from a Blu-ray MPLS or M2TS file to an OGM chapter file.</p> <code>get_mkv_chapter</code> <p>Extracts chapters from an MKV file using mkvextract to an OGM chapter file.</p>"},{"location":"API/encode/chapter/#y5gfunc.encode.chapter.get_bd_chapter","title":"get_bd_chapter","text":"<pre><code>get_bd_chapter(m2ts_or_mpls_path: Union[str, Path], chapter_save_path: Union[str, Path], target_clip: Optional[str] = None, all: bool = False) -&gt; Path\n</code></pre> <p>Extracts chapters from a Blu-ray MPLS or M2TS file to an OGM chapter file.</p> <p>If an M2TS path is provided, it searches the corresponding BDMV structure for the MPLS file containing that M2TS clip.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, Path]</code> <p>Path to the input M2TS or MPLS file.</p> required <code>Union[str, Path]</code> <p>Path to save the output OGM chapter file.</p> required <code>Optional[str]</code> <p>The 5-digit clip name (e.g., \"00001\") if input is MPLS and <code>all</code> is False. Auto-detected if input is M2TS.</p> <code>None</code> <code>bool</code> <p>If True, extract all chapter marks from the relevant MPLS. If False, extract chapters relative to the target_clip's start time.</p> <code>False</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved OGM chapter file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If input path or required BDMV structure doesn't exist.</p> <code>ValueError</code> <p>If input is invalid (e.g., MPLS without target_clip/all=True, or no chapters found).</p> <code>RuntimeError</code> <p>On errors during MPLS parsing.</p> <code>IOError</code> <p>On failure to write the chapter file.</p> Source code in <code>y5gfunc/encode/chapter.py</code> <pre><code>def get_bd_chapter(\n    m2ts_or_mpls_path: Union[str, Path],\n    chapter_save_path: Union[str, Path],\n    target_clip: Optional[str] = None,\n    all: bool = False,  # True: return all mpls marks; False: return chapter\n) -&gt; Path:\n    \"\"\"\n    Extracts chapters from a Blu-ray MPLS or M2TS file to an OGM chapter file.\n\n    If an M2TS path is provided, it searches the corresponding BDMV structure for the MPLS file containing that M2TS clip.\n\n    Args:\n        m2ts_or_mpls_path: Path to the input M2TS or MPLS file.\n        chapter_save_path: Path to save the output OGM chapter file.\n        target_clip: The 5-digit clip name (e.g., \"00001\") if input is MPLS and `all` is False. Auto-detected if input is M2TS.\n        all: If True, extract all chapter marks from the relevant MPLS. If False, extract chapters relative to the target_clip's start time.\n\n    Returns:\n        Path to the saved OGM chapter file.\n\n    Raises:\n        FileNotFoundError: If input path or required BDMV structure doesn't exist.\n        ValueError: If input is invalid (e.g., MPLS without target_clip/all=True, or no chapters found).\n        RuntimeError: On errors during MPLS parsing.\n        IOError: On failure to write the chapter file.\n    \"\"\"\n\n    m2ts_or_mpls_path = resolve_path(m2ts_or_mpls_path)\n    chapter_save_path = resolve_path(chapter_save_path)\n\n    def _format_timestamp(seconds: float) -&gt; str:\n        hours = int(seconds // 3600)\n        minutes = int((seconds % 3600) // 60)\n        seconds_remainder = seconds % 60\n        whole_seconds = int(seconds_remainder)\n        milliseconds = int((seconds_remainder - whole_seconds) * 1000)\n        return f\"{hours:02d}:{minutes:02d}:{whole_seconds:02d}.{milliseconds:03d}\"\n\n    def _process_mpls(\n        mpls_path: Path, target_clip: Optional[str] = None\n    ) -&gt; Optional[list[float]]:\n        try:\n            with mpls_path.open(\"rb\") as f:\n                if f.read(4) != b\"MPLS\":\n                    raise ValueError(\n                        f\"get_bd_chapter: Invalid MPLS format in file: {mpls_path}\"\n                    )\n\n                f.seek(0)\n                header: dict[str, Any] = {}\n                header[\"TypeIndicator\"] = f.read(4)\n                header[\"VersionNumber\"] = f.read(4)\n                (header[\"PlayListStartAddress\"],) = struct.unpack(\"&gt;I\", f.read(4))\n                (header[\"PlayListMarkStartAddress\"],) = struct.unpack(\"&gt;I\", f.read(4))\n                (header[\"ExtensionDataStartAddress\"],) = struct.unpack(\"&gt;I\", f.read(4))\n\n                f.seek(header[\"PlayListStartAddress\"])\n                (playlist_length,) = struct.unpack(\"&gt;I\", f.read(4))\n                f.read(2)  # reserved\n                (num_items,) = struct.unpack(\"&gt;H\", f.read(2))\n                (num_subpaths,) = struct.unpack(\"&gt;H\", f.read(2))\n\n                play_items = []\n                target_item_index = None\n                for i in range(num_items):\n                    (item_length,) = struct.unpack(\"&gt;H\", f.read(2))\n                    item_start = f.tell()\n\n                    clip_name = f.read(5).decode(\"utf-8\", errors=\"ignore\")\n                    codec_id = f.read(4).decode(\"utf-8\", errors=\"ignore\")  # noqa: F841\n\n                    f.read(3)  # reserved\n                    stc_id = f.read(1)  # noqa: F841\n                    (in_time,) = struct.unpack(\"&gt;I\", f.read(4))\n                    (out_time,) = struct.unpack(\"&gt;I\", f.read(4))\n\n                    if target_clip and clip_name == target_clip:\n                        target_item_index = i\n\n                    play_items.append(\n                        {\n                            \"clip_name\": clip_name,\n                            \"in_time\": in_time,\n                            \"out_time\": out_time,\n                        }\n                    )\n\n                    f.seek(item_start + item_length)\n\n                if target_clip and target_item_index is None:\n                    return None\n\n                f.seek(header[\"PlayListMarkStartAddress\"])\n                (marks_length,) = struct.unpack(\"&gt;I\", f.read(4))\n                (num_marks,) = struct.unpack(\"&gt;H\", f.read(2))\n\n                chapters_by_item = {}\n                for _ in range(num_marks):\n                    f.read(1)  # reserved\n                    (mark_type,) = struct.unpack(\"&gt;B\", f.read(1))\n                    (ref_play_item_id,) = struct.unpack(\"&gt;H\", f.read(2))\n                    (mark_timestamp,) = struct.unpack(\"&gt;I\", f.read(4))\n                    (entry_es_pid,) = struct.unpack(\"&gt;H\", f.read(2))\n                    (duration,) = struct.unpack(\"&gt;I\", f.read(4))\n\n                    if mark_type == 1:\n                        if ref_play_item_id not in chapters_by_item:\n                            chapters_by_item[ref_play_item_id] = []\n                        chapters_by_item[ref_play_item_id].append(mark_timestamp)\n\n                result = []\n                if target_clip:\n                    if target_item_index in chapters_by_item:\n                        marks = chapters_by_item[target_item_index]\n                        offset = min(marks)\n                        if play_items[target_item_index][\"in_time\"] &lt; offset:  # type: ignore\n                            offset = play_items[target_item_index][\"in_time\"]  # type: ignore\n\n                        for timestamp in marks:\n                            relative_time = (timestamp - offset) / 45000.0\n                            if relative_time &gt;= 0:\n                                result.append(relative_time)\n                else:\n                    for item_id, marks in chapters_by_item.items():\n                        offset = min(marks)\n                        if play_items[item_id][\"in_time\"] &lt; offset:\n                            offset = play_items[item_id][\"in_time\"]\n\n                        for timestamp in marks:\n                            relative_time = (timestamp - offset) / 45000.0\n                            if relative_time &gt;= 0:\n                                result.append(relative_time)\n\n                return sorted(result)\n\n        except ValueError:\n            raise\n        except Exception as e:\n            raise RuntimeError(f\"get_bd_chapter: Error processing MPLS file: {str(e)}\")\n\n    if not m2ts_or_mpls_path.exists():\n        raise FileNotFoundError(\n            f\"get_bd_chapter: Path does not exist: {m2ts_or_mpls_path}\"\n        )\n\n    is_mpls = m2ts_or_mpls_path.suffix.lower() == \".mpls\"\n\n    if is_mpls:\n        if not target_clip and not all:\n            raise ValueError(\n                \"get_bd_chapter: target_clip must be provided with MPLS input if all is False!\"\n            )\n        chapters = (\n            _process_mpls(m2ts_or_mpls_path, target_clip)\n            if not all\n            else _process_mpls(m2ts_or_mpls_path)\n        )\n    else:\n        bdmv_root = next(\n            (p.parent for p in m2ts_or_mpls_path.parents if p.name.upper() == \"BDMV\"),\n            None,\n        )\n        if not bdmv_root:\n            raise FileNotFoundError(\n                \"get_bd_chapter: Could not find BDMV directory in path hierarchy\"\n            )\n\n        target_clip = m2ts_or_mpls_path.stem\n        mpls_dir = bdmv_root / \"BDMV\" / \"PLAYLIST\"\n\n        if not mpls_dir.exists():\n            raise FileNotFoundError(f\"PLAYLIST directory not found: {mpls_dir}\")\n\n        chapters = None\n        for mpls_file in mpls_dir.glob(\"*.mpls\"):\n            try:\n                chapters = _process_mpls(mpls_file, target_clip=target_clip)\n                if chapters:\n                    if all:\n                        chapters = _process_mpls(mpls_file)\n                    break\n            except (ValueError, RuntimeError):\n                continue\n\n    if not chapters:\n        raise ValueError(\"get_bd_chapter: No chapters found in the Blu-ray disc\")\n\n    try:\n        with chapter_save_path.open(\"w\", encoding=\"utf-8\") as f:\n            for i, time in enumerate(chapters, 1):\n                chapter_num = f\"{i:02d}\"\n                timestamp = _format_timestamp(time)\n                f.write(f\"CHAPTER{chapter_num}={timestamp}\\n\")\n                f.write(f\"CHAPTER{chapter_num}NAME=Chapter {i}\\n\")\n    except IOError as e:\n        raise IOError(f\"get_bd_chapter: Failed to write chapter file: {str(e)}\")\n\n    return chapter_save_path\n</code></pre>"},{"location":"API/encode/chapter/#y5gfunc.encode.chapter.get_bd_chapter(m2ts_or_mpls_path)","title":"<code>m2ts_or_mpls_path</code>","text":""},{"location":"API/encode/chapter/#y5gfunc.encode.chapter.get_bd_chapter(chapter_save_path)","title":"<code>chapter_save_path</code>","text":""},{"location":"API/encode/chapter/#y5gfunc.encode.chapter.get_bd_chapter(target_clip)","title":"<code>target_clip</code>","text":""},{"location":"API/encode/chapter/#y5gfunc.encode.chapter.get_bd_chapter(all)","title":"<code>all</code>","text":""},{"location":"API/encode/chapter/#y5gfunc.encode.chapter.get_mkv_chapter","title":"get_mkv_chapter","text":"<pre><code>get_mkv_chapter(mkv_path: Union[str, Path], output_path: Union[str, Path]) -&gt; Path\n</code></pre> <p>Extracts chapters from an MKV file using mkvextract to an OGM chapter file.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, Path]</code> <p>Path to the input MKV file.</p> required <code>Union[str, Path]</code> <p>Path to save the output OGM chapter file.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved OGM chapter file.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If mkvextract fails to extract chapters.</p> <code>IOError</code> <p>On failure to write the chapter file.</p> Source code in <code>y5gfunc/encode/chapter.py</code> <pre><code>def get_mkv_chapter(mkv_path: Union[str, Path], output_path: Union[str, Path]) -&gt; Path:\n    \"\"\"\n    Extracts chapters from an MKV file using mkvextract to an OGM chapter file.\n\n    Args:\n        mkv_path: Path to the input MKV file.\n        output_path: Path to save the output OGM chapter file.\n\n    Returns:\n        Path to the saved OGM chapter file.\n\n    Raises:\n        RuntimeError: If mkvextract fails to extract chapters.\n        IOError: On failure to write the chapter file.\n    \"\"\"\n    mkv_path = resolve_path(mkv_path)\n    output_path = resolve_path(output_path)\n\n    try:\n        result = subprocess.run(\n            [\"mkvextract\", \"chapters\", str(mkv_path), \"-s\"],\n            capture_output=True,\n            text=True,\n            check=True,\n            encoding=\"utf-8\",\n        )\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(\n            f\"get_mkv_chapter: Error extracting chapters from '{mkv_path}': {e.stderr.strip()}\"\n        )\n\n    chapter_data = result.stdout\n\n    try:\n        output_path.write_text(chapter_data, encoding=\"utf-8\")\n    except IOError as e:\n        raise IOError(\n            f\"get_mkv_chapter: Failed to write chapter file '{output_path}': {str(e)}\"\n        )\n\n    return output_path\n</code></pre>"},{"location":"API/encode/chapter/#y5gfunc.encode.chapter.get_mkv_chapter(mkv_path)","title":"<code>mkv_path</code>","text":""},{"location":"API/encode/chapter/#y5gfunc.encode.chapter.get_mkv_chapter(output_path)","title":"<code>output_path</code>","text":""},{"location":"API/encode/mux/","title":"<code>y5gfunc.encode.mux</code>","text":""},{"location":"API/encode/mux/#y5gfunc.encode.mux","title":"mux","text":"<p>Functions:</p> Name Description <code>mux_mkv</code> <p>Muxes video, audio, subtitle tracks, chapters, and fonts into an MKV file.</p>"},{"location":"API/encode/mux/#y5gfunc.encode.mux.mux_mkv","title":"mux_mkv","text":"<pre><code>mux_mkv(output_path: Union[str, Path], videos: Optional[Union[list[dict[str, Union[str, Path, bool]]], dict[str, Union[str, Path, bool]]]] = None, audios: Optional[Union[list[dict[str, Union[str, Path, bool]]], dict[str, Union[str, Path, bool]]]] = None, subtitles: Optional[Union[list[dict[str, Union[str, Path, bool]]], dict[str, Union[str, Path, bool]]]] = None, fonts_dir: Optional[Union[str, Path]] = None, chapters: Optional[Union[str, Path]] = None) -&gt; Path\n</code></pre> <p>Muxes video, audio, subtitle tracks, chapters, and fonts into an MKV file.</p> <p>Uses mkvmerge for muxing tracks and chapters, and mkvpropedit for attaching fonts.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, Path]</code> <p>Path for the output MKV file.</p> required <code>Optional[Union[list[dict[str, Union[str, Path, bool]]], dict[str, Union[str, Path, bool]]]]</code> <p>Video track(s). Can be a single dict or a list of dicts.</p> <code>None</code> <code>Optional[Union[list[dict[str, Union[str, Path, bool]]], dict[str, Union[str, Path, bool]]]]</code> <p>Audio track(s). Can be a single dict or a list of dicts.</p> <code>None</code> <code>Optional[Union[list[dict[str, Union[str, Path, bool]]], dict[str, Union[str, Path, bool]]]]</code> <p>Subtitle track(s). Can be a single dict or a list of dicts.</p> <code>None</code> <code>Optional[Union[str, Path]]</code> <p>Optional directory containing TTF/OTF fonts to attach.</p> <code>None</code> <code>Optional[Union[str, Path]]</code> <p>Optional path to an OGM chapter file.</p> <code>None</code> Note <p>Track dictionary structure: <pre><code>    {\n        \"path\": str | Path,       # Path to the track file (Required)\n        \"language\": str,          # Language code\n        \"track_name\": str,        # Name for the track\n        \"default\": bool,          # True to set the default flag\n        \"comment\": bool,          # True to set the commentary flag\n        \"timecode\": str | Path    # Path to a timecode file\n    }\n</code></pre>     The first track of each type (video, audio, subtitle) will be marked as default unless explicitly set otherwise via the \"default\" key.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the created MKV file.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no video, audio, subtitle, chapter, or font inputs are provided.</p> <code>FileNotFoundError</code> <p>If an input file (track, chapter) is not found.</p> <code>RuntimeError</code> <p>If mkvmerge or mkvpropedit encounters an error during execution.</p> Source code in <code>y5gfunc/encode/mux.py</code> <pre><code>def mux_mkv(\n    output_path: Union[str, Path],\n    videos: Optional[\n        Union[\n            list[dict[str, Union[str, Path, bool]]], dict[str, Union[str, Path, bool]]\n        ]\n    ] = None,\n    audios: Optional[\n        Union[\n            list[dict[str, Union[str, Path, bool]]], dict[str, Union[str, Path, bool]]\n        ]\n    ] = None,\n    subtitles: Optional[\n        Union[\n            list[dict[str, Union[str, Path, bool]]], dict[str, Union[str, Path, bool]]\n        ]\n    ] = None,\n    fonts_dir: Optional[Union[str, Path]] = None,\n    chapters: Optional[Union[str, Path]] = None,\n) -&gt; Path:\n    \"\"\"\n    Muxes video, audio, subtitle tracks, chapters, and fonts into an MKV file.\n\n    Uses mkvmerge for muxing tracks and chapters, and mkvpropedit for attaching fonts.\n\n    Args:\n        output_path: Path for the output MKV file.\n        videos: Video track(s). Can be a single dict or a list of dicts.\n        audios: Audio track(s). Can be a single dict or a list of dicts.\n        subtitles: Subtitle track(s). Can be a single dict or a list of dicts.\n        fonts_dir: Optional directory containing TTF/OTF fonts to attach.\n        chapters: Optional path to an OGM chapter file.\n\n    Note:\n        Track dictionary structure:\n        ```python\n            {\n                \"path\": str | Path,       # Path to the track file (Required)\n                \"language\": str,          # Language code\n                \"track_name\": str,        # Name for the track\n                \"default\": bool,          # True to set the default flag\n                \"comment\": bool,          # True to set the commentary flag\n                \"timecode\": str | Path    # Path to a timecode file\n            }\n        ```\n            The first track of each type (video, audio, subtitle) will be marked as default unless explicitly set otherwise via the \"default\" key.\n\n    Returns:\n        Path to the created MKV file.\n\n    Raises:\n        ValueError: If no video, audio, subtitle, chapter, or font inputs are provided.\n        FileNotFoundError: If an input file (track, chapter) is not found.\n        RuntimeError: If mkvmerge or mkvpropedit encounters an error during execution.\n    \"\"\"\n    output_path = resolve_path(output_path)\n    if fonts_dir:\n        fonts_dir = resolve_path(fonts_dir)\n    if chapters:\n        chapters = resolve_path(chapters)\n\n    if not any((videos, audios, subtitles, chapters, fonts_dir)):\n        raise ValueError(\n            \"mux_mkv: At least one input (videos, audios, subtitles, chapters, fonts_dir) must be provided.\"\n        )\n\n    def _normalize_inputs(inputs):\n        if isinstance(inputs, dict):\n            return [inputs]\n        return inputs or []\n\n    videos = _normalize_inputs(videos)\n    audios = _normalize_inputs(audios)\n    subtitles = _normalize_inputs(subtitles)\n\n    for track_list in (videos, audios, subtitles):\n        for track in track_list:\n            track[\"path\"] = resolve_path(track[\"path\"])  # type: ignore\n\n    all_files = [track[\"path\"] for track in videos + audios + subtitles] + (\n        [chapters] if chapters else []\n    )\n    for file in all_files:\n        if not file.exists():  # type: ignore\n            raise FileNotFoundError(f\"mux_mkv: Required file not found: {file}\")\n\n    mkvmerge_cmd = [\"mkvmerge\", \"-o\", str(output_path)]\n\n    def _process_tracks(tracks) -&gt; None:\n        first_default_set = False\n        for i, track in enumerate(tracks):\n            if \"language\" in track:\n                mkvmerge_cmd.extend([\"--language\", f\"0:{track['language']}\"])\n            if \"track_name\" in track:\n                mkvmerge_cmd.extend([\"--track-name\", f\"0:{track['track_name']}\"])\n            if \"comment\" in track:\n                mkvmerge_cmd.extend([\"--commentary-flag\", \"0:yes\"])\n            if \"timecode\" in track:\n                mkvmerge_cmd.extend([\"--timestamps\", f\"0:{str(track['timecode'])}\"])\n\n            if track.get(\"default\") is True:\n                mkvmerge_cmd.extend([\"--default-track\", \"0:yes\"])\n                first_default_set = True\n            elif track.get(\"default\") is False:\n                mkvmerge_cmd.extend([\"--default-track\", \"0:no\"])\n            elif not first_default_set and i == 0:\n                mkvmerge_cmd.extend([\"--default-track\", \"0:yes\"])\n                first_default_set = True\n            else:\n                mkvmerge_cmd.extend([\"--default-track\", \"0:no\"])\n\n            mkvmerge_cmd.append(str(track[\"path\"]))\n\n    _process_tracks(videos)\n    _process_tracks(audios)\n    _process_tracks(subtitles)\n\n    if chapters:\n        mkvmerge_cmd.extend([\"--chapters\", str(chapters)])\n\n    result = subprocess.run(mkvmerge_cmd, capture_output=True, text=True)\n    if result.returncode != 0:\n        raise RuntimeError(f\"mux_mkv: Error executing mkvmerge:\\n{result.stdout}\")\n\n    if fonts_dir and fonts_dir.exists():\n        for font_ext in [\"ttf\", \"otf\"]:\n            for font_file in fonts_dir.glob(f\"*.{font_ext}\"):\n                font_cmd = [\n                    \"mkvpropedit\",\n                    str(output_path),\n                    \"--attachment-mime-type\",\n                    f\"font/{font_ext}\",\n                    \"--add-attachment\",\n                    str(font_file),\n                ]\n                font_result = subprocess.run(font_cmd, capture_output=True, text=True)\n                if font_result.returncode != 0:\n                    raise RuntimeError(\n                        f\"mux_mkv: Error adding font {font_file}:\\n{font_result.stderr}\"\n                    )\n\n    return output_path\n</code></pre>"},{"location":"API/encode/mux/#y5gfunc.encode.mux.mux_mkv(output_path)","title":"<code>output_path</code>","text":""},{"location":"API/encode/mux/#y5gfunc.encode.mux.mux_mkv(videos)","title":"<code>videos</code>","text":""},{"location":"API/encode/mux/#y5gfunc.encode.mux.mux_mkv(audios)","title":"<code>audios</code>","text":""},{"location":"API/encode/mux/#y5gfunc.encode.mux.mux_mkv(subtitles)","title":"<code>subtitles</code>","text":""},{"location":"API/encode/mux/#y5gfunc.encode.mux.mux_mkv(fonts_dir)","title":"<code>fonts_dir</code>","text":""},{"location":"API/encode/mux/#y5gfunc.encode.mux.mux_mkv(chapters)","title":"<code>chapters</code>","text":""},{"location":"API/encode/qc/","title":"<code>y5gfunc.encode.qc</code>","text":""},{"location":"API/encode/qc/#y5gfunc.encode.qc","title":"qc","text":"<p>Classes:</p> Name Description <code>QcMode</code> <p>Which metrics to use for quality check</p> <code>ReturnType</code> <p>What to return after quality check</p> <p>Functions:</p> Name Description <code>encode_check</code> <p>Perform a quality check on an encoded video using SSIM and/or CAMBI metrics.</p>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.QcMode","title":"QcMode","text":"<p>               Bases: <code>StrEnum</code></p> <p>Which metrics to use for quality check</p> <p>Attributes:</p> Name Type Description <code>SSIM</code> <code>CAMBI</code> <code>BOTH</code>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.QcMode.SSIM","title":"SSIM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SSIM = 'SSIM'\n</code></pre>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.QcMode.CAMBI","title":"CAMBI  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CAMBI = 'CAMBI'\n</code></pre>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.QcMode.BOTH","title":"BOTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BOTH = 'BOTH'\n</code></pre>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.ReturnType","title":"ReturnType","text":"<p>               Bases: <code>StrEnum</code></p> <p>What to return after quality check</p> <p>Attributes:</p> Name Type Description <code>ENCODED</code> <p>Return the <code>encoded</code> clip with frame properties added (CAMBI, PlaneSSIM, *_err flags)</p> <code>ERROR</code> <p>Return a clip containing only the frames flagged as errors</p> <code>BOTH</code> <p>Return a tuple containing both the annotated <code>encoded</code> clip and the <code>error</code> clip.</p>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.ReturnType.ENCODED","title":"ENCODED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ENCODED = 'encoded'\n</code></pre>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.ReturnType.ERROR","title":"ERROR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ERROR = 'error'\n</code></pre>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.ReturnType.BOTH","title":"BOTH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BOTH = 'both'\n</code></pre>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.encode_check","title":"encode_check","text":"<pre><code>encode_check(encoded: VideoNode, source: Optional[VideoNode] = None, mode: QcMode = BOTH, threshold_cambi: float = 5, threshold_ssim: float = 0.9, return_type: ReturnType = ENCODED) -&gt; Union[VideoNode, tuple[VideoNode, VideoNode]]\n</code></pre> <p>Perform a quality check on an encoded video using SSIM and/or CAMBI metrics.</p> <p>This function compares the encoded video against optional source video (for SSIM) and calculates CAMBI scores. It identifies frames that fall below the SSIM threshold or exceed the CAMBI threshold, printing information about problematic frames to the console.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>The encoded video clip to check.</p> required <code>Optional[VideoNode]</code> <p>The source video clip for SSIM comparison. Required if mode includes SSIM. Must have the same format as <code>encoded</code>.</p> <code>None</code> <code>QcMode</code> <p>Which metrics to use.</p> <code>BOTH</code> <code>float</code> <p>The maximum allowed CAMBI score. Frames exceeding this are flagged. Must be between 0 and 24.</p> <code>5</code> <code>float</code> <p>The minimum allowed PlaneSSIM score. Frames below this are flagged. Must be between 0 and 1.</p> <code>0.9</code> <code>ReturnType</code> <p>What to return:</p> <code>ENCODED</code> <p>Returns:</p> Type Description <code>Union[VideoNode, tuple[VideoNode, VideoNode]]</code> <p>Depending on <code>return_type</code>, either the annotated encoded clip, a clip with only error frames, or a tuple containing both.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If input parameters are invalid.</p> Source code in <code>y5gfunc/encode/qc.py</code> <pre><code>def encode_check(\n    encoded: vs.VideoNode,\n    source: Optional[vs.VideoNode] = None,\n    mode: QcMode = QcMode.BOTH,\n    threshold_cambi: float = 5,\n    threshold_ssim: float = 0.9,\n    return_type: ReturnType = ReturnType.ENCODED,\n) -&gt; Union[vs.VideoNode, tuple[vs.VideoNode, vs.VideoNode]]:\n    \"\"\"\n    Perform a quality check on an encoded video using SSIM and/or CAMBI metrics.\n\n    This function compares the encoded video against optional source video (for SSIM) and calculates CAMBI scores. It identifies frames\n    that fall below the SSIM threshold or exceed the CAMBI threshold, printing information about problematic frames to the console.\n\n    Args:\n        encoded: The encoded video clip to check.\n        source: The source video clip for SSIM comparison. Required if mode includes SSIM. Must have the same format as `encoded`.\n        mode: Which metrics to use.\n        threshold_cambi: The maximum allowed CAMBI score. Frames exceeding this are flagged. Must be between 0 and 24.\n        threshold_ssim: The minimum allowed PlaneSSIM score. Frames below this are flagged. Must be between 0 and 1.\n        return_type: What to return:\n\n    Returns:\n        Depending on `return_type`, either the annotated encoded clip, a clip with only error frames, or a tuple containing both.\n\n    Raises:\n        AssertionError: If input parameters are invalid.\n    \"\"\"\n\n    assert 0 &lt;= threshold_cambi &lt;= 24\n    assert 0 &lt;= threshold_ssim &lt;= 1\n\n    if mode == QcMode.BOTH:\n        enable_ssim = enable_cambi = True\n    elif mode == QcMode.SSIM:\n        enable_ssim = True\n        enable_cambi = False\n    else:\n        enable_ssim = False\n        enable_cambi = True\n\n    if enable_ssim:\n        assert source\n        assert encoded.format.id == source.format.id\n        ssim = SSIM(encoded, source)\n\n    if enable_cambi:\n        cambi = core.cambi.Cambi(\n            encoded\n            if vstools.get_depth(encoded) &lt;= 10\n            else vstools.depth(encoded, 10, dither_type=\"none\"),\n            prop=\"CAMBI\",\n        )\n\n    error_frames = []\n\n    def _chk(n: int, f: list[vs.VideoFrame]) -&gt; vs.VideoFrame:\n        def print_red_bold(text) -&gt; None:\n            print(\"\\033[1;31m\" + text + \"\\033[0m\")\n\n        fout = f[0].copy()\n\n        ssim_err = cambi_err = False\n\n        if enable_ssim:\n            fout.props[\"PlaneSSIM\"] = ssim_val = f[2].props[\"PlaneSSIM\"]\n            fout.props[\"ssim_err\"] = ssim_err = (\n                1 if threshold_ssim &gt; f[2].props[\"PlaneSSIM\"] else 0  # type: ignore\n            )\n\n        if enable_cambi:\n            fout.props[\"CAMBI\"] = cambi_val = f[1].props[\"CAMBI\"]\n            fout.props[\"cambi_err\"] = cambi_err = (\n                1 if threshold_cambi &lt; f[1].props[\"CAMBI\"] else 0  # type: ignore\n            )\n\n        if cambi_err and enable_cambi:\n            print_red_bold(\n                f\"frame {n}: Banding detected! CAMBI: {cambi_val}\"\n                f\"    Note: banding threshold is {threshold_cambi}\"\n            )\n        if ssim_err and enable_ssim:\n            print_red_bold(\n                f\"frame {n}: Distortion detected! SSIM: {ssim_val}\"\n                f\"    Note: distortion threshold is {threshold_ssim}\"\n            )\n        if not (cambi_err or ssim_err):\n            print(f\"Frame {n}: OK!\")\n        else:\n            error_frames.append(n)\n\n        return fout\n\n    if enable_ssim and enable_cambi:\n        output = core.std.ModifyFrame(encoded, [encoded, cambi, ssim], _chk)\n    elif enable_cambi:\n        output = core.std.ModifyFrame(encoded, [encoded, cambi, cambi], _chk)\n    else:\n        output = core.std.ModifyFrame(encoded, [encoded, ssim, ssim], _chk)\n\n    if return_type == ReturnType.ENCODED:\n        return output\n\n    for _ in output.frames():\n        pass\n\n    err = PickFrames(encoded, error_frames)\n\n    if return_type == ReturnType.BOTH:\n        return output, err\n    else:\n        return err\n</code></pre>"},{"location":"API/encode/qc/#y5gfunc.encode.qc.encode_check(encoded)","title":"<code>encoded</code>","text":""},{"location":"API/encode/qc/#y5gfunc.encode.qc.encode_check(source)","title":"<code>source</code>","text":""},{"location":"API/encode/qc/#y5gfunc.encode.qc.encode_check(mode)","title":"<code>mode</code>","text":""},{"location":"API/encode/qc/#y5gfunc.encode.qc.encode_check(threshold_cambi)","title":"<code>threshold_cambi</code>","text":""},{"location":"API/encode/qc/#y5gfunc.encode.qc.encode_check(threshold_ssim)","title":"<code>threshold_ssim</code>","text":""},{"location":"API/encode/qc/#y5gfunc.encode.qc.encode_check(return_type)","title":"<code>return_type</code>","text":""},{"location":"API/encode/subtitle/","title":"<code>y5gfunc.encode.subtitle</code>","text":""},{"location":"API/encode/subtitle/#y5gfunc.encode.subtitle","title":"subtitle","text":"<p>Functions:</p> Name Description <code>subset_fonts</code> <p>Create a subset of fonts containing only the glyphs used by specified ASS files.</p> <code>extract_pgs_subtitles</code> <p>Extract all PGS (HDMV PGS) subtitle tracks from an M2TS file.</p>"},{"location":"API/encode/subtitle/#y5gfunc.encode.subtitle.subset_fonts","title":"subset_fonts","text":"<pre><code>subset_fonts(ass_path: Union[list[Union[str, Path]], str, Path], fonts_path: Union[str, Path], output_directory: Union[str, Path]) -&gt; Path\n</code></pre> <p>Create a subset of fonts containing only the glyphs used by specified ASS files.</p> <p>Parameters:</p> Name Type Description Default <code>Union[list[Union[str, Path]], str, Path]</code> <p>Path to a single ASS file or a list of paths to ASS files.</p> required <code>Union[str, Path]</code> <p>Path to the directory containing the original font files.</p> required <code>Union[str, Path]</code> <p>Path to the directory where the subsetted fonts will be saved. This directory will be created if it doesn't exist.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>The Path object representing the output directory.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the 'assfonts' command fails (returns a non-zero exit code).</p> Source code in <code>y5gfunc/encode/subtitle.py</code> <pre><code>def subset_fonts(\n    ass_path: Union[list[Union[str, Path]], str, Path],\n    fonts_path: Union[str, Path],\n    output_directory: Union[str, Path],\n) -&gt; Path:\n    \"\"\"\n    Create a subset of fonts containing only the glyphs used by specified ASS files.\n\n    Args:\n        ass_path: Path to a single ASS file or a list of paths to ASS files.\n        fonts_path: Path to the directory containing the original font files.\n        output_directory: Path to the directory where the subsetted fonts will be saved. This directory will be created if it doesn't exist.\n\n    Returns:\n        The Path object representing the output directory.\n\n    Raises:\n        RuntimeError: If the 'assfonts' command fails (returns a non-zero exit code).\n    \"\"\"\n    if isinstance(ass_path, (str, Path)):\n        ass_path = [ass_path]\n\n    ass_paths = [resolve_path(path) for path in ass_path]\n    fonts_path = resolve_path(fonts_path)\n    output_directory = resolve_path(output_directory)\n\n    subtitle_command = [\"assfonts\"]\n    for path in ass_paths:\n        subtitle_command += [\"-i\", str(path)]\n\n    subtitle_command += [\"-r\", \"-c\", \"-f\", str(fonts_path), \"-o\", str(output_directory)]\n\n    process = subprocess.run(subtitle_command, capture_output=True, text=True)\n    if process.returncode != 0:\n        raise RuntimeError(f\"subset_fonts: assfonts failed: {process.stderr}\")\n\n    return output_directory\n</code></pre>"},{"location":"API/encode/subtitle/#y5gfunc.encode.subtitle.subset_fonts(ass_path)","title":"<code>ass_path</code>","text":""},{"location":"API/encode/subtitle/#y5gfunc.encode.subtitle.subset_fonts(fonts_path)","title":"<code>fonts_path</code>","text":""},{"location":"API/encode/subtitle/#y5gfunc.encode.subtitle.subset_fonts(output_directory)","title":"<code>output_directory</code>","text":""},{"location":"API/encode/subtitle/#y5gfunc.encode.subtitle.extract_pgs_subtitles","title":"extract_pgs_subtitles","text":"<pre><code>extract_pgs_subtitles(m2ts_path: Union[str, Path], output_dir: Optional[Union[str, Path]] = None) -&gt; list[dict[str, Union[str, Path, bool]]]\n</code></pre> <p>Extract all PGS (HDMV PGS) subtitle tracks from an M2TS file.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, Path]</code> <p>Path to the input M2TS file.</p> required <code>Optional[Union[str, Path]]</code> <p>Optional path to the directory where extracted .sup files will be saved. If None, defaults to a subdirectory         'named '{m2ts_file_stem}_subs' next to the input M2TS file. The directory will be created if it doesn't exist.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, Union[str, Path, bool]]]</code> <p>A list of dictionaries, where each dictionary represents a successfully extracted pgs subtitle and contains keys suitable for use in muxing functions.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If ffprobe fails, if tsMuxeR fails, if no PGS subtitles are found, or if an expected demuxed subtitle file is not found after tsMuxeR runs.</p> Source code in <code>y5gfunc/encode/subtitle.py</code> <pre><code>def extract_pgs_subtitles(\n    m2ts_path: Union[str, Path], output_dir: Optional[Union[str, Path]] = None\n) -&gt; list[dict[str, Union[str, Path, bool]]]:\n    \"\"\"\n    Extract all PGS (HDMV PGS) subtitle tracks from an M2TS file.\n\n    Args:\n        m2ts_path: Path to the input M2TS file.\n        output_dir: Optional path to the directory where extracted .sup files will be saved. If None, defaults to a subdirectory\n                    'named '{m2ts_file_stem}_subs' next to the input M2TS file. The directory will be created if it doesn't exist.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a successfully extracted pgs subtitle and contains keys suitable for use in muxing functions.\n\n    Raises:\n        RuntimeError: If ffprobe fails, if tsMuxeR fails, if no PGS subtitles are found, or if an expected demuxed subtitle file is not found after tsMuxeR runs.\n    \"\"\"\n\n    m2ts_path = resolve_path(m2ts_path)\n\n    if output_dir is None:\n        output_dir = m2ts_path.parent / f\"{m2ts_path.stem}_subs\"\n\n    output_dir = resolve_path(output_dir)\n\n    print(f\"extract_pgs_subtitles: Analyzing {m2ts_path}...\")\n\n    cmd = [\n        \"ffprobe\",\n        \"-v\",\n        \"quiet\",\n        \"-print_format\",\n        \"json\",\n        \"-show_streams\",\n        str(m2ts_path),\n    ]\n    result = subprocess.run(cmd, capture_output=True, text=True)\n    if result.returncode != 0:\n        raise RuntimeError(f\"extract_pgs_subtitles: ffprobe failed: {result.stderr}\")\n\n    probe_data = json.loads(result.stdout)\n\n    pgs_streams = []\n    for stream in probe_data[\"streams\"]:\n        if not stream.get(\"id\"):\n            stream[\"id\"] = hex(int(stream.get(\"index\")) + 1)\n        if stream[\"codec_name\"] == \"hdmv_pgs_subtitle\":\n            stream_id = stream[\"id\"]\n            language = get_language_by_trackid(m2ts_path, stream_id)\n\n            pgs_streams.append(\n                {\n                    \"track_id\": int(stream_id, 16),\n                    \"language\": language or \"und\",\n                    \"default\": bool(stream[\"disposition\"][\"default\"]),\n                    \"type\": \"PGS\",\n                }\n            )\n\n    if not pgs_streams:\n        raise RuntimeError(\"extract_pgs_subtitles: No PGS subtitles found!\")\n\n    print(f\"Found {len(pgs_streams)} PGS subtitle streams:\")\n    for stream in pgs_streams:\n        default_str = \" (Default)\" if stream[\"default\"] else \"\"\n        print(f\"Track {stream['track_id']}: Language {stream['language']}{default_str}\")\n\n    with tempfile.TemporaryDirectory() as temp_dir:\n        temp_dir = resolve_path(temp_dir)\n        print(f\"extract_pgs_subtitles: Using temporary directory: {temp_dir}\")\n\n        meta_content = [\"MUXOPT --no-pcr-on-video-pid --new-audio-pes --demux\\n\"]\n        for stream in pgs_streams:\n            meta_line = f\"S_HDMV/PGS, \\\"{m2ts_path}\\\", track={stream['track_id']}\\n\"\n            meta_content.append(meta_line)\n            print(f\"extract_pgs_subtitles: Adding to meta: {meta_line.strip()}\")\n\n        meta_file = temp_dir / \"meta.txt\"\n        meta_file.write_text(\"\".join(meta_content))\n        print(f\"extract_pgs_subtitles: Created meta file at: {meta_file}\")\n\n        output_dir.mkdir(parents=True, exist_ok=True)\n        print(f\"extract_pgs_subtitles: Output directory: {output_dir}\")\n\n        print(\"\\nextract_pgs_subtitles: Running tsMuxeR...\")\n        cmd = [\"tsmuxer\", str(meta_file), str(temp_dir)]\n        print(f\"extract_pgs_subtitles: Command: {' '.join(cmd)}\")\n\n        process = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            bufsize=1,\n            universal_newlines=True,\n        )\n\n        while True:\n            output = process.stdout.readline()  # type: ignore\n            if output == \"\" and process.poll() is not None:\n                break\n            if output:\n                print(f\"extract_pgs_subtitles: tsMuxeR: {output.strip()}\")\n\n        stdout, stderr = process.communicate()\n        if stdout:\n            print(f\"extract_pgs_subtitles: tsMuxeR additional output: {stdout}\")\n        if stderr:\n            print(f\"extract_pgs_subtitles: tsMuxeR error output: {stderr}\")\n\n        if process.returncode != 0:\n            raise RuntimeError(\n                f\"extract_pgs_subtitles: tsMuxeR failed with return code {process.returncode}\"\n            )\n\n        print(\"\\nextract_pgs_subtitles: Extracting subtitles...\")\n\n        subtitles = []\n        for stream in pgs_streams:\n            track_num = stream[\"track_id\"]\n            try:\n                sup_file = next(temp_dir.glob(f\"*track_{track_num}.sup\"))\n\n                final_path = output_dir / f\"track_{track_num}_{stream['language']}.sup\"\n                shutil.move(str(sup_file), str(final_path))\n\n                default_str = \" (Default)\" if stream[\"default\"] else \"\"\n                print(\n                    f\"extract_pgs_subtitles: Extracted subtitle track {track_num} to {final_path}{default_str}\"\n                )\n\n                subtitles.append(\n                    {\n                        \"path\": final_path,\n                        \"language\": stream[\"language\"],\n                        \"default\": stream[\"default\"],\n                    }\n                )\n            except StopIteration:\n                raise RuntimeError(\n                    f\"extract_pgs_subtitles: Could not find extracted subtitle for track {track_num}\"\n                )\n\n    print(\"\\nextract_pgs_subtitles: Extraction completed!\")\n    return subtitles\n</code></pre>"},{"location":"API/encode/subtitle/#y5gfunc.encode.subtitle.extract_pgs_subtitles(m2ts_path)","title":"<code>m2ts_path</code>","text":""},{"location":"API/encode/subtitle/#y5gfunc.encode.subtitle.extract_pgs_subtitles(output_dir)","title":"<code>output_dir</code>","text":""},{"location":"API/encode/utils/","title":"<code>y5gfunc.encode.utils</code>","text":""},{"location":"API/encode/utils/#y5gfunc.encode.utils","title":"utils","text":"<p>Functions:</p> Name Description <code>get_language_by_trackid</code> <p>Get the language code for a specific track ID within an M2TS file.</p>"},{"location":"API/encode/utils/#y5gfunc.encode.utils.get_language_by_trackid","title":"get_language_by_trackid","text":"<pre><code>get_language_by_trackid(m2ts_path: Path, ffprobe_id: str) -&gt; str\n</code></pre> <p>Get the language code for a specific track ID within an M2TS file.</p> <p>Uses tsMuxeR to analyze the M2TS file and extract the language tag associated with the given track ID.</p> <p>Parameters:</p> Name Type Description Default <code>Path</code> <p>Path to the M2TS file.</p> required <code>str</code> <p>The track ID. Can be a hexadecimal string (e.g., '0x1011') or an integer representing the 0-based index from ffprobe.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The language code (e.g., \"eng\", \"jpn\") or \"und\" if not found or if tsMuxeR fails.</p> Source code in <code>y5gfunc/encode/utils.py</code> <pre><code>def get_language_by_trackid(m2ts_path: Path, ffprobe_id: str) -&gt; str:\n    \"\"\"\n    Get the language code for a specific track ID within an M2TS file.\n\n    Uses tsMuxeR to analyze the M2TS file and extract the language tag\n    associated with the given track ID.\n\n    Args:\n        m2ts_path: Path to the M2TS file.\n        ffprobe_id: The track ID. Can be a hexadecimal string (e.g., '0x1011') or an integer representing the 0-based index from ffprobe.\n\n    Returns:\n        The language code (e.g., \"eng\", \"jpn\") or \"und\" if not found or if tsMuxeR fails.\n    \"\"\"\n    if str(ffprobe_id).startswith(\"0x\"):\n        track_id = int(ffprobe_id, 16)\n    else:\n        track_id = int(ffprobe_id) + 1\n\n    try:\n        tsmuxer_output = subprocess.check_output([\"tsMuxeR\", str(m2ts_path)], text=True)\n    except subprocess.CalledProcessError:\n        return \"und\"\n\n    current_track = None\n    track_langs = {}\n\n    for line in tsmuxer_output.splitlines():\n        line = line.strip()\n\n        if line.startswith(\"Track ID:\"):\n            current_track = int(line.split(\":\")[1].strip())\n        elif line.startswith(\"Stream lang:\") and current_track is not None:\n            lang = line.split(\":\")[1].strip()\n            track_langs[current_track] = lang\n            current_track = None\n\n    return track_langs.get(track_id, \"und\") or \"und\"\n</code></pre>"},{"location":"API/encode/utils/#y5gfunc.encode.utils.get_language_by_trackid(m2ts_path)","title":"<code>m2ts_path</code>","text":""},{"location":"API/encode/utils/#y5gfunc.encode.utils.get_language_by_trackid(ffprobe_id)","title":"<code>ffprobe_id</code>","text":""},{"location":"API/encode/video/","title":"<code>y5gfunc.encode.video</code>","text":""},{"location":"API/encode/video/#y5gfunc.encode.video","title":"video","text":"<p>Functions:</p> Name Description <code>encode_video</code> <p>Encode one or multiple VapourSynth video nodes using external encoders or output directly to stdout.</p>"},{"location":"API/encode/video/#y5gfunc.encode.video.encode_video","title":"encode_video","text":"<pre><code>encode_video(clip: Union[VideoNode, list[Union[VideoNode, tuple[VideoNode, int]]]], encoder: Union[list[Popen], Popen, IO, None] = None, multi: bool = False) -&gt; None\n</code></pre> <p>Encode one or multiple VapourSynth video nodes using external encoders or output directly to stdout.</p> <p>Parameters:</p> Name Type Description Default <code>Union[VideoNode, list[Union[VideoNode, tuple[VideoNode, int]]]]</code> <p>A VapourSynth video node or a list of video nodes/tuples to encode.</p> required <code>Union[list[Popen], Popen, IO, None]</code> <p>External encoder process(es) created with subprocess.Popen, a file-like object, or None to output to stdout.</p> <code>None</code> <code>bool</code> <p>If True, handle multiple input clips and multiple encoders. If False, handle a single clip.</p> <code>False</code> <p>Examples:</p> <pre><code>```python\n\n# Output to an external encoder\nencoder = subprocess.Popen(['x264', '--demuxer', 'y4m', '-', '-o', 'output.mp4'], stdin=subprocess.PIPE)\nencode_video(clip, encoder)\n\n# Output directly to stdout (like vspipe)\nencode_video(clip, None)\n# or\nencode_video(clip, sys.stdout)\n\n# Output to a file\nwith open('output.y4m', 'wb') as f:\n    encode_video(clip, f)\n\n# Example with multiple encoders\nencoders = [\n    subprocess.Popen(['x264', '--demuxer', 'y4m', '-', '-o', 'output1.mp4'], stdin=subprocess.PIPE),\n    subprocess.Popen(['x264', '--demuxer', 'y4m', '-', '-o', 'output2.mp4'], stdin=subprocess.PIPE)\n]\nencode_video([clip1, clip2], encoders, multi=True)\n\n```\n</code></pre> Source code in <code>y5gfunc/encode/video.py</code> <pre><code>def encode_video(\n    clip: Union[vs.VideoNode, list[Union[vs.VideoNode, tuple[vs.VideoNode, int]]]],\n    encoder: Union[list[Popen], Popen, IO, None] = None,\n    multi: bool = False,\n) -&gt; None:\n    \"\"\"\n    Encode one or multiple VapourSynth video nodes using external encoders or output directly to stdout.\n\n    Args:\n        clip: A VapourSynth video node or a list of video nodes/tuples to encode.\n        encoder: External encoder process(es) created with subprocess.Popen, a file-like object, or None to output to stdout.\n        multi: If True, handle multiple input clips and multiple encoders. If False, handle a single clip.\n\n    Examples:\n\n        ```python\n\n        # Output to an external encoder\n        encoder = subprocess.Popen(['x264', '--demuxer', 'y4m', '-', '-o', 'output.mp4'], stdin=subprocess.PIPE)\n        encode_video(clip, encoder)\n\n        # Output directly to stdout (like vspipe)\n        encode_video(clip, None)\n        # or\n        encode_video(clip, sys.stdout)\n\n        # Output to a file\n        with open('output.y4m', 'wb') as f:\n            encode_video(clip, f)\n\n        # Example with multiple encoders\n        encoders = [\n            subprocess.Popen(['x264', '--demuxer', 'y4m', '-', '-o', 'output1.mp4'], stdin=subprocess.PIPE),\n            subprocess.Popen(['x264', '--demuxer', 'y4m', '-', '-o', 'output2.mp4'], stdin=subprocess.PIPE)\n        ]\n        encode_video([clip1, clip2], encoders, multi=True)\n\n        ```\n    \"\"\"\n\n    if not multi:\n        output_clip = None\n\n        if isinstance(clip, vs.VideoNode):\n            output_clip = clip\n        elif isinstance(clip, list):\n            for item in clip:\n                if isinstance(item, tuple):\n                    clip, index = item\n                    if isinstance(clip, vs.VideoNode) and isinstance(index, int):\n                        if index == 0:\n                            output_clip = clip\n                    else:\n                        raise TypeError(\"encode_video: Tuple must be (VideoNode, int)\")\n            if not output_clip:\n                output_clip = clip[0] if isinstance(clip[0], vs.VideoNode) else None\n            if not output_clip:\n                raise ValueError(\"encode_video: Couldn't parse clip!\")\n\n        assert isinstance(output_clip, vs.VideoNode)\n        assert (\n            output_clip.format.color_family == vs.YUV\n        ), \"encode_video: All clips must be YUV color family\"\n        assert output_clip.fps != 0, \"encode_video: all clips must be CFR\"\n\n        # Allow direct output to stdout when encoder is None\n        if encoder is None:\n            _MIMO([output_clip], [sys.stdout])\n        elif hasattr(encoder, \"write\") and callable(encoder.write):  # type: ignore # type: ignore # File-like object\n            _MIMO([output_clip], [encoder])  # type: ignore\n        else:  # Subprocess.Popen object\n            _MIMO([output_clip], [encoder.stdin])  # type: ignore\n            encoder.communicate()  # type: ignore\n            encoder.wait()  # type: ignore\n    else:\n        assert isinstance(\n            encoder, list\n        ), \"encode_video: encoder must be a list when multi=True\"\n        assert isinstance(\n            clip, list\n        ), \"encode_video: clip must be a list when multi=True\"\n        assert len(encoder) == len(\n            clip\n        ), \"encode_video: encoder and clip must have the same length\"\n        assert all(\n            isinstance(item, vs.VideoNode) for item in clip\n        ), \"encode_video: all items in clip must be VideoNodes\"\n        assert all(\n            clip.format.color_family == vs.YUV for clip in clip  # type: ignore\n        ), \"encode_video: all clips must be YUV color family\"\n        assert all(\n            clip.fps != 0 for clip in clip  # type: ignore\n        ), \"encode_video: all clips must be CFR\"\n\n        output_clips = []\n        stdins = []\n        for i, clip in enumerate(clip):  # type: ignore\n            output_clips.append(clip)\n            if hasattr(encoder[i], \"write\") and callable(encoder[i].write):  # type: ignore # File-like object\n                stdins.append(encoder[i])\n            else:  # Subprocess.Popen object\n                stdins.append(encoder[i].stdin)\n\n        _MIMO(output_clips, stdins)  # type: ignore\n\n        # Only call communicate and wait for Popen objects\n        for i, enc in enumerate(encoder):\n            if not hasattr(enc, \"write\") or not callable(enc.write):  # type: ignore # Not a file-like object\n                enc.communicate()\n                enc.wait()\n</code></pre>"},{"location":"API/encode/video/#y5gfunc.encode.video.encode_video(clip)","title":"<code>clip</code>","text":""},{"location":"API/encode/video/#y5gfunc.encode.video.encode_video(encoder)","title":"<code>encoder</code>","text":""},{"location":"API/encode/video/#y5gfunc.encode.video.encode_video(multi)","title":"<code>multi</code>","text":""},{"location":"API/encode/audio/audio/","title":"<code>y5gfunc.encode.audio.audio</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio","title":"audio","text":"<p>Functions:</p> Name Description <code>encode_audio</code> <p>Encodes or copies a single audio track from an input file using FFmpeg.</p> <code>extract_audio_tracks</code> <p>Extracts and processes audio tracks from a media file based on AudioConfig.</p>"},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.encode_audio","title":"encode_audio","text":"<pre><code>encode_audio(input_file: Union[str, Path], output_file: Union[str, Path], audio_track: int = 0, bitrate: Optional[str] = None, overwrite: bool = True, copy: bool = False, delay: float = 0.0) -&gt; Path\n</code></pre> <p>Encodes or copies a single audio track from an input file using FFmpeg.</p> <p>Handles lossless (FLAC) and lossy (AAC, MP3) encoding, stream copying, and applying audio delay (positive or negative). Special handling exists for applying positive delay when copying lossy streams.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, Path]</code> <p>Path to the input media file.</p> required <code>Union[str, Path]</code> <p>Path for the output audio file. Extension determines format.</p> required <code>int</code> <p>Index of the audio track to process (0-based relative to audio streams only, after FFmpeg maps it).</p> <code>0</code> <code>Optional[str]</code> <p>Target bitrate for lossy encoding (e.g., \"320k\"). Auto-set for AAC/MP3 if None and not copying. Ignored for FLAC/copy.</p> <code>None</code> <code>bool</code> <p>If True, overwrite the output file if it exists.</p> <code>True</code> <code>bool</code> <p>If True, perform a stream copy without re-encoding. Cannot be used with <code>bitrate</code>.</p> <code>False</code> <code>float</code> <p>Audio delay in milliseconds. Positive values add silence at the start; negative values trim from the start.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the created audio file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the input file does not exist.</p> <code>RuntimeError</code> <p>If FFmpeg/FFprobe fails, the output file exists and <code>overwrite</code> is False, or the specified audio track is not found.</p> <code>ValueError</code> <p>If incompatible options are used (e.g., <code>copy</code> and <code>bitrate</code>, bitrate for FLAC).</p> Source code in <code>y5gfunc/encode/audio/audio.py</code> <pre><code>def encode_audio(\n    input_file: Union[str, Path],\n    output_file: Union[str, Path],\n    audio_track: int = 0,\n    bitrate: Optional[str] = None,\n    overwrite: bool = True,\n    copy: bool = False,\n    delay: float = 0.0,  # ms\n) -&gt; Path:\n    \"\"\"\n    Encodes or copies a single audio track from an input file using FFmpeg.\n\n    Handles lossless (FLAC) and lossy (AAC, MP3) encoding, stream copying, and applying audio delay (positive or negative).\n    Special handling exists for applying positive delay when copying lossy streams.\n\n    Args:\n        input_file: Path to the input media file.\n        output_file: Path for the output audio file. Extension determines format.\n        audio_track: Index of the audio track to process (0-based relative to audio streams only, after FFmpeg maps it).\n        bitrate: Target bitrate for lossy encoding (e.g., \"320k\"). Auto-set for AAC/MP3 if None and not copying. Ignored for FLAC/copy.\n        overwrite: If True, overwrite the output file if it exists.\n        copy: If True, perform a stream copy without re-encoding. Cannot be used with `bitrate`.\n        delay: Audio delay in milliseconds. Positive values add silence at the start; negative values trim from the start.\n\n    Returns:\n        Path to the created audio file.\n\n    Raises:\n        FileNotFoundError: If the input file does not exist.\n        RuntimeError: If FFmpeg/FFprobe fails, the output file exists and `overwrite` is False, or the specified audio track is not found.\n        ValueError: If incompatible options are used (e.g., `copy` and `bitrate`, bitrate for FLAC).\n    \"\"\"\n    input_path = resolve_path(input_file)\n    output_path = resolve_path(output_file)\n\n    if not input_path.exists():\n        raise FileNotFoundError(f\"encode_audio: Input file not found: {input_path}\")\n\n    if output_path.exists():\n        if overwrite:\n            output_path.unlink()\n        else:\n            raise RuntimeError(\n                f\"encode_audio: Output file already exists! {output_path}\"\n            )\n\n    if copy and bitrate:\n        raise ValueError(\"encode_audio: Cannot apply bitrate using copy mode!\")\n\n    output_ext = output_path.suffix.lower()\n    if output_ext == \".flac\" and bitrate is not None:\n        raise ValueError(\"encode_audio: Don't set bitrate for flac file!\")\n\n    probe_cmd = [\n        \"ffprobe\",\n        \"-v\",\n        \"quiet\",\n        \"-print_format\",\n        \"json\",\n        \"-show_streams\",\n        \"-select_streams\",\n        f\"a:{audio_track}\",\n        str(input_path),\n    ]\n\n    probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)\n    if probe_result.returncode != 0:\n        raise RuntimeError(f\"encode_audio: FFprobe failed: {probe_result.stderr}\")\n\n    audio_info = json.loads(probe_result.stdout)\n    if not audio_info.get(\"streams\"):\n        raise RuntimeError(f\"encode_audio: No audio track {audio_track} found in file\")\n\n    input_stream = audio_info[\"streams\"][0]\n\n    input_is_lossless = check_audio_stream_lossless(input_stream)\n\n    output_is_lossless = output_ext.lower() in [\".flac\", \".wav\", \".alac\"]\n\n    if output_ext in {\".aac\", \".mp3\"} and bitrate is None and not copy:\n        bitrate = \"320k\"\n\n    if delay &gt; 0 and copy and not input_is_lossless and not output_is_lossless:\n        temp_dir = Path(tempfile.mkdtemp())\n        extracted_audio = temp_dir / f\"extracted{output_ext}\"\n        silence_file = temp_dir / f\"silence{output_ext}\"\n        concat_list = temp_dir / \"concat.txt\"\n\n        extract_cmd = [\n            \"ffmpeg\",\n            \"-i\",\n            str(input_path),\n            \"-map\",\n            f\"0:a:{audio_track}\",\n            \"-c:a\",\n            \"copy\",\n            str(extracted_audio),\n        ]\n\n        extract_process = subprocess.run(extract_cmd, capture_output=True, text=True)\n        if extract_process.returncode != 0:\n            shutil.rmtree(temp_dir)\n            raise RuntimeError(\n                f\"encode_audio: Failed to extract audio: {extract_process.stderr}\\nCommand: {extract_cmd}\"\n            )\n\n        extract_probe_cmd = [\n            \"ffprobe\",\n            \"-v\",\n            \"quiet\",\n            \"-print_format\",\n            \"json\",\n            \"-show_streams\",\n            str(extracted_audio),\n        ]\n\n        extract_probe_result = subprocess.run(\n            extract_probe_cmd, capture_output=True, text=True\n        )\n        if extract_probe_result.returncode != 0:\n            shutil.rmtree(temp_dir)\n            raise RuntimeError(\n                f\"encode_audio: FFprobe failed on extracted audio: {extract_probe_result.stderr}\"\n            )\n\n        extracted_info = json.loads(extract_probe_result.stdout)\n        if not extracted_info.get(\"streams\"):\n            shutil.rmtree(temp_dir)\n            raise RuntimeError(\"encode_audio: No streams found in extracted audio\")\n\n        stream = extracted_info[\"streams\"][0]\n        codec = stream[\"codec_name\"]\n        sample_rate = stream[\"sample_rate\"]\n        sample_fmt = stream.get(\"sample_fmt\")\n\n        if \"channel_layout\" in stream:\n            channel_layout = stream[\"channel_layout\"]\n        else:\n            # Fallback based on channel count\n            channels = stream[\"channels\"]\n            if channels == 1:\n                channel_layout = \"mono\"\n            elif channels == 2:\n                channel_layout = \"stereo\"\n            elif channels == 6:\n                channel_layout = \"5.1\"\n            elif channels == 8:\n                channel_layout = \"7.1\"\n            else:\n                channel_layout = f\"{channels}c\"\n\n        if \"bit_rate\" in stream:\n            audio_bitrate = stream[\"bit_rate\"]\n        else:\n            audio_bitrate = \"320k\" if output_ext in {\".aac\", \".mp3\"} else \"192k\"\n\n        delay_sec = delay / 1000\n        silence_cmd = [\n            \"ffmpeg\",\n            \"-f\",\n            \"lavfi\",\n            \"-i\",\n            f\"anullsrc=channel_layout={channel_layout}:sample_rate={sample_rate}\",\n            \"-t\",\n            f\"{delay_sec}\",\n            \"-c:a\",\n            codec,\n            \"-b:a\",\n            audio_bitrate,\n        ]\n        if sample_fmt:\n            silence_cmd.extend([\"-sample_fmt\", sample_fmt])\n\n        silence_cmd.append(str(silence_file))\n\n        silence_process = subprocess.run(silence_cmd, capture_output=True, text=True)\n        if silence_process.returncode != 0:\n            shutil.rmtree(temp_dir)\n            raise RuntimeError(\n                f\"encode_audio: Failed to generate silence: {silence_process.stderr}\\nCommand: {silence_cmd}\"\n            )\n\n        with open(concat_list, \"w\") as f:\n            f.write(f\"file '{silence_file}'\\n\")\n            f.write(f\"file '{extracted_audio}'\\n\")\n\n        ffmpeg_cmd = [\n            \"ffmpeg\",\n            \"-f\",\n            \"concat\",\n            \"-safe\",\n            \"0\",\n            \"-i\",\n            str(concat_list),\n            \"-c\",\n            \"copy\",\n            str(output_path),\n        ]\n\n        process = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)\n        shutil.rmtree(temp_dir)\n\n        if process.returncode != 0:\n            raise RuntimeError(\n                f\"encode_audio: FFmpeg concat failed: {process.stderr}\\nCommand: {ffmpeg_cmd}\"\n            )\n\n        return output_path\n\n    ffmpeg_cmd = [\"ffmpeg\", \"-i\", str(input_path)]\n\n    if delay != 0:\n        delay_sec = delay / 1000\n        if delay_sec &gt; 0:\n            ffmpeg_cmd.extend([\"-af\", f\"adelay={int(delay)}\"])\n        else:\n            ffmpeg_cmd.extend([\"-ss\", f\"{-delay_sec}\"])\n\n    ffmpeg_cmd.extend([\"-map\", f\"0:a:{audio_track}\"])\n\n    if copy:\n        ffmpeg_cmd.extend([\"-c:a\", \"copy\"])\n    else:\n        if output_ext == \".flac\":\n            sample_fmt = audio_info[\"streams\"][0][\"sample_fmt\"]\n            if \"16\" in sample_fmt:\n                sample_fmt = \"s16\"\n            else:\n                sample_fmt = \"s32\"\n\n            sample_rate = audio_info[\"streams\"][0][\"sample_rate\"]\n            ffmpeg_cmd.extend(\n                [\n                    \"-c:a\",\n                    \"flac\",\n                    \"-sample_fmt\",\n                    sample_fmt,\n                    \"-ar\",\n                    sample_rate,\n                    \"-compression_level\",\n                    \"12\",\n                ]\n            )\n        elif output_ext == \".aac\":\n            assert isinstance(bitrate, str)\n            if platform.system() == \"Darwin\":\n                ffmpeg_cmd.extend(\n                    [\n                        \"-c:a\",\n                        \"aac_at\",\n                        \"-global_quality:a\",\n                        \"14\",\n                        \"-aac_at_mode\",\n                        \"2\",\n                        \"-b:a\",\n                        bitrate,\n                    ]\n                )\n            else:\n                ffmpeg_cmd.extend(\n                    [  # better qaac?\n                        \"-c:a\",\n                        \"libfdk_aac\",\n                        \"-vbr\",\n                        \"5\",\n                        \"-cutoff\",\n                        \"20000\",\n                        \"-b:a\",\n                        bitrate,\n                    ]\n                )\n        elif output_ext == \".mp3\":\n            assert isinstance(bitrate, str)\n            ffmpeg_cmd.extend([\"-c:a\", \"libmp3lame\", \"-q:a\", \"0\", \"-b:a\", bitrate])\n        elif bitrate:\n            ffmpeg_cmd.extend([\"-b:a\", bitrate])\n\n    ffmpeg_cmd.append(str(output_path))\n\n    process = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)\n    if process.returncode != 0:\n        raise RuntimeError(\n            f\"encode_audio: FFmpeg failed: {process.stderr}\\n FFMPEG cmd: {ffmpeg_cmd}\"\n        )\n\n    return output_path\n</code></pre>"},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.encode_audio(input_file)","title":"<code>input_file</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.encode_audio(output_file)","title":"<code>output_file</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.encode_audio(audio_track)","title":"<code>audio_track</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.encode_audio(bitrate)","title":"<code>bitrate</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.encode_audio(overwrite)","title":"<code>overwrite</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.encode_audio(copy)","title":"<code>copy</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.encode_audio(delay)","title":"<code>delay</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.extract_audio_tracks","title":"extract_audio_tracks","text":"<pre><code>extract_audio_tracks(input_path: Union[str, Path], output_dir: Optional[Union[str, Path]] = None, config: AudioConfig = AudioConfig()) -&gt; list[dict[str, Union[str, Path, bool]]]\n</code></pre> <p>Extracts and processes audio tracks from a media file based on AudioConfig.</p> <p>Probes the input file for video and audio streams, attempts to get delays using tsMuxeR (if available), determines the processing mode (copy, compress, lossy encode, drop) for each track based on the provided AudioConfig, and then calls <code>encode_audio</code> for each track to be kept.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, Path]</code> <p>Path to the input media file.</p> required <code>Optional[Union[str, Path]]</code> <p>Directory to save extracted audio files. Defaults to a folder named \"{input_stem}_audio\" next to the input file.</p> <code>None</code> <code>AudioConfig</code> <p>An AudioConfig object defining how to process different types of audio tracks.</p> <code>AudioConfig()</code> <p>Returns:</p> Type Description <code>list[dict[str, Union[str, Path, bool]]]</code> <p>A list of dictionaries, where each dictionary represents a successfully extracted track and contains keys suitable for use in muxing functions.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the input file or required executables (ffprobe, ffmpeg, optionally tsMuxeR) are not found.</p> <code>RuntimeError</code> <p>If ffprobe fails, no audio tracks are found, or if <code>encode_audio</code> fails for any track.</p> Source code in <code>y5gfunc/encode/audio/audio.py</code> <pre><code>def extract_audio_tracks(\n    input_path: Union[str, Path],\n    output_dir: Optional[Union[str, Path]] = None,\n    config: AudioConfig = AudioConfig(),\n) -&gt; list[dict[str, Union[str, Path, bool]]]:\n    \"\"\"\n    Extracts and processes audio tracks from a media file based on AudioConfig.\n\n    Probes the input file for video and audio streams, attempts to get delays using tsMuxeR (if available), determines the processing mode\n    (copy, compress, lossy encode, drop) for each track based on the provided AudioConfig, and then calls `encode_audio` for each track to be kept.\n\n    Args:\n        input_path: Path to the input media file.\n        output_dir: Directory to save extracted audio files. Defaults to a folder named \"{input_stem}_audio\" next to the input file.\n        config: An AudioConfig object defining how to process different types of audio tracks.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a successfully extracted track and contains keys suitable for use in muxing functions.\n\n    Raises:\n        FileNotFoundError: If the input file or required executables (ffprobe, ffmpeg, optionally tsMuxeR) are not found.\n        RuntimeError: If ffprobe fails, no audio tracks are found, or if `encode_audio` fails for any track.\n    \"\"\"\n    input_path = resolve_path(input_path)\n\n    if output_dir is None:\n        output_dir = input_path.parent / f\"{input_path.stem}_audio\"\n\n    output_dir = resolve_path(output_dir)\n\n    video_track_cmd = [\n        \"ffprobe\",\n        \"-v\",\n        \"quiet\",\n        \"-print_format\",\n        \"json\",\n        \"-show_streams\",\n        \"-select_streams\",\n        \"v\",\n        str(input_path),\n    ]\n\n    video_result = subprocess.run(video_track_cmd, capture_output=True, text=True)\n    if video_result.returncode != 0:\n        raise RuntimeError(\n            f\"extract_audio_tracks: ffprobe failed when detecting video tracks: {video_result.stderr}\"\n        )\n\n    video_streams = json.loads(video_result.stdout).get(\"streams\", [])\n    video_track_count = len(video_streams)\n\n    print(f\"extract_audio_tracks: Detected {video_track_count} video tracks.\")\n\n    audio_track_cmd = [\n        \"ffprobe\",\n        \"-v\",\n        \"quiet\",\n        \"-print_format\",\n        \"json\",\n        \"-show_streams\",\n        \"-select_streams\",\n        \"a\",\n        str(input_path),\n    ]\n\n    audio_result = subprocess.run(audio_track_cmd, capture_output=True, text=True)\n    if audio_result.returncode != 0:\n        raise RuntimeError(\n            f\"extract_audio_tracks: ffprobe failed when detecting audio tracks: {audio_result.stderr}\"\n        )\n\n    streams = json.loads(audio_result.stdout).get(\"streams\", [])\n\n    if not streams:\n        raise RuntimeError(\"extract_audio_tracks: No audio tracks found!\")\n\n    print(f\"extract_audio_tracks: Found {len(streams)} audio tracks:\")\n    delays = {}\n    try:\n        tsmuxer_cmd = [\"tsMuxeR\", str(input_path)]\n        tsmuxer_process = subprocess.Popen(\n            tsmuxer_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n        )\n        tsmuxer_output = tsmuxer_process.communicate()[0].decode()\n\n        current_track = None\n        for line in tsmuxer_output.splitlines():\n            if line.startswith(\"Track ID:\"):\n                current_track = line[9:].strip()\n            elif line.startswith(\"Stream delay:\") and current_track:\n                delay_str = line[13:].strip()\n                if delay_str.endswith(\"ms\"):\n                    delay_str = delay_str[:-2]\n                try:\n                    delays[int(current_track)] = float(delay_str)\n                except ValueError:\n                    pass\n    except Exception as e:\n        print(f\"Warning: Failed to get delays from tsmuxer: {e}\")\n\n    print(delays)\n\n    for stream in streams:\n        default_str = (\n            \" (Default)\" if stream.get(\"disposition\", {}).get(\"default\") else \"\"\n        )\n        comment_str = (\n            \" (Commentary)\" if stream.get(\"disposition\", {}).get(\"comment\") else \"\"\n        )\n        if not stream.get(\"id\"):\n            stream[\"id\"] = hex(\n                int(stream.get(\"index\")) + 1\n            )  # make up id for non-m2ts sources\n        language = get_language_by_trackid(\n            m2ts_path=input_path, ffprobe_id=stream.get(\"id\")\n        )\n        if language == \"und\":\n            if stream.get(\"tags\"):\n                language = stream.get(\"tags\", {}).get(\n                    \"language\", \"und\"\n                )  # also try ffprobe\n        stream[\"language\"] = language\n        print(\n            f\"Track {stream['index']}: {stream.get('codec_name', 'unknown')} \"\n            f\"{stream.get('channels', '?')}ch \"\n            f\"Language: {language} \"\n            f\"Delay: {delays.get(int(stream.get('id'), 16), 0.0)}\"\n            f\"{default_str}{comment_str}\"\n        )\n\n    output_dir.mkdir(parents=True, exist_ok=True)\n    extracted_tracks = []\n\n    for stream in streams:\n        track_num = stream[\"index\"]\n        codec_name = stream.get(\"codec_name\", \"\").lower()\n        language = stream[\"language\"]\n        channels = int(stream.get(\"channels\", 2))\n        is_default = bool(stream.get(\"disposition\", {}).get(\"default\"))\n        is_comment = bool(stream.get(\"disposition\", {}).get(\"comment\"))\n\n        is_stream_lossless = check_audio_stream_lossless(stream)\n\n        is_core_track = False\n        if codec_name == \"dts\":\n            base_id = stream.get(\"id\", \"\").rsplit(\".\", 1)[0]\n            for other_stream in streams:\n                if all(\n                    [\n                        other_stream[\"index\"] != track_num,\n                        other_stream.get(\"id\", \"\").startswith(base_id),\n                        other_stream.get(\"profile\", \"\").lower() == \"dts-hd ma\",\n                    ]\n                ):\n                    is_core_track = True\n                    break\n        elif codec_name == \"ac3\":\n            base_id = stream.get(\"id\", \"\").rsplit(\".\", 1)[0]\n            for other_stream in streams:\n                if all(\n                    [\n                        other_stream[\"index\"] != track_num,\n                        other_stream.get(\"codec_name\", \"\").lower() == \"truehd\",\n                        other_stream.get(\"id\", \"\").startswith(base_id),\n                    ]\n                ):\n                    is_core_track = True\n                    break\n\n        if is_core_track:\n            print(\n                f\"extract_audio_tracks: Skipping core track {track_num} ({codec_name})\"\n            )\n            continue\n\n        source_bitrate = None\n        if \"bit_rate\" in stream:\n            try:\n                source_bitrate = int(stream[\"bit_rate\"]) // 1000  # kbps\n            except (ValueError, TypeError):\n                pass\n\n        track_config = config.get_track_config(\n            is_comment=is_comment,\n            is_lossless=is_stream_lossless,\n            channels=channels,\n            bitrate=source_bitrate,\n        )\n\n        if track_config.mode == ProcessMode.DROP:\n            print(f\"extract_audio_tracks: Dropping track {track_num}\")\n            continue\n        if track_config.mode == ProcessMode.COPY:\n            output_ext = codec_name\n            should_copy = True\n            encode_bitrate = None\n        elif track_config.mode == ProcessMode.COMPRESS:\n            output_ext = track_config.format\n            should_copy = False\n            encode_bitrate = None\n        else:  # LOSSY\n            output_ext = track_config.format\n            should_copy = False\n            encode_bitrate = track_config.bitrate\n\n        prefix = \"comment_\" if is_comment else \"track_\"\n        output_path = output_dir / f\"{prefix}{track_num}_{language}.{output_ext}\"\n\n        print(\n            f\"\\nextract_audio_tracks: Processing {'comment ' if is_comment else ''}audio track {track_num}\"\n        )\n        print(f\"Codec: {codec_name}, Channels: {channels}, Language: {language}\")\n        if source_bitrate:\n            print(f\"Original bitrate: {source_bitrate}kbps\")\n\n        delay = delays.get(int(stream.get(\"id\", \"-0x1\"), 16), 0.0)\n        if delay != 0.0:\n            print(\n                f\"extract_audio_tracks: Applying delay of {delay}ms for track {track_num}\"\n            )\n\n        try:\n            output_path = encode_audio(\n                input_file=input_path,\n                output_file=output_path,\n                audio_track=track_num - video_track_count,\n                overwrite=True,\n                copy=should_copy,\n                delay=delay,\n                bitrate=encode_bitrate,\n            )\n\n            extracted_tracks.append(\n                {\n                    \"path\": output_path,\n                    \"language\": language,\n                    \"default\": is_default,\n                    \"comment\": is_comment,\n                }\n            )\n\n            print(f\"extract_audio_tracks: Successfully extracted to: {output_path}\")\n\n        except Exception as e:\n            raise RuntimeError(\n                f\"extract_audio_tracks: Failed to extract track {track_num}: {e}\"\n            )\n\n    return extracted_tracks\n</code></pre>"},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.extract_audio_tracks(input_path)","title":"<code>input_path</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.extract_audio_tracks(output_dir)","title":"<code>output_dir</code>","text":""},{"location":"API/encode/audio/audio/#y5gfunc.encode.audio.audio.extract_audio_tracks(config)","title":"<code>config</code>","text":""},{"location":"API/encode/audio/audio_config/","title":"<code>y5gfunc.encode.audio.audio_config</code>","text":""},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config","title":"audio_config","text":"<p>Classes:</p> Name Description <code>ProcessMode</code> <p>Defines how an audio track should be processed.</p> <code>TrackConfig</code> <code>AudioConfig</code> <p>Functions:</p> Name Description <code>create_main_lossless_2ch</code> <code>create_main_lossless_multi</code> <code>create_main_lossy</code> <code>create_main_special</code> <code>create_comment_lossless_2ch</code> <code>create_comment_lossless_multi</code> <code>create_comment_lossy_low</code> <code>create_comment_lossy_2ch</code> <code>create_comment_lossy_multi</code>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.ProcessMode","title":"ProcessMode","text":"<p>               Bases: <code>StrEnum</code></p> <p>Defines how an audio track should be processed.</p> <p>Attributes:</p> Name Type Description <code>COPY</code> <p>Keep original track, stream copy if possible</p> <code>COMPRESS</code> <p>Re-encode losslessly (e.g., to FLAC)</p> <code>LOSSY</code> <p>Re-encode lossily (e.g., to AAC, Opus)</p> <code>DROP</code> <p>Do not include this track in the output</p>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.ProcessMode.COPY","title":"COPY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COPY = 'copy'\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.ProcessMode.COMPRESS","title":"COMPRESS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COMPRESS = 'compress'\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.ProcessMode.LOSSY","title":"LOSSY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LOSSY = 'lossy'\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.ProcessMode.DROP","title":"DROP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DROP = 'drop'\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.TrackConfig","title":"TrackConfig  <code>dataclass</code>","text":"<pre><code>TrackConfig(mode: ProcessMode = COPY, format: str = 'flac', bitrate: Optional[str] = None)\n</code></pre> <p>Attributes:</p> Name Type Description <code>mode</code> <code>ProcessMode</code> <code>format</code> <code>str</code> <code>bitrate</code> <code>Optional[str]</code>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.TrackConfig.mode","title":"mode  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>mode: ProcessMode = COPY\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.TrackConfig.format","title":"format  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>format: str = 'flac'\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.TrackConfig.bitrate","title":"bitrate  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bitrate: Optional[str] = None\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig","title":"AudioConfig  <code>dataclass</code>","text":"<pre><code>AudioConfig(main_lossless_2ch: TrackConfig = create_main_lossless_2ch(), main_lossless_multi: TrackConfig = create_main_lossless_multi(), main_lossy: TrackConfig = create_main_lossy(), main_special: TrackConfig = create_main_special(), comment_lossless_2ch: TrackConfig = create_comment_lossless_2ch(), comment_lossless_multi: TrackConfig = create_comment_lossless_multi(), comment_lossy_low: TrackConfig = create_comment_lossy_low(), comment_lossy_2ch: TrackConfig = create_comment_lossy_2ch(), comment_lossy_multi: TrackConfig = create_comment_lossy_multi(), lossy_threshold: int = 512)\n</code></pre> <p>Methods:</p> Name Description <code>get_track_config</code> <p>Determines the appropriate TrackConfig based on audio track properties.</p> <p>Attributes:</p> Name Type Description <code>main_lossless_2ch</code> <code>TrackConfig</code> <code>main_lossless_multi</code> <code>TrackConfig</code> <code>main_lossy</code> <code>TrackConfig</code> <code>main_special</code> <code>TrackConfig</code> <code>comment_lossless_2ch</code> <code>TrackConfig</code> <code>comment_lossless_multi</code> <code>TrackConfig</code> <code>comment_lossy_low</code> <code>TrackConfig</code> <code>comment_lossy_2ch</code> <code>TrackConfig</code> <code>comment_lossy_multi</code> <code>TrackConfig</code> <code>lossy_threshold</code> <code>int</code>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.main_lossless_2ch","title":"main_lossless_2ch  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>main_lossless_2ch: TrackConfig = field(default_factory=create_main_lossless_2ch)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.main_lossless_multi","title":"main_lossless_multi  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>main_lossless_multi: TrackConfig = field(default_factory=create_main_lossless_multi)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.main_lossy","title":"main_lossy  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>main_lossy: TrackConfig = field(default_factory=create_main_lossy)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.main_special","title":"main_special  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>main_special: TrackConfig = field(default_factory=create_main_special)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.comment_lossless_2ch","title":"comment_lossless_2ch  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>comment_lossless_2ch: TrackConfig = field(default_factory=create_comment_lossless_2ch)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.comment_lossless_multi","title":"comment_lossless_multi  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>comment_lossless_multi: TrackConfig = field(default_factory=create_comment_lossless_multi)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.comment_lossy_low","title":"comment_lossy_low  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>comment_lossy_low: TrackConfig = field(default_factory=create_comment_lossy_low)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.comment_lossy_2ch","title":"comment_lossy_2ch  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>comment_lossy_2ch: TrackConfig = field(default_factory=create_comment_lossy_2ch)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.comment_lossy_multi","title":"comment_lossy_multi  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>comment_lossy_multi: TrackConfig = field(default_factory=create_comment_lossy_multi)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.lossy_threshold","title":"lossy_threshold  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>lossy_threshold: int = 512\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.get_track_config","title":"get_track_config","text":"<pre><code>get_track_config(is_comment: bool, is_lossless: bool, channels: int, bitrate: Optional[int] = None, is_special: bool = False) -&gt; TrackConfig\n</code></pre> <p>Determines the appropriate TrackConfig based on audio track properties.</p> <p>Parameters:</p> Name Type Description Default <code>bool</code> <p>True if the track is commentary.</p> required <code>bool</code> <p>True if the original track is lossless.</p> required <code>int</code> <p>Number of audio channels in the track.</p> required <code>Optional[int]</code> <p>Original bitrate of the track in Kbps (used for lossy threshold).</p> <code>None</code> <code>bool</code> <p>True if the track should use the 'main_special' config.</p> <code>False</code> <p>Returns:</p> Type Description <code>TrackConfig</code> <p>The selected TrackConfig instance defining how to process the track.</p> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def get_track_config(\n    self,\n    is_comment: bool,\n    is_lossless: bool,\n    channels: int,\n    bitrate: Optional[int] = None,\n    is_special: bool = False,\n) -&gt; TrackConfig:\n    \"\"\"\n    Determines the appropriate TrackConfig based on audio track properties.\n\n    Args:\n        is_comment: True if the track is commentary.\n        is_lossless: True if the original track is lossless.\n        channels: Number of audio channels in the track.\n        bitrate: Original bitrate of the track in Kbps (used for lossy threshold).\n        is_special: True if the track should use the 'main_special' config.\n\n    Returns:\n        The selected TrackConfig instance defining how to process the track.\n    \"\"\"\n\n    if is_special:\n        return self.main_special\n\n    if is_comment:\n        if is_lossless:\n            return (\n                self.comment_lossless_2ch\n                if channels &lt;= 2\n                else self.comment_lossless_multi\n            )\n        else:  # lossy\n            if bitrate and bitrate &lt; self.lossy_threshold:\n                return self.comment_lossy_low\n            return (\n                self.comment_lossy_2ch\n                if channels &lt;= 2\n                else self.comment_lossy_multi\n            )\n    else:  # main track\n        if is_lossless:\n            return (\n                self.main_lossless_2ch\n                if channels &lt;= 2\n                else self.main_lossless_multi\n            )\n        return self.main_lossy\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.get_track_config(is_comment)","title":"<code>is_comment</code>","text":""},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.get_track_config(is_lossless)","title":"<code>is_lossless</code>","text":""},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.get_track_config(channels)","title":"<code>channels</code>","text":""},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.get_track_config(bitrate)","title":"<code>bitrate</code>","text":""},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.AudioConfig.get_track_config(is_special)","title":"<code>is_special</code>","text":""},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.create_main_lossless_2ch","title":"create_main_lossless_2ch","text":"<pre><code>create_main_lossless_2ch() -&gt; TrackConfig\n</code></pre> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def create_main_lossless_2ch() -&gt; TrackConfig:\n    return TrackConfig(mode=ProcessMode.COMPRESS, format=\"flac\")\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.create_main_lossless_multi","title":"create_main_lossless_multi","text":"<pre><code>create_main_lossless_multi() -&gt; TrackConfig\n</code></pre> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def create_main_lossless_multi() -&gt; TrackConfig:\n    return TrackConfig(mode=ProcessMode.COMPRESS, format=\"flac\")\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.create_main_lossy","title":"create_main_lossy","text":"<pre><code>create_main_lossy() -&gt; TrackConfig\n</code></pre> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def create_main_lossy() -&gt; TrackConfig:\n    return TrackConfig(mode=ProcessMode.COPY)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.create_main_special","title":"create_main_special","text":"<pre><code>create_main_special() -&gt; TrackConfig\n</code></pre> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def create_main_special() -&gt; TrackConfig:\n    return TrackConfig(mode=ProcessMode.COMPRESS, format=\"flac\")\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.create_comment_lossless_2ch","title":"create_comment_lossless_2ch","text":"<pre><code>create_comment_lossless_2ch() -&gt; TrackConfig\n</code></pre> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def create_comment_lossless_2ch() -&gt; TrackConfig:\n    return TrackConfig(mode=ProcessMode.LOSSY, format=\"aac\", bitrate=\"192k\")\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.create_comment_lossless_multi","title":"create_comment_lossless_multi","text":"<pre><code>create_comment_lossless_multi() -&gt; TrackConfig\n</code></pre> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def create_comment_lossless_multi() -&gt; TrackConfig:\n    return TrackConfig(mode=ProcessMode.LOSSY, format=\"aac\", bitrate=\"320k\")\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.create_comment_lossy_low","title":"create_comment_lossy_low","text":"<pre><code>create_comment_lossy_low() -&gt; TrackConfig\n</code></pre> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def create_comment_lossy_low() -&gt; TrackConfig:\n    return TrackConfig(mode=ProcessMode.COPY)\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.create_comment_lossy_2ch","title":"create_comment_lossy_2ch","text":"<pre><code>create_comment_lossy_2ch() -&gt; TrackConfig\n</code></pre> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def create_comment_lossy_2ch() -&gt; TrackConfig:\n    return TrackConfig(mode=ProcessMode.LOSSY, format=\"aac\", bitrate=\"192k\")\n</code></pre>"},{"location":"API/encode/audio/audio_config/#y5gfunc.encode.audio.audio_config.create_comment_lossy_multi","title":"create_comment_lossy_multi","text":"<pre><code>create_comment_lossy_multi() -&gt; TrackConfig\n</code></pre> Source code in <code>y5gfunc/encode/audio/audio_config.py</code> <pre><code>def create_comment_lossy_multi() -&gt; TrackConfig:\n    return TrackConfig(mode=ProcessMode.LOSSY, format=\"aac\", bitrate=\"320k\")\n</code></pre>"},{"location":"API/encode/audio/utils/","title":"<code>y5gfunc.encode.audio.utils</code>","text":""},{"location":"API/encode/audio/utils/#y5gfunc.encode.audio.utils","title":"utils","text":"<p>Functions:</p> Name Description <code>check_audio_stream_lossless</code> <p>Checks if an audio stream from ffprobe represents a lossless format.</p> <p>Attributes:</p> Name Type Description <code>LOSSLESS_CODEC_NAMES</code>"},{"location":"API/encode/audio/utils/#y5gfunc.encode.audio.utils.LOSSLESS_CODEC_NAMES","title":"LOSSLESS_CODEC_NAMES  <code>module-attribute</code>","text":"<pre><code>LOSSLESS_CODEC_NAMES = {'truehd', 'flac', 'alac', 'mlp', 'pcm_s16le', 'pcm_s24le', 'pcm_s32le', 'pcm_f32le', 'pcm_f64le', 'pcm_s16be', 'pcm_s24be', 'pcm_s32be', 'pcm_f32be', 'pcm_f64be', 'pcm_alaw', 'pcm_mulaw', 'pcm_u8'}\n</code></pre>"},{"location":"API/encode/audio/utils/#y5gfunc.encode.audio.utils.check_audio_stream_lossless","title":"check_audio_stream_lossless","text":"<pre><code>check_audio_stream_lossless(stream: dict) -&gt; bool\n</code></pre> <p>Checks if an audio stream from ffprobe represents a lossless format.</p> <p>Parameters:</p> Name Type Description Default <code>dict</code> <p>A dictionary representing an audio stream from ffprobe JSON.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the stream is identified as lossless, False otherwise.</p> Source code in <code>y5gfunc/encode/audio/utils.py</code> <pre><code>def check_audio_stream_lossless(stream: dict) -&gt; bool:\n    \"\"\"\n    Checks if an audio stream from ffprobe represents a lossless format.\n\n    Args:\n        stream: A dictionary representing an audio stream from ffprobe JSON.\n\n    Returns:\n        True if the stream is identified as lossless, False otherwise.\n    \"\"\"\n    codec_name = str(stream.get(\"codec_name\", \"\")).lower()\n    profile = str(stream.get(\"profile\", \"\")).lower()\n\n    if \"dts\" in profile or codec_name == \"dts\":\n        if profile == \"dts-hd ma\":\n            return True\n        else:\n            return False\n\n    if codec_name in LOSSLESS_CODEC_NAMES:\n        return True\n\n    return False\n</code></pre>"},{"location":"API/encode/audio/utils/#y5gfunc.encode.audio.utils.check_audio_stream_lossless(stream)","title":"<code>stream</code>","text":""},{"location":"API/expr/expr_utils/","title":"<code>y5gfunc.expr.expr_utils</code>","text":""},{"location":"API/expr/expr_utils/#y5gfunc.expr.expr_utils","title":"expr_utils","text":"<p>Attributes:</p> Name Type Description <code>math_functions</code> <code>str</code>"},{"location":"API/expr/expr_utils/#y5gfunc.expr.expr_utils.math_functions","title":"math_functions  <code>module-attribute</code>","text":"<pre><code>math_functions: str = '\\n# These functions work, but some are really slow......\\n\\nfunction fma(var1, var2, var3) {\\n    return var1 * var2 + var3\\n}\\n\\nfunction copysign(val, sign) {\\n    return (sign &lt; 0) ? -abs(val) : abs(val)\\n}\\n\\n# https://stackoverflow.com/a/23097989\\nfunction atan(var) {\\n    zz = abs(var)\\n    aa = (zz &gt; 1) ? (1 / zz) : zz\\n    ss = aa ** 2\\n    qq = ss ** 2\\n    pp =             -2.0258553044340116e-5\\n    tt =              2.2302240345710764e-4\\n    pp = fma(pp, qq, -1.1640717779912220e-3)\\n    tt = fma(tt, qq,  3.8559749383656407e-3)\\n    pp = fma(pp, qq, -9.1845592187222193e-3)\\n    tt = fma(tt, qq,  1.6978035834594660e-2)\\n    pp = fma(pp, qq, -2.5826796814492296e-2)\\n    tt = fma(tt, qq,  3.4067811082715810e-2)\\n    pp = fma(pp, qq, -4.0926382420509999e-2)\\n    tt = fma(tt, qq,  4.6739496199158334e-2)\\n    pp = fma(pp, qq, -5.2392330054601366e-2)\\n    tt = fma(tt, qq,  5.8773077721790683e-2)\\n    pp = fma(pp, qq, -6.6658603633512892e-2)\\n    tt = fma(tt, qq,  7.6922129305867892e-2)\\n    pp = fma(pp, ss,                     tt)\\n    pp = fma(pp, ss, -9.0909012354005267e-2)\\n    pp = fma(pp, ss,  1.1111110678749421e-1)\\n    pp = fma(pp, ss, -1.4285714271334810e-1)\\n    pp = fma(pp, ss,  1.9999999999755005e-1)\\n    pp = fma(pp, ss, -3.3333333333331838e-1)\\n    pp = fma(pp * ss, aa, aa)\\n    rr = (zz &gt; 1) ? fma(0.93282184640716537, 1.6839188885261840, -pp): pp\\n    return copysign (rr, var)\\n}\\n\\nfunction atan2(var_y, var_x) {\\n    theta = 0\\n    theta = (var_x &gt; 0) ? atan(var_y / var_x) : theta\\n    theta = (var_x &lt; 0) ? (atan(var_y / var_x) + copysign(pi, var_y)) : theta\\n    theta = ((var_x == 0) &amp;&amp; var_y) ? (copysign(pi / 2, var_y)) : theta\\n    theta = ((var_x == 0) &amp;&amp; (var_y == 0)) ? 0 : theta\\n    return theta\\n}\\n\\nfunction cot(var) {\\n    return cos(var) / sin(var)\\n}\\n\\nfunction sec(var) {\\n    return 1 / cos(var)\\n}\\n\\nfunction csc(var) {\\n    return 1 / sin(var)\\n}\\n\\nfunction asin(var) {\\n    return 2 * atan(var / (1 + sqrt(1 - var ** 2)))\\n}\\n\\nfunction acos(var) {\\n    return 2 * atan(sqrt((1 - var) / (1 + var)))\\n}\\n\\nfunction acot(var) {\\n    return pi / 2 - atan(var)\\n}\\n\\nfunction sinh(var) {\\n    return (exp(var) - exp(-var)) / 2\\n}\\n\\nfunction cosh(var) {\\n    return (exp(var) + exp(-var)) / 2\\n}\\n\\nfunction tanh(var) {\\n    return (exp(2 * var) - 1) / (exp(2 * var) + 1)\\n}\\n\\nfunction coth(var) {\\n    return (exp(2 * var) + 1) / (exp(2 * var) - 1)\\n}\\n\\nfunction sech(var) {\\n    return 1 / cosh(var)\\n}\\n\\nfunction csch(var) {\\n    return 1 / sinh(var)\\n}\\n\\nfunction arsinh(var) {\\n    return log(var + sqrt(var ** 2 + 1))\\n}\\n\\nfunction arcosh(var) {\\n    return log(var + sqrt(var ** 2 - 1))\\n}\\n\\nfunction artanh(var) {\\n    return 0.5 * log((1 + var) / (1 - var))\\n}\\n\\nfunction arcoth(var) {\\n    return 0.5 * log((var + 1) / (var - 1))\\n}\\n\\nfunction arsech(var) {\\n    return log((1 + sqrt(1 - var ** 2)) / var)\\n}\\n\\nfunction arcsch(var) {\\n    return log(1 / var + sqrt(1 / (var ** 2) + 1))\\n}\\n\\n# https://stackoverflow.com/a/77465269\\nfunction cbrt(var) {\\n    abs_var = abs(var)\\n    est = abs_var ? exp(log(abs_var) / 3) : var\\n    est = copysign(est, var)\\n    cube = est ** 3 \\n    return abs_var? fma(-est, ((cube - var) / (2 * cube + var)), est) : var\\n}\\n\\n# https://github.com/kravietz/nist-sts/blob/master/erf.c\\nfunction erf(var) {\\n    abs_var = abs(var)\\n    tt = 1 / (1 + 0.3275911 * abs_var)\\n    yy = 1 - (((((1.061405429 * tt + -1.453152027) * tt) + 1.421413741) * tt + -0.284496736) * tt + 0.254829592) * tt * exp(-abs_var * abs_var)\\n    return copysign(yy, var)\\n}\\n\\n# https://github.com/kravietz/nist-sts/blob/master/erf.c\\nfunction erfc(var) {\\n\\tzz = abs(var)\\n\\ttt = 1 / (1 + 0.5 * zz)\\n\\tans = tt * exp(-zz * zz - 1.26551223 + tt * (1.00002368 + tt * (0.37409196 + tt * (0.09678418 + tt * (-0.18628806 + tt * (0.27886807 + tt * (-1.13520398 + tt * (1.48851587 + tt * (-0.82215223 + tt * 0.17087277)))))))))\\n\\treturn var &gt;= 0 ? ans : 2 - ans\\n}\\n\\nfunction gamma_sign(var_z) {\\n    is_pole = (var_z &lt;= 0) &amp;&amp; (floor(var_z) == var_z)\\n    use_reflection = (var_z &lt; 0.5) &amp;&amp; !is_pole\\n    sign_direct = 1\\n    sin_pi_var_z = sin(pi * var_z)\\n    sign_reflected = (sin_pi_var_z &gt;= 0) ? 1 : -1\\n    calc_sign = use_reflection ? sign_reflected : sign_direct\\n    return is_pole ? 1 : calc_sign\\n}\\n\\nfunction lgamma_val(var_z) {\\n    is_pole = (var_z &lt;= 0) &amp;&amp; (floor(var_z) == var_z)\\n    use_reflection = (var_z &lt; 0.5) &amp;&amp; !is_pole\\n    var_z_calc = use_reflection ? (1 - var_z) : var_z\\n    var_z_minus_1 = var_z_calc - 1\\n    tmp = var_z_minus_1 + 7 + 0.5\\n    series = 0.99999999999980993227684700473478\\n    series = series + 676.52036812188509856700919044401 / (var_z_minus_1 + 1)\\n    series = series + -1259.1392167224028704715607875528 / (var_z_minus_1 + 2)\\n    series = series + 771.32342877765307884893049653757 / (var_z_minus_1 + 3)\\n    series = series + -176.61502916214059906584551354002 / (var_z_minus_1 + 4)\\n    series = series + 12.507343278686904814458936853287 / (var_z_minus_1 + 5)\\n    series = series + -0.13857109526572011689554707118956 / (var_z_minus_1 + 6)\\n    series = series + 9.9843695780195708595638234185252e-6 / (var_z_minus_1 + 7)\\n    series = series + 1.5056327351493115583497230996790e-7 / (var_z_minus_1 + 8)\\n    log_series = log(max(series, 1e9))\\n    log_gamma_core = 0.5 * log(2 * pi) + (var_z_calc - 0.5) * log(max(tmp, 1e9)) - tmp + log_series\\n    sin_pi_var_z = sin(pi * var_z)\\n    log_abs_sin = log(max(abs(sin_pi_var_z), 1e9))\\n    reflection_adjustment = log(pi) - log_abs_sin\\n    final_log_gamma = use_reflection ? (reflection_adjustment - log_gamma_core) : log_gamma_core\\n    return is_pole ? 1e9 : final_log_gamma\\n}\\n\\nfunction tgamma(var_z) {\\n    sign = gamma_sign(var_z)\\n    lgamma_val = lgamma_val(var_z)\\n    is_inf = (lgamma_val &gt;= 1e9)\\n    abs_gamma = exp(lgamma_val)\\n    signed_gamma = sign * abs_gamma\\n    return is_inf ? (sign * 1e9) : signed_gamma\\n}\\n'\n</code></pre>"},{"location":"API/expr/infix2postfix/","title":"<code>y5gfunc.expr.infix2postfix</code>","text":""},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix","title":"infix2postfix","text":"<p>Classes:</p> Name Description <code>SyntaxError</code> <p>Custom syntax error class with line information</p> <p>Functions:</p> Name Description <code>is_clip</code> <p>Determine whether token is a source clip.</p> <code>is_constant</code> <p>Check if the token is a built-in constant.</p> <code>strip_outer_parentheses</code> <p>Remove outer parentheses if the entire expression is enclosed.</p> <code>match_full_function_call</code> <p>Try to match a complete function call with proper nesting.</p> <code>extract_function_info</code> <p>Given a renamed internal variable (e.g. __internal_funcname_varname),</p> <code>find_duplicate_functions</code> <p>Check if any duplicate function is defined.</p> <code>compute_stack_effect</code> <p>Compute the net stack effect of a postfix expression.</p> <code>parse_ternary</code> <p>For a given expression string without delimiters, detects the presence of a ternary operator in the outer layer.</p> <code>infix2postfix</code> <p>Convert infix expressions to postfix expressions.</p> <code>validate_static_relative_pixel_indices</code> <p>Validate that the static relative pixel access indices are numeric constants.</p> <code>check_variable_usage</code> <p>Check that all variables in the expression have been defined.</p> <code>convert_expr</code> <p>Convert a single infix expression to a postfix expression.</p> <code>find_binary_op</code> <p>Find the last occurrence of the binary operator op at the outer level and return the left and right parts.</p> <code>parse_args</code> <p>Parse the arguments of a function call.</p> <code>is_builtin_function</code> <p>Check if the function name belongs to a built-in function.</p> <p>Attributes:</p> Name Type Description <code>func_call_pattern</code> <code>clip_pattern</code> <code>func_info_pattern</code> <code>func_pattern</code> <code>global_decl_pattern</code> <code>function_def_pattern</code> <code>m_call_pattern</code> <code>m_str_pattern</code> <code>valid_str_pattern</code> <code>number_pattern</code> <code>nth_pattern</code> <code>m_line_pattern</code> <code>m_static_pattern</code> <code>find_duplicate_functions_pattern</code> <code>drop_pattern</code> <code>sort_pattern</code> <code>global_match_pattern</code> <code>assign_pattern</code> <code>rel_pattern</code> <code>func_sub_pattern</code> <code>identifier_pattern</code> <code>letter_pattern</code> <code>function_pattern</code> <code>build_in_func_patterns</code>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.func_call_pattern","title":"func_call_pattern  <code>module-attribute</code>","text":"<pre><code>func_call_pattern = compile('(\\\\w+)\\\\s*\\\\(')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.clip_pattern","title":"clip_pattern  <code>module-attribute</code>","text":"<pre><code>clip_pattern = compile('(?:[a-zA-Z]|src\\\\d+)$')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.func_info_pattern","title":"func_info_pattern  <code>module-attribute</code>","text":"<pre><code>func_info_pattern = compile('__internal_([a-zA-Z_]\\\\w*)_([a-zA-Z_]\\\\w+)$')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.func_pattern","title":"func_pattern  <code>module-attribute</code>","text":"<pre><code>func_pattern = compile('function\\\\s+(\\\\w+)')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.global_decl_pattern","title":"global_decl_pattern  <code>module-attribute</code>","text":"<pre><code>global_decl_pattern = compile('^&lt;global((?:&lt;[a-zA-Z_]\\\\w*&gt;)+)&gt;$')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.function_def_pattern","title":"function_def_pattern  <code>module-attribute</code>","text":"<pre><code>function_def_pattern = compile('^\\\\s*function\\\\s+(\\\\w+)\\\\s*\\\\(([^)]*)\\\\)\\\\s*\\\\{')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.m_call_pattern","title":"m_call_pattern  <code>module-attribute</code>","text":"<pre><code>m_call_pattern = compile('^(\\\\w+)\\\\s*\\\\(')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.m_str_pattern","title":"m_str_pattern  <code>module-attribute</code>","text":"<pre><code>m_str_pattern = compile('^str\\\\(([^)]+)\\\\)$')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.valid_str_pattern","title":"valid_str_pattern  <code>module-attribute</code>","text":"<pre><code>valid_str_pattern = compile('\\\\b([a-zA-Z_]\\\\w*)\\\\b')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.number_pattern","title":"number_pattern  <code>module-attribute</code>","text":"<pre><code>number_pattern = compile('^(0x[0-9A-Fa-f]+(\\\\.[0-9A-Fa-f]+(p[+\\\\-]?\\\\d+)?)?|0[0-7]*|[+\\\\-]?(\\\\d+(\\\\.\\\\d+)?([eE][+\\\\-]?\\\\d+)?))$')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.nth_pattern","title":"nth_pattern  <code>module-attribute</code>","text":"<pre><code>nth_pattern = compile('^nth_(\\\\d+)$')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.m_line_pattern","title":"m_line_pattern  <code>module-attribute</code>","text":"<pre><code>m_line_pattern = compile('^([a-zA-Z_]\\\\w*)\\\\s*=\\\\s*(.+)$')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.m_static_pattern","title":"m_static_pattern  <code>module-attribute</code>","text":"<pre><code>m_static_pattern = compile('^(\\\\w+)\\\\[(-?\\\\d+),\\\\s*(-?\\\\d+)\\\\](\\\\:\\\\w)?$')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.find_duplicate_functions_pattern","title":"find_duplicate_functions_pattern  <code>module-attribute</code>","text":"<pre><code>find_duplicate_functions_pattern = compile('\\\\bfunction\\\\s+(\\\\w+)\\\\s*\\\\(.*?\\\\)')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.drop_pattern","title":"drop_pattern  <code>module-attribute</code>","text":"<pre><code>drop_pattern = compile('drop(\\\\d*)')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.sort_pattern","title":"sort_pattern  <code>module-attribute</code>","text":"<pre><code>sort_pattern = compile('sort(\\\\d+)')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.global_match_pattern","title":"global_match_pattern  <code>module-attribute</code>","text":"<pre><code>global_match_pattern = compile('&lt;([a-zA-Z_]\\\\w*)&gt;')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.assign_pattern","title":"assign_pattern  <code>module-attribute</code>","text":"<pre><code>assign_pattern = compile('(?&lt;![&lt;&gt;!])=(?![=])')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.rel_pattern","title":"rel_pattern  <code>module-attribute</code>","text":"<pre><code>rel_pattern = compile('\\\\w+\\\\[(.*?)\\\\]')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.func_sub_pattern","title":"func_sub_pattern  <code>module-attribute</code>","text":"<pre><code>func_sub_pattern = compile('\\\\w+\\\\([^)]*\\\\)|\\\\[[^\\\\]]*\\\\]')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.identifier_pattern","title":"identifier_pattern  <code>module-attribute</code>","text":"<pre><code>identifier_pattern = compile('\\\\b([a-zA-Z_]\\\\w*)\\\\b(?!\\\\s*\\\\()')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.letter_pattern","title":"letter_pattern  <code>module-attribute</code>","text":"<pre><code>letter_pattern = compile('[a-zA-Z_]\\\\w*')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.function_pattern","title":"function_pattern  <code>module-attribute</code>","text":"<pre><code>function_pattern = compile('function\\\\s+(\\\\w+)\\\\s*\\\\(([^)]*)\\\\)\\\\s*\\\\{([^{}]*(?:\\\\{[^{}]*\\\\}[^{}]*)*)\\\\}')\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.build_in_func_patterns","title":"build_in_func_patterns  <code>module-attribute</code>","text":"<pre><code>build_in_func_patterns = [compile(r) for r in [f'^{prefix}\\d+$' for prefix in ['nth_', 'sort', 'dup', 'drop', 'swap']]]\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.SyntaxError","title":"SyntaxError","text":"<pre><code>SyntaxError(message: str, line_num: Optional[int] = None, function_name: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Custom syntax error class with line information</p> <p>Attributes:</p> Name Type Description <code>line_num</code> <code>function_name</code> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    line_num: Optional[int] = None,\n    function_name: Optional[str] = None,\n):\n    self.line_num = line_num\n    self.function_name = function_name\n    if function_name and line_num is not None:\n        super().__init__(\n            f\"Line {line_num}: In function '{function_name}', {message}\"\n        )\n    elif line_num is not None:\n        super().__init__(f\"Line {line_num}: {message}\")\n    else:\n        super().__init__(message)\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.SyntaxError.line_num","title":"line_num  <code>instance-attribute</code>","text":"<pre><code>line_num = line_num\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.SyntaxError.function_name","title":"function_name  <code>instance-attribute</code>","text":"<pre><code>function_name = function_name\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.is_clip","title":"is_clip  <code>cached</code>","text":"<pre><code>is_clip(token: str) -&gt; bool\n</code></pre> <p>Determine whether token is a source clip. (std.Expr: single letter; or akarin.Expr: srcN)</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>@lru_cache\ndef is_clip(token: str) -&gt; bool:\n    \"\"\"\n    Determine whether token is a source clip.\n    (std.Expr: single letter; or akarin.Expr: srcN)\n    \"\"\"\n    return bool(clip_pattern.fullmatch(token))\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.is_constant","title":"is_constant  <code>cached</code>","text":"<pre><code>is_constant(token: str) -&gt; bool\n</code></pre> <p>Check if the token is a built-in constant.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>@lru_cache\ndef is_constant(token: str) -&gt; bool:\n    \"\"\"\n    Check if the token is a built-in constant.\n    \"\"\"\n    constants_set = {\n        \"N\",\n        \"X\",\n        \"current_x\",\n        \"Y\",\n        \"current_y\",\n        \"width\",\n        \"current_width\",\n        \"height\",\n        \"current_height\",\n        \"pi\",\n    }\n    if token in constants_set:\n        return True\n    if is_clip(token):\n        return True\n    return False\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.strip_outer_parentheses","title":"strip_outer_parentheses  <code>cached</code>","text":"<pre><code>strip_outer_parentheses(expr: str) -&gt; str\n</code></pre> <p>Remove outer parentheses if the entire expression is enclosed.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>@lru_cache\ndef strip_outer_parentheses(expr: str) -&gt; str:\n    \"\"\"\n    Remove outer parentheses if the entire expression is enclosed.\n    \"\"\"\n    if not expr.startswith(\"(\") or not expr.endswith(\")\"):\n        return expr\n    count = 0\n    for i, char in enumerate(expr):\n        if char == \"(\":\n            count += 1\n        elif char == \")\":\n            count -= 1\n        if count == 0 and i &lt; len(expr) - 1:\n            return expr\n    return expr[1:-1]\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.match_full_function_call","title":"match_full_function_call  <code>cached</code>","text":"<pre><code>match_full_function_call(expr: str) -&gt; Optional[tuple[str, str]]\n</code></pre> <p>Try to match a complete function call with proper nesting. Returns (func_name, args_str) if matched; otherwise returns None.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>@lru_cache\ndef match_full_function_call(expr: str) -&gt; Optional[tuple[str, str]]:\n    \"\"\"\n    Try to match a complete function call with proper nesting.\n    Returns (func_name, args_str) if matched; otherwise returns None.\n    \"\"\"\n    expr = expr.strip()\n    m = func_call_pattern.match(expr)\n    if not m:\n        return None\n    func_name = m.group(1)\n    start = m.end() - 1  # position of '('\n    depth = 0\n    for i in range(start, len(expr)):\n        if expr[i] == \"(\":\n            depth += 1\n        elif expr[i] == \")\":\n            depth -= 1\n            if depth == 0:\n                if i == len(expr) - 1:\n                    args_str = expr[start + 1 : i]\n                    return func_name, args_str\n                else:\n                    return None\n    return None\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.extract_function_info","title":"extract_function_info  <code>cached</code>","text":"<pre><code>extract_function_info(internal_var: str, current_function: Optional[str] = None) -&gt; tuple[Optional[str], Optional[str]]\n</code></pre> <p>Given a renamed internal variable (e.g. __internal_funcname_varname), extract the original function name and variable name.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>@lru_cache\ndef extract_function_info(\n    internal_var: str, current_function: Optional[str] = None\n) -&gt; tuple[Optional[str], Optional[str]]:\n    \"\"\"\n    Given a renamed internal variable (e.g. __internal_funcname_varname),\n    extract the original function name and variable name.\n    \"\"\"\n    if current_function is not None and internal_var.startswith(\n        f\"__internal_{current_function}_\"\n    ):\n        return current_function, internal_var[len(f\"__internal_{current_function}_\") :]\n    match = func_info_pattern.match(internal_var)\n    if match:\n        return match.group(1), match.group(2)\n    return None, None\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.find_duplicate_functions","title":"find_duplicate_functions","text":"<pre><code>find_duplicate_functions(code: str)\n</code></pre> <p>Check if any duplicate function is defined.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def find_duplicate_functions(code: str):\n    \"\"\"\n    Check if any duplicate function is defined.\n    \"\"\"\n    function_lines = {}\n    lines = code.split(\"\\n\")\n    for line_num, line in enumerate(lines, start=1):\n        match = find_duplicate_functions_pattern.search(line)\n        if match:\n            func_name = match.group(1)\n            if func_name in function_lines:\n                raise SyntaxError(\n                    f\"Duplicated function '{func_name}' defined at lines {function_lines[func_name]} and {line_num}\",\n                    line_num=line_num,\n                )\n            function_lines[func_name] = line_num\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.compute_stack_effect","title":"compute_stack_effect","text":"<pre><code>compute_stack_effect(postfix_expr: str, line_num: Optional[int] = None, func_name: Optional[str] = None) -&gt; int\n</code></pre> <p>Compute the net stack effect of a postfix expression.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def compute_stack_effect(\n    postfix_expr: str, line_num: Optional[int] = None, func_name: Optional[str] = None\n) -&gt; int:\n    \"\"\"\n    Compute the net stack effect of a postfix expression.\n    \"\"\"\n    tokens = postfix_expr.split()\n    op_arity = {\n        \"+\": 2,\n        \"-\": 2,\n        \"*\": 2,\n        \"/\": 2,\n        \"%\": 2,\n        \"pow\": 2,\n        \"and\": 2,\n        \"or\": 2,\n        \"=\": 2,\n        \"&lt;\": 2,\n        \"&gt;\": 2,\n        \"&lt;=\": 2,\n        \"&gt;=\": 2,\n        \"bitand\": 2,\n        \"bitor\": 2,\n        \"bitxor\": 2,\n        \"min\": 2,\n        \"max\": 2,\n        \"clamp\": 3,\n        \"?\": 3,\n        \"not\": 1,\n        \"sin\": 1,\n        \"cos\": 1,\n        \"round\": 1,\n        \"floor\": 1,\n        \"abs\": 1,\n        \"sqrt\": 1,\n        \"trunc\": 1,\n        \"bitnot\": 1,\n    }\n\n    stack: list[int] = []\n    for i, token in enumerate(tokens):\n        if token.endswith(\"!\"):\n            if not stack:\n                raise SyntaxError(\"Stack underflow in assignment\", line_num, func_name)\n            stack.pop()\n            continue\n        elif token.endswith(\"[]\"):  # dynamic access operator\n            if len(stack) &lt; 2:\n                raise SyntaxError(\n                    f\"Stack underflow for operator {token} at token index {i}\",\n                    line_num,\n                    func_name,\n                )\n            stack.pop()\n            stack.pop()\n            stack.append(1)\n            continue\n\n        # dropN operator (default is drop1)\n        m_drop = drop_pattern.fullmatch(token)\n        if m_drop:\n            n_str = m_drop.group(1)\n            n = int(n_str) if n_str != \"\" else 1\n            if len(stack) &lt; n:\n                raise SyntaxError(\n                    f\"Stack underflow for operator {token}\", line_num, func_name\n                )\n            for _ in range(n):\n                stack.pop()\n            continue\n\n        # sortN operator: reorder top N items without changing the stack count.\n        m_sort = sort_pattern.fullmatch(token)\n        if m_sort:\n            n = int(m_sort.group(1))\n            if len(stack) &lt; n:\n                raise SyntaxError(\n                    f\"Stack underflow for operator {token}\", line_num, func_name\n                )\n            # Sorting reorders items but does not change the stack count.\n            continue\n\n        if token in op_arity:\n            arity = op_arity[token]\n            if len(stack) &lt; arity:\n                raise SyntaxError(\n                    f\"Stack underflow for operator {token} at token index {i}\",\n                    line_num,\n                    func_name,\n                )\n            for _ in range(arity):\n                stack.pop()\n            stack.append(1)\n        else:\n            stack.append(1)\n    return len(stack)\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.parse_ternary","title":"parse_ternary","text":"<pre><code>parse_ternary(expr: str, line_num: Optional[int] = None, func_name: Optional[str] = None) -&gt; Optional[tuple[str, str, str]]\n</code></pre> <p>For a given expression string without delimiters, detects the presence of a ternary operator in the outer layer. If present, returns a triple (condition, true_expr, false_expr); otherwise returns None.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def parse_ternary(\n    expr: str, line_num: Optional[int] = None, func_name: Optional[str] = None\n) -&gt; Optional[tuple[str, str, str]]:\n    \"\"\"\n    For a given expression string without delimiters, detects the presence of a ternary operator in the outer layer.\n    If present, returns a triple (condition, true_expr, false_expr); otherwise returns None.\n    \"\"\"\n    expr = expr.strip()\n    n = len(expr)\n    depth = 0\n    q_index = -1\n    for i, c in enumerate(expr):\n        if c == \"(\":\n            depth += 1\n        elif c == \")\":\n            depth -= 1\n        elif c == \"?\" and depth == 0:\n            q_index = i\n            break\n    if q_index == -1:\n        return None\n\n    condition = expr[:q_index].strip()\n\n    ternary_level = 1\n    depth = 0\n    colon_index = -1\n    for i in range(q_index + 1, n):\n        c = expr[i]\n        if c == \"(\":\n            depth += 1\n        elif c == \")\":\n            depth -= 1\n        elif c == \"?\" and depth == 0:\n            ternary_level += 1\n        elif c == \":\" and depth == 0:\n            ternary_level -= 1\n            if ternary_level == 0:\n                colon_index = i\n                break\n    if colon_index == -1:\n        raise SyntaxError(\"Ternary operator missing ':'\", line_num, func_name)\n    true_expr = expr[q_index + 1 : colon_index].strip()\n    false_expr = expr[colon_index + 1 :].strip()\n    return (condition, true_expr, false_expr)\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix","title":"infix2postfix","text":"<pre><code>infix2postfix(infix_code: str) -&gt; str\n</code></pre> <p>Convert infix expressions to postfix expressions.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Input infix code.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Converted postfix expr.</p> <p>Raises:</p> Type Description <code>SyntaxError</code> <p>If infix code failed to convert to postfix expr.</p> <p>Refer to ..vfx/ and .expr_utils.py for examples.</p>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix(infix_code)","title":"<code>infix_code</code>","text":""},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--general-format","title":"General Format","text":"<ul> <li> <p>Input Structure: The source code is written as plain text with one statement per line. User input must not contain semicolons.</p> </li> <li> <p>Whitespace: Whitespace (spaces and newlines) is used to separate tokens and statements. Extra spaces are generally ignored.</p> </li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--lexical-elements","title":"Lexical Elements","text":""},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--identifiers-and-literals","title":"Identifiers and Literals","text":"<ul> <li>Identifiers (Variable and Function Names):</li> <li>Must start with a letter or an underscore and can be composed of letters, digits, and underscores (matching <code>[a-zA-Z_]\\w*</code>).</li> <li>Identifiers starting with the reserved prefix <code>__internal_</code> are not allowed in user code (they are used internally for parameter renaming and temporary variables).</li> <li> <p>Some names are \u201cbuilt-in constants\u201d (see below) and cannot be reassigned.</p> </li> <li> <p>Built-in Constants: The language defines the following reserved identifiers: (Refer to std.Expr and akarin.Expr documents for more information)</p> </li> <li> <p><code>N</code>, <code>X</code>, <code>current_x</code>, <code>Y</code>, <code>current_y</code>, <code>width</code>, <code>current_width</code>, <code>height</code>, <code>current_height</code>, <code>pi</code> In addition, any token that is a single letter (e.g. <code>a</code>, <code>b</code>) or a string matching <code>src</code> followed by digits (e.g. <code>src1</code>, <code>src42</code>) is considered a source clip.</p> </li> <li> <p>Numeric Literals: The language supports:  (Refer to akarin.Expr documents for more information)</p> </li> <li>Decimal numbers: Integers (e.g. <code>123</code>, <code>-42</code>) and floating\u2011point numbers (e.g. <code>3.14</code>, <code>-0.5</code> with optional scientific notation).</li> <li>Hexadecimal numbers: Starting with <code>0x</code> followed by hexadecimal digits (optionally with a fractional part and a \u201cp\u2011exponent\u201d).</li> <li>Octal numbers: A leading zero followed by octal digits (e.g. <code>0755</code>).</li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--operators","title":"Operators","text":""},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--binary-operators","title":"Binary Operators","text":"<p>Expressions may contain binary operators that, when converted, yield corresponding postfix tokens. The supported binary operators include:</p> <ul> <li>Logical Operators:</li> <li><code>||</code> (logical OR; converted to <code>or</code>)</li> <li> <p><code>&amp;&amp;</code> (logical AND; converted to <code>and</code>)</p> </li> <li> <p>Bitwise Operators:</p> <ul> <li><code>&amp;</code> (bitwise AND; converted to <code>bitand</code>)</li> <li><code>|</code> (bitwise OR; converted to <code>bitor</code>)</li> <li><code>^</code> (bitwise XOR; converted to <code>bitxor</code>)</li> </ul> </li> <li> <p>Equality and Relational Operators:</p> </li> <li><code>==</code> (equality, converted to <code>=</code> in postfix)</li> <li><code>!=</code> (inequality)</li> <li> <p>Relational: <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code></p> </li> <li> <p>Arithmetic Operators:</p> </li> <li><code>+</code> (addition)</li> <li><code>-</code> (subtraction)</li> <li><code>*</code> (multiplication)</li> <li><code>/</code> (division)</li> <li><code>%</code> (modulus)</li> <li><code>**</code> (exponentiation; converted to <code>pow</code>)</li> </ul> <p>When parsing an infix expression, the algorithm searches for a binary operator at the outer level (i.e. not inside any nested parentheses) and\u2014depending on its position\u2014splits the expression into left and right operands. The order in which the operator candidates are considered effectively defines the operator precedence.</p>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--unary-operators","title":"Unary Operators","text":"<ul> <li> <p>Negation: A minus sign (<code>-</code>) may be used to denote negative numeric literals; if used before an expression that is not a literal number, it is interpreted as multiplying the operand by -1.</p> </li> <li> <p>Logical NOT: An exclamation mark (<code>!</code>) is used as a unary operator for logical NOT. For example, <code>!expr</code> is converted to postfix by appending the operator <code>not</code> to the processed operand.</p> </li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--ternary-operator","title":"Ternary Operator","text":"<ul> <li>Conditional Expression: The language supports a ternary operator with the syntax: <pre><code>condition ? true_expression : false_expression\n</code></pre> The operator first evaluates the condition; then based on its result, it selects either the true or false branch. In the conversion process, the three expressions are translated to a corresponding postfix form followed by a <code>?</code> token.</li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--grouping","title":"Grouping","text":"<ul> <li>Parentheses: Parentheses <code>(</code> and <code>)</code> can be used to override the default evaluation order. If an entire expression is wrapped in parentheses, the outer pair is stripped prior to further conversion.</li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--function-calls-and-built-in-functions","title":"Function Calls and Built-in Functions","text":""},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--general-function-call-syntax","title":"General Function Call Syntax","text":"<ul> <li> <p>Invocation: Functions are called using the usual form: <pre><code>functionName(arg1, arg2, \u2026)\n</code></pre> The argument list must be properly parenthesized and can contain nested expressions. The arguments are parsed by taking into account nested parentheses and brackets.</p> </li> <li> <p>Builtin Function Examples: Some functions are specially handled and have fixed argument counts:</p> </li> <li> <p>Unary Functions: <code>sin(x)</code>, <code>cos(x)</code>, <code>round(x)</code>, <code>floor(x)</code>, <code>abs(x)</code>, <code>sqrt(x)</code>, <code>trunc(x)</code>, <code>bitnot(x)</code>, <code>not(x)</code>, <code>str(x)</code>     &gt; Note: <code>str(x)</code> acts like \"x\" or 'x' in python, and is only used in get_prop* functions (see below).</p> </li> <li> <p>Binary Functions: <code>min(a, b)</code>, <code>max(a, b)</code>, <code>get_prop(clip, prop)</code>, <code>get_prop_safe(clip, prop)</code>     For the <code>get_prop*</code> functions, the first argument must be a valid source clip, and the second argument must be a string. (e.g. To get frame prop 'abc' from src0, call get_prop(_safe)(src0, str(abc)))     <code>get_prop_safe</code> ensures returns are numbers, while <code>get_prop</code> returns a <code>nan</code> if fetching a non-exist prop.</p> </li> <li> <p>Ternary Functions: <code>clamp(a, b, c)</code>, <code>dyn(a, b, c)</code>     Again, in the case of <code>dyn</code> the first argument must be a valid source clip.     In addidion, an extra optimizing will be performed to convert dynamic access (<code>dyn</code>) to static access (see below) if possible for potentially higher performance.</p> </li> <li> <p>Special Pattern \u2013 nth_N Functions:     Function names matching the pattern <code>nth_&lt;number&gt;</code> (for example, <code>nth_2</code>) are supported. They require at least N arguments and returns the Nth smallest of the arguments (e.g. <code>nth_1(a, b, c, d)</code> returns the smallest one of <code>a</code>, <code>b</code>, <code>c</code> and <code>d</code>).</p> </li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--custom-function-definitions","title":"Custom Function Definitions","text":"<ul> <li>Syntax: Functions are defined as follows: <pre><code>function functionName(param1, param2, \u2026) {\n    // function body\n    return expression\n}\n</code></pre></li> <li>Requirements and Checks:</li> <li>The parameter names must be unique, and none may begin with the reserved prefix <code>__internal_</code>.</li> <li>The function body may span several lines. It can contain assignment statements and expression evaluations.</li> <li>There must be exactly one return statement, and it must be the last (non-empty) statement in the function body.</li> <li>Defining functions inside another function is not currently supported.</li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--global-declarations-and-assignments","title":"Global Declarations and Assignments","text":""},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--global-declarations","title":"Global Declarations","text":"<ul> <li>Syntax: Global variables may be declared on a dedicated line with the format: <pre><code>&lt;global&lt;var1&gt;&lt;var2&gt;\u2026&gt;\n</code></pre> This declaration must immediately precede a function definition, and the declared names are recorded as global variables associated with that function.</li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--assignment-statements","title":"Assignment Statements","text":"<ul> <li> <p>Global Assignments: A top-level assignment statement uses the syntax: <pre><code>variable = expression\n</code></pre> The left-hand side (<code>variable</code>) must not be a built-in constant or otherwise reserved. The expression on the right-hand side is converted to its postfix form. Internally, the assignment is marked by appending an exclamation mark (<code>!</code>) to indicate that the result is stored in that variable.</p> </li> <li> <p>Variable Usage Rules: Variables must be defined (assigned) before they are referenced in expressions. Otherwise, a syntax error will be raised.</p> </li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--special-constructs","title":"Special Constructs","text":""},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--static-relative-pixel-access","title":"Static Relative Pixel Access","text":"<ul> <li>Syntax: For accessing a pixel value relative to a source clip, the expression can take the following form: <pre><code>clip[statX, statY]\n</code></pre> where:</li> <li><code>clip</code> is a valid source clip,</li> <li><code>statX</code> and <code>statY</code> are integer literals specifying the x and y offsets, and</li> <li> <p>An optional suffix (<code>:m</code> or <code>:c</code>) may follow the closing bracket.</p> </li> <li> <p>Validation: The indices must be numeric constants (no expressions allowed inside the brackets).</p> </li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--operator-precedence-and-expression-parsing","title":"Operator Precedence and Expression Parsing","text":"<ul> <li> <p>Precedence Determination: When converting infix to postfix, the parser searches the expression (tracking parenthesis nesting) for a binary operator at the outer level. The operators are considered in the following order (which effectively sets their precedence):</p> </li> <li> <p>Logical OR: <code>||</code></p> </li> <li>Logical AND: <code>&amp;&amp;</code></li> <li>Bitwise Operators: <code>&amp;</code>, <code>|</code>, <code>^</code></li> <li>Relational: <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code></li> <li>Equality: <code>==</code></li> <li>Inequality: <code>!=</code></li> <li>Addition and Subtraction: <code>+</code>, <code>-</code></li> <li>Multiplication, Division, and Modulus: <code>*</code>, <code>/</code>, <code>%</code></li> <li>Exponentiation: <code>**</code></li> </ul> <p>The conversion function finds the last occurrence of an operator at the outer level for splitting the expression. Parentheses can be used to override this behavior.</p> <ul> <li>Ternary Operator: The ternary operator (<code>? :</code>) is detected after other operators have been processed.</li> </ul>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.infix2postfix--error-checks-and-restrictions","title":"Error Checks and Restrictions","text":"<ul> <li> <p>Semicolon Usage: The input may not contain semicolons.</p> </li> <li> <p>Naming Restrictions: Variables, function names, and parameters must not use reserved names (such as built-in constants or names beginning with <code>__internal_</code>).</p> </li> <li> <p>Global Dependencies: For functions that use global variables (declared using the <code>&lt;global&lt;...&gt;&gt;</code> syntax), the globals must be defined before any function call that depends on them.</p> </li> <li> <p>Function Return: Each function definition must have exactly one return statement, and that return must be the last statement in the function.</p> </li> <li> <p>Argument Counts: Function calls (both built-in and custom) check that the exact number of required arguments is provided; otherwise, a syntax error is raised.</p> </li> </ul> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def infix2postfix(infix_code: str) -&gt; str:\n    R\"\"\"\n    Convert infix expressions to postfix expressions.\n\n    Args:\n        infix_code: Input infix code.\n\n    Returns:\n        Converted postfix expr.\n\n    Raises:\n        SyntaxError: If infix code failed to convert to postfix expr.\n\n    Refer to ..vfx/ and .expr_utils.py for examples.\n\n    ## General Format\n\n    - **Input Structure:**\n    The source code is written as plain text with one statement per line. User input must not contain semicolons.\n\n    - **Whitespace:**\n    Whitespace (spaces and newlines) is used to separate tokens and statements. Extra spaces are generally ignored.\n\n    ---\n\n    ## Lexical Elements\n\n    ### Identifiers and Literals\n\n    - **Identifiers (Variable and Function Names):**\n    - Must start with a letter or an underscore and can be composed of letters, digits, and underscores (matching `[a-zA-Z_]\\w*`).\n    - Identifiers starting with the reserved prefix `__internal_` are not allowed in user code (they are used internally for parameter renaming and temporary variables).\n    - Some names are \u201cbuilt-in constants\u201d (see below) and cannot be reassigned.\n\n    - **Built-in Constants:**\n    The language defines the following reserved identifiers: (Refer to std.Expr and akarin.Expr documents for more information)\n    - `N`, `X`, `current_x`, `Y`, `current_y`, `width`, `current_width`, `height`, `current_height`, `pi`\n    In addition, any token that is a single letter (e.g. `a`, `b`) or a string matching `src` followed by digits (e.g. `src1`, `src42`) is considered a source clip.\n\n    - **Numeric Literals:**\n    The language supports:  (Refer to akarin.Expr documents for more information)\n    - **Decimal numbers:** Integers (e.g. `123`, `-42`) and floating\u2011point numbers (e.g. `3.14`, `-0.5` with optional scientific notation).\n    - **Hexadecimal numbers:** Starting with `0x` followed by hexadecimal digits (optionally with a fractional part and a \u201cp\u2011exponent\u201d).\n    - **Octal numbers:** A leading zero followed by octal digits (e.g. `0755`).\n\n    ---\n\n    ## Operators\n\n    ### Binary Operators\n\n    Expressions may contain binary operators that, when converted, yield corresponding postfix tokens. The supported binary operators include:\n\n    - **Logical Operators:**\n    - `||` (logical OR; converted to `or`)\n    - `&amp;&amp;` (logical AND; converted to `and`)\n\n    - **Bitwise Operators:**\n        - `&amp;` (bitwise AND; converted to `bitand`)\n        - `|` (bitwise OR; converted to `bitor`)\n        - `^` (bitwise XOR; converted to `bitxor`)\n\n    - **Equality and Relational Operators:**\n    - `==` (equality, converted to `=` in postfix)\n    - `!=` (inequality)\n    - Relational: `&lt;`, `&gt;`, `&lt;=`, `&gt;=`\n\n    - **Arithmetic Operators:**\n    - `+` (addition)\n    - `-` (subtraction)\n    - `*` (multiplication)\n    - `/` (division)\n    - `%` (modulus)\n    - `**` (exponentiation; converted to `pow`)\n\n    When parsing an infix expression, the algorithm searches for a binary operator at the outer level (i.e. not inside any nested parentheses) and\u2014depending on its position\u2014splits the expression into left and right operands. The order in which the operator candidates are considered effectively defines the operator precedence.\n\n    ### Unary Operators\n\n    - **Negation:**\n    A minus sign (`-`) may be used to denote negative numeric literals; if used before an expression that is not a literal number, it is interpreted as multiplying the operand by -1.\n\n    - **Logical NOT:**\n    An exclamation mark (`!`) is used as a unary operator for logical NOT. For example, `!expr` is converted to postfix by appending the operator `not` to the processed operand.\n\n    ### Ternary Operator\n\n    - **Conditional Expression:**\n    The language supports a ternary operator with the syntax:\n    ```\n    condition ? true_expression : false_expression\n    ```\n    The operator first evaluates the condition; then based on its result, it selects either the true or false branch. In the conversion process, the three expressions are translated to a corresponding postfix form followed by a `?` token.\n\n    ---\n\n    ## Grouping\n\n    - **Parentheses:**\n    Parentheses `(` and `)` can be used to override the default evaluation order. If an entire expression is wrapped in parentheses, the outer pair is stripped prior to further conversion.\n\n    ---\n\n    ## Function Calls and Built-in Functions\n\n    ### General Function Call Syntax\n\n    - **Invocation:**\n    Functions are called using the usual form:\n    ```\n    functionName(arg1, arg2, \u2026)\n    ```\n    The argument list must be properly parenthesized and can contain nested expressions. The arguments are parsed by taking into account nested parentheses and brackets.\n\n    - **Builtin Function Examples:**\n    Some functions are specially handled and have fixed argument counts:\n\n    - **Unary Functions:**\n        `sin(x)`, `cos(x)`, `round(x)`, `floor(x)`, `abs(x)`, `sqrt(x)`, `trunc(x)`, `bitnot(x)`, `not(x)`, `str(x)`\n        &gt; **Note:** `str(x)` acts like \"x\" or 'x' in python, and is only used in get_prop* functions (see below).\n\n    - **Binary Functions:**\n        `min(a, b)`, `max(a, b)`, `get_prop(clip, prop)`, `get_prop_safe(clip, prop)`\n        For the `get_prop*` functions, the first argument must be a valid source clip, and the second argument must be a string. (e.g. To get frame prop 'abc' from src0, call get_prop(_safe)(src0, str(abc)))\n        `get_prop_safe` ensures returns are numbers, while `get_prop` returns a `nan` if fetching a non-exist prop.\n\n    - **Ternary Functions:**\n        `clamp(a, b, c)`, `dyn(a, b, c)`\n        Again, in the case of `dyn` the first argument must be a valid source clip.\n        In addidion, an extra optimizing will be performed to convert dynamic access (`dyn`) to static access (see below) if possible for potentially higher performance.\n\n    - **Special Pattern \u2013 nth_N Functions:**\n        Function names matching the pattern `nth_&lt;number&gt;` (for example, `nth_2`) are supported. They require at least N arguments and returns the Nth smallest of the arguments (e.g. `nth_1(a, b, c, d)` returns the smallest one of `a`, `b`, `c` and `d`).\n\n    ### Custom Function Definitions\n\n    - **Syntax:**\n    Functions are defined as follows:\n    ```\n    function functionName(param1, param2, \u2026) {\n        // function body\n        return expression\n    }\n    ```\n    - **Requirements and Checks:**\n    - The parameter names must be unique, and none may begin with the reserved prefix `__internal_`.\n    - The function body may span several lines. It can contain assignment statements and expression evaluations.\n    - There must be exactly one return statement, and it must be the last (non-empty) statement in the function body.\n    - Defining functions inside another function is not currently supported.\n\n    ---\n\n    ## Global Declarations and Assignments\n\n    ### Global Declarations\n\n    - **Syntax:**\n    Global variables may be declared on a dedicated line with the format:\n    ```\n    &lt;global&lt;var1&gt;&lt;var2&gt;\u2026&gt;\n    ```\n    This declaration must immediately precede a function definition, and the declared names are recorded as global variables associated with that function.\n\n    ### Assignment Statements\n\n    - **Global Assignments:**\n    A top-level assignment statement uses the syntax:\n    ```\n    variable = expression\n    ```\n    The left-hand side (`variable`) must not be a built-in constant or otherwise reserved. The expression on the right-hand side is converted to its postfix form. Internally, the assignment is marked by appending an exclamation mark (`!`) to indicate that the result is stored in that variable.\n\n    - **Variable Usage Rules:**\n    Variables must be defined (assigned) before they are referenced in expressions. Otherwise, a syntax error will be raised.\n\n    ---\n\n    ## Special Constructs\n\n    ### Static Relative Pixel Access\n\n    - **Syntax:**\n    For accessing a pixel value relative to a source clip, the expression can take the following form:\n    ```\n    clip[statX, statY]\n    ```\n    where:\n    - `clip` is a valid source clip,\n    - `statX` and `statY` are integer literals specifying the x and y offsets, and\n    - An optional suffix (`:m` or `:c`) may follow the closing bracket.\n\n    - **Validation:**\n    The indices must be numeric constants (no expressions allowed inside the brackets).\n\n    ---\n\n    ## Operator Precedence and Expression Parsing\n\n    - **Precedence Determination:**\n    When converting infix to postfix, the parser searches the expression (tracking parenthesis nesting) for a binary operator at the outer level. The operators are considered in the following order (which effectively sets their precedence):\n\n    1. Logical OR: `||`\n    2. Logical AND: `&amp;&amp;`\n    3. Bitwise Operators: `&amp;`, `|`, `^`\n    4. Relational: `&lt;`, `&lt;=`, `&gt;`, `&gt;=`\n    5. Equality: `==`\n    6. Inequality: `!=`\n    7. Addition and Subtraction: `+`, `-`\n    8. Multiplication, Division, and Modulus: `*`, `/`, `%`\n    9. Exponentiation: `**`\n\n    The conversion function finds the **last occurrence** of an operator at the outer level for splitting the expression. Parentheses can be used to override this behavior.\n\n    - **Ternary Operator:**\n    The ternary operator (`? :`) is detected after other operators have been processed.\n\n    ---\n\n    ## Error Checks and Restrictions\n\n    - **Semicolon Usage:**\n    The input may not contain semicolons.\n\n    - **Naming Restrictions:**\n    Variables, function names, and parameters must not use reserved names (such as built-in constants or names beginning with `__internal_`).\n\n    - **Global Dependencies:**\n    For functions that use global variables (declared using the `&lt;global&lt;...&gt;&gt;` syntax), the globals must be defined before any function call that depends on them.\n\n    - **Function Return:**\n    Each function definition must have exactly one return statement, and that return must be the last statement in the function.\n\n    - **Argument Counts:**\n    Function calls (both built-in and custom) check that the exact number of required arguments is provided; otherwise, a syntax error is raised.\n    \"\"\"\n\n    # Reject user input that contains semicolons.\n    if \";\" in infix_code:\n        raise SyntaxError(\n            \"User input code cannot contain semicolons. Use newlines instead.\"\n        )\n\n    # Check for duplicate function definitions.\n    find_duplicate_functions(infix_code)\n\n    # Process global declarations.\n    # global declaration syntax: &lt;global&lt;var1&gt;&lt;var2&gt;...&gt;\n    # Also record for functions if global declaration appears immediately before function definition.\n    declared_globals: dict[\n        str, int\n    ] = {}  # mapping: global variable -&gt; declaration line number\n    global_vars_for_functions: dict[str, set[str]] = {}\n    lines = infix_code.split(\"\\n\")\n    modified_lines: list[str] = []\n\n    # Build a mapping from line number to function name for function declarations.\n    function_lines = {}\n    for i, line in enumerate(lines):\n        func_match = func_pattern.match(line.strip())\n        if func_match:\n            func_name = func_match.group(1)\n            function_lines[i] = func_name\n\n    i = 0\n    while i &lt; len(lines):\n        line = lines[i].strip()\n\n        global_decl_match = global_decl_pattern.match(line)\n        if global_decl_match:\n            # Extract all global variable names from this line.\n            globals_list = global_match_pattern.findall(global_decl_match.group(1))\n            for gv in globals_list:\n                if gv not in declared_globals:\n                    declared_globals[gv] = (\n                        i + 1\n                    )  # store declaration line number (1-indexed)\n            j = i + 1\n            # If the next non-global line is a function definition, apply these globals for that function.\n            if j &lt; len(lines):\n                function_match = function_def_pattern.match(lines[j])\n                if function_match:\n                    func_name = function_match.group(1)\n                    args = function_match.group(2)\n                    if func_name not in global_vars_for_functions:\n                        global_vars_for_functions[func_name] = set(\"\")\n                    global_vars_for_functions[func_name].update(globals_list)\n                    function_params = parse_args(args)\n                    if any(\n                        global_var in function_params for global_var in globals_list\n                    ):\n                        raise SyntaxError(\n                            \"Function param must not duplicate with global declarations.\",\n                            j,\n                        )\n                else:\n                    raise SyntaxError(\n                        \"Global declaration must be followed by a function definition.\",\n                        j,\n                    )\n            else:\n                raise SyntaxError(\n                    \"Global declaration must not be at the last line of code.\",\n                    j,\n                )\n            # Comment out the global declaration lines.\n            for k in range(i, j):\n                modified_lines.append(\"# \" + lines[k])\n            i = j\n        else:\n            modified_lines.append(lines[i])\n            i += 1\n\n    expanded_code = \"\\n\".join(modified_lines)\n\n    # Replace function definitions with newlines to preserve line numbers.\n    functions: dict[str, tuple[list[str], str, int, set[str]]] = {}\n\n    def replace_function(match: re.Match[str]) -&gt; str:\n        func_name = match.group(1)\n        params_str = match.group(2)\n        body = match.group(3)\n        func_start_index = match.start()\n        line_num = 1 + expanded_code[:func_start_index].count(\"\\n\")\n        params = [p.strip() for p in params_str.split(\",\") if p.strip()]\n\n        try:\n            dup1, dup2, dupc = reduce(  # type: ignore\n                lambda a, i: a  # type: ignore\n                if a[1] is not None  # type: ignore\n                else (\n                    {**a[0], i[1]: i[0]} if i[1] not in a[0] else a[0],  # type: ignore\n                    (a[0][i[1]], i[0], i[1]) if i[1] in a[0] else None,  # type: ignore\n                ),\n                enumerate(params),\n                ({}, None),  # type: ignore\n            )[1]\n            if any([dup1, dup2, dupc]):  # type: ignore\n                raise SyntaxError(\n                    f\"{dup1}th argument and {dup2}th argument '{dupc}' duplicated in function definition.\",\n                    line_num,\n                )\n        except (TypeError, UnboundLocalError):\n            pass\n\n        if is_builtin_function(func_name):\n            raise SyntaxError(\n                f\"Function name '{func_name}' conflicts with built-in functions!\",\n                line_num,\n            )\n        for param in params:\n            if param.startswith(\"__internal_\"):\n                raise SyntaxError(\n                    f\"Parameter name '{param}' cannot start with '__internal_' (reserved prefix)\",\n                    line_num,\n                )\n        # Get globals declared for this function if any.\n        global_vars = global_vars_for_functions.get(func_name, set())\n        functions[func_name] = (params, body, line_num, global_vars)\n        return \"\\n\" * match.group(0).count(\"\\n\")\n\n    cleaned_code = function_pattern.sub(replace_function, expanded_code)\n\n    # Process global code by splitting on physical newlines.\n    global_statements: list[tuple[str, int]] = []\n    for i, line in enumerate(cleaned_code.splitlines(), start=1):\n        if line.strip():\n            global_statements.append((line.strip(), i))\n\n    # Record global assignments with line numbers.\n    global_assignments: dict[str, int] = {}\n    # current_globals holds the set of global variables defined so far (by assignment).\n    current_globals: set[str] = set()\n    postfix_tokens: list[str] = []\n\n    # Process global statements in order and check function call global dependencies.\n    for stmt, line_num in global_statements:\n        # Skip comment lines.\n        if stmt.startswith(\"#\"):\n            continue\n        # Process assignment statements.\n        if assign_pattern.search(stmt):\n            var_name, expr = stmt.split(\"=\", 1)\n            var_name = var_name.strip()\n            if var_name.startswith(\"__internal_\"):\n                raise SyntaxError(\n                    f\"Variable name '{var_name}' cannot start with '__internal_' (reserved prefix)\",\n                    line_num,\n                )\n            if is_constant(var_name):\n                raise SyntaxError(f\"Cannot assign to constant '{var_name}'.\", line_num)\n            expr = expr.strip()\n            # If the right-hand side is a function call, check that its global dependencies are defined.\n            m_call = m_call_pattern.match(expr)\n            if m_call:\n                func_name = m_call.group(1)\n                if func_name in functions:\n                    for gv in functions[func_name][3]:\n                        if gv not in current_globals:\n                            raise SyntaxError(\n                                f\"Global variable '{gv}' used in function '{func_name}' is not defined before its first call.\",\n                                line_num,\n                                func_name,\n                            )\n            # Check self-reference in definition.\n            if var_name not in current_globals and re.search(\n                r\"\\b\" + re.escape(var_name) + r\"\\b\", expr\n            ):\n                raise SyntaxError(\n                    f\"Variable '{var_name}' used before definition\", line_num\n                )\n            # Record the assignment (only record the first assignment).\n            if var_name not in global_assignments:\n                global_assignments[var_name] = line_num\n            current_globals.add(var_name)\n            postfix_expr = convert_expr(expr, current_globals, functions, line_num)\n            postfix_tokens.append(f\"{postfix_expr} {var_name}!\")\n        else:\n            # For standalone expression statements, check if they directly call a function.\n            m_call = m_call_pattern.match(stmt)\n            if m_call:\n                func_name = m_call.group(1)\n                if func_name in functions:\n                    for gv in functions[func_name][3]:\n                        if gv not in current_globals:\n                            raise SyntaxError(\n                                f\"Global variable '{gv}' used in function '{func_name}' is not defined before its first call.\",\n                                line_num,\n                                func_name,\n                            )\n            postfix_expr = convert_expr(stmt, current_globals, functions, line_num)\n            if compute_stack_effect(postfix_expr, line_num) != 0:\n                raise SyntaxError(f\"Unused global expression: {stmt}\", line_num)\n            postfix_tokens.append(postfix_expr)\n\n    # Check that all declared global variables are defined.\n    for gv, decl_line in declared_globals.items():\n        if gv not in global_assignments:\n            raise SyntaxError(\n                f\"Global variable '{gv}' declared but not defined.\", decl_line\n            )\n\n    final_result = \" \".join(postfix_tokens)\n    final_result = final_result.replace(\"(\", \"\").replace(\")\", \"\")\n    if \"RESULT!\" not in final_result:\n        raise SyntaxError(\"Final result must be assigned to variable 'RESULT!'\")\n\n    optimized = optimize_akarin_expr(final_result + \" RESULT@\")\n    return optimized\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.validate_static_relative_pixel_indices","title":"validate_static_relative_pixel_indices","text":"<pre><code>validate_static_relative_pixel_indices(expr: str, line_num: int, function_name: Optional[str] = None) -&gt; None\n</code></pre> <p>Validate that the static relative pixel access indices are numeric constants.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def validate_static_relative_pixel_indices(\n    expr: str, line_num: int, function_name: Optional[str] = None\n) -&gt; None:\n    \"\"\"\n    Validate that the static relative pixel access indices are numeric constants.\n    \"\"\"\n    static_relative_pixel_indices = rel_pattern.finditer(expr)\n    for match in static_relative_pixel_indices:\n        indices = match.group(1).split(\",\")\n        for idx in indices:\n            if not number_pattern.fullmatch(idx.strip()):\n                raise SyntaxError(\n                    f\"Static relative pixel access index must be a numeric constant, got '{idx.strip()}'\",\n                    line_num,\n                    function_name,\n                )\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.check_variable_usage","title":"check_variable_usage","text":"<pre><code>check_variable_usage(expr: str, variables: set[str], line_num: int, function_name: Optional[str] = None, local_vars: Optional[set[str]] = None) -&gt; None\n</code></pre> <p>Check that all variables in the expression have been defined. In function scope, if local_vars is provided, only local variables are checked.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def check_variable_usage(\n    expr: str,\n    variables: set[str],\n    line_num: int,\n    function_name: Optional[str] = None,\n    local_vars: Optional[set[str]] = None,\n) -&gt; None:\n    \"\"\"\n    Check that all variables in the expression have been defined.\n    In function scope, if local_vars is provided, only local variables are checked.\n    \"\"\"\n    expr = func_sub_pattern.sub(\"\", expr)\n    identifiers = identifier_pattern.finditer(expr)\n    for match in identifiers:\n        var_name = match.group(1)\n        if is_constant(var_name) or (\n            (local_vars is not None and var_name in local_vars)\n            or (local_vars is None and var_name in variables)\n        ):\n            continue\n        if var_name.startswith(\"__internal_\"):\n            func_name_extracted, orig_var = extract_function_info(\n                var_name, function_name\n            )\n            if local_vars is not None and orig_var in local_vars:\n                continue\n            raise SyntaxError(\n                f\"Variable '{orig_var}' used before definition\",\n                line_num,\n                func_name_extracted,\n            )\n        if not re.search(rf\"{re.escape(var_name)}\\s*=\", expr):\n            raise SyntaxError(\n                f\"Variable '{var_name}' used before definition\", line_num, function_name\n            )\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.convert_expr","title":"convert_expr","text":"<pre><code>convert_expr(expr: str, variables: set[str], functions: dict[str, tuple[list[str], str, int, set[str]]], line_num: int, current_function: Optional[str] = None, local_vars: Optional[set[str]] = None) -&gt; str\n</code></pre> <p>Convert a single infix expression to a postfix expression. Supports binary and unary operators, function calls, and custom function definitions.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def convert_expr(\n    expr: str,\n    variables: set[str],\n    functions: dict[str, tuple[list[str], str, int, set[str]]],\n    line_num: int,\n    current_function: Optional[str] = None,\n    local_vars: Optional[set[str]] = None,\n) -&gt; str:\n    \"\"\"\n    Convert a single infix expression to a postfix expression.\n    Supports binary and unary operators, function calls, and custom function definitions.\n    \"\"\"\n    expr = expr.strip()\n\n    m_str = m_str_pattern.match(expr)\n    if m_str:\n        args = parse_args(m_str.group(1))\n        if len(args) != 1:\n            raise SyntaxError(\n                f\"str() requires 1 arguments, but {len(args)} were provided.\",\n                line_num,\n                current_function,\n            )\n        if not valid_str_pattern.match(args[0]):\n            raise SyntaxError(\n                f\"Unsupported string content '{args[0]}'\", line_num, current_function\n            )\n        return f\"{args[0]}\"\n\n    # Check variable usage and validate static relative pixel indices.\n    check_variable_usage(expr, variables, line_num, current_function, local_vars)\n    validate_static_relative_pixel_indices(expr, line_num, current_function)\n\n    if number_pattern.match(expr):\n        return expr\n\n    constants_map = {\n        \"current_frame_number\": \"N\",\n        \"current_x\": \"X\",\n        \"current_y\": \"Y\",\n        \"current_width\": \"width\",\n        \"current_height\": \"height\",\n        \"pi\": \"pi\",\n    }\n    if expr in constants_map:\n        return constants_map[expr]\n\n    func_call_full = match_full_function_call(expr)\n    if func_call_full:\n        func_name, args_str = func_call_full\n        if func_name not in functions and not is_builtin_function(func_name):\n            raise SyntaxError(\n                f\"Undefined function '{func_name}'\", line_num, current_function\n            )\n        m_nth = nth_pattern.match(func_name)\n        if m_nth:\n            N_val = int(m_nth.group(1))\n            args = parse_args(args_str)\n            M = len(args)\n            if M &lt; N_val:\n                raise SyntaxError(\n                    f\"nth_{N_val} requires at least {N_val} arguments, but only {M} were provided.\",\n                    line_num,\n                    current_function,\n                )\n            if N_val &lt; 1:\n                raise SyntaxError(\n                    f\"nth_{N_val} is not supported!\",\n                    line_num,\n                    current_function,\n                )\n            args_postfix = [\n                convert_expr(\n                    arg, variables, functions, line_num, current_function, local_vars\n                )\n                for arg in args\n            ]\n            sort_token = f\"sort{M}\"\n            drop_before = f\"drop{N_val-1}\" if (N_val - 1) &gt; 0 else \"\"\n            drop_after = f\"drop{M-N_val}\" if (M - N_val) &gt; 0 else \"\"\n            tokens: list[str] = []\n            tokens.append(\" \".join(args_postfix))\n            tokens.append(sort_token)\n            if drop_before:\n                tokens.append(drop_before)\n            tokens.append(\"__internal_nth_tmp!\")\n            if drop_after:\n                tokens.append(drop_after)\n            tokens.append(\"__internal_nth_tmp@\")\n            return \" \".join(tokens).strip()\n\n        args = parse_args(args_str)\n        args_postfix = [\n            convert_expr(\n                arg, variables, functions, line_num, current_function, local_vars\n            )\n            for arg in args\n        ]\n\n        if func_name == \"dyn\":\n            if len(args) != 3:\n                raise SyntaxError(\n                    f\"Built-in function {func_name} requires 3 arguments, but {len(args)} were provided.\",\n                    line_num,\n                    current_function,\n                )\n            if not is_clip(args[0]):\n                raise SyntaxError(\n                    f\"{args[0]} is not a source clip.\", line_num, current_function\n                )\n            return f\"{args_postfix[1]} {args_postfix[2]} {args[0]}[]\"\n\n        if func_name == \"get_prop\":\n            if len(args) != 2:\n                raise SyntaxError(\n                    f\"Built-in function {func_name} requires 2 arguments, but {len(args)} were provided.\",\n                    line_num,\n                    current_function,\n                )\n            if not is_clip(args[0]):\n                raise SyntaxError(\n                    f\"{args[0]} is not a source clip.\", line_num, current_function\n                )\n            return f\"{args_postfix[0]}.{args_postfix[1]}\"\n\n        if func_name == \"get_prop_safe\":\n            if len(args) != 2:\n                raise SyntaxError(\n                    f\"Built-in function {func_name} requires 2 arguments, but {len(args)} were provided.\",\n                    line_num,\n                    current_function,\n                )\n            if not is_clip(args[0]):\n                raise SyntaxError(\n                    f\"{args[0]} is not a source clip.\", line_num, current_function\n                )\n            return f\"{args_postfix[0]}.{args_postfix[1]} __internal_get_prop_safe_tmp! __internal_get_prop_safe_tmp@\"  # Ensure 0 is returned if prop doesn't exist.\n\n        if func_name in [\"min\", \"max\"]:\n            if len(args) != 2:\n                raise SyntaxError(\n                    f\"Built-in function {func_name} requires 2 arguments, but {len(args)} were provided.\",\n                    line_num,\n                    current_function,\n                )\n            return f\"{args_postfix[0]} {args_postfix[1]} {func_name}\"\n        elif func_name == \"clamp\":\n            if len(args) != 3:\n                raise SyntaxError(\n                    f\"Built-in function {func_name} requires 3 arguments, but {len(args)} were provided.\",\n                    line_num,\n                    current_function,\n                )\n            return f\"{args_postfix[0]} {args_postfix[1]} {args_postfix[2]} clamp\"\n        else:\n            builtin_unary = [\n                \"sin\",\n                \"cos\",\n                \"log\",\n                \"exp\",\n                \"round\",\n                \"floor\",\n                \"abs\",\n                \"sqrt\",\n                \"trunc\",\n                \"bitnot\",\n                \"not\",\n            ]\n            if func_name in builtin_unary:\n                if len(args) != 1:\n                    raise SyntaxError(\n                        f\"Built-in function {func_name} requires 1 argument, but {len(args)} were provided.\",\n                        line_num,\n                        current_function,\n                    )\n                return f\"{args_postfix[0]} {func_name}\"\n        # Handle custom function calls.\n        if func_name in functions:\n            params, body, func_line_num, global_vars = functions[func_name]\n            if len(args) != len(params):\n                raise SyntaxError(\n                    f\"Function {func_name} requires {len(params)} parameters, but {len(args)} were provided.\",\n                    line_num,\n                    current_function,\n                )\n            # Rename parameters: __internal_&lt;funcname&gt;_&lt;varname&gt;\n            param_map = {p: f\"__internal_{func_name}_{p}\" for p in params}\n            body_lines = [line.strip() for line in body.split(\"\\n\")]\n            body_lines_strip = [\n                line.strip()\n                for line in body.split(\"\\n\")\n                if line.strip() and not line.lstrip().startswith(\"#\")\n            ]\n            return_indices = [\n                i\n                for i, line in enumerate(body_lines_strip)\n                if line.startswith(\"return\")\n            ]\n            if return_indices and return_indices[0] != len(body_lines_strip) - 1:\n                raise SyntaxError(\n                    f\"Return statement must be the last line in function '{func_name}'\",\n                    func_line_num,\n                    func_name,\n                )\n\n            local_map: dict[str, str] = {}\n            for offset, body_line in enumerate(body_lines):\n                if body_line.lstrip().startswith(\"#\"):\n                    continue\n                if body_line.startswith(\"return\"):\n                    continue\n                m_line = m_line_pattern.match(body_line)\n                if m_line:\n                    var = m_line.group(1)\n                    if var.startswith(\"__internal_\"):\n                        raise SyntaxError(\n                            f\"Variable name '{var}' cannot start with '__internal_' (reserved prefix)\",\n                            func_line_num + offset,\n                            func_name,\n                        )\n                    if is_constant(var):\n                        raise SyntaxError(\n                            f\"Cannot assign to constant '{var}'.\",\n                            func_line_num + offset,\n                            func_name,\n                        )\n                    # Only rename &amp; map local variables\n                    if (\n                        var not in param_map\n                        and not var.startswith(f\"__internal_{func_name}_\")\n                        and var not in global_vars\n                    ):\n                        local_map[var] = f\"__internal_{func_name}_{var}\"\n\n            rename_map: dict[str, str] = {}\n            rename_map.update(param_map)\n            rename_map.update(local_map)\n            new_local_vars = (\n                set(param_map.keys()).union(set(local_map.keys())).union(global_vars)\n            )\n            param_assignments: list[str] = []\n            for i, p in enumerate(params):\n                arg_orig = args[i].strip()\n                if is_constant(arg_orig):\n                    rename_map[p] = args_postfix[i]\n                else:\n                    if p not in global_vars:\n                        param_assignments.append(f\"{args_postfix[i]} {rename_map[p]}!\")\n            new_lines: list[str] = []\n            for line_text in body_lines:\n                if line_text.lstrip().startswith(\"#\"):\n                    continue\n                new_line = line_text\n                for old, new in rename_map.items():\n                    if old not in global_vars:\n                        new_line = re.sub(\n                            rf\"(?&lt;!\\w){re.escape(old)}(?!\\w)\", new, new_line\n                        )\n                new_lines.append(new_line)\n            function_tokens: list[str] = []\n            return_count = 0\n            for offset, body_line in enumerate(new_lines):\n                effective_line_num = func_line_num + offset\n                if body_line.lstrip().startswith(\"#\"):\n                    continue\n                if body_line.startswith(\n                    \"return\"\n                ):  # Return does nothing, but it looks better to have one.\n                    return_count += 1\n                    ret_expr = body_line[len(\"return\") :].strip()\n                    function_tokens.append(\n                        convert_expr(\n                            ret_expr,\n                            variables,\n                            functions,\n                            effective_line_num,\n                            func_name,\n                            new_local_vars,\n                        )\n                    )\n                # Process assignment statements.\n                elif assign_pattern.search(body_line):\n                    var_name, expr_line = body_line.split(\"=\", 1)\n                    var_name = var_name.strip()\n                    if is_constant(var_name):\n                        raise SyntaxError(\n                            f\"Cannot assign to constant '{var_name}'.\",\n                            effective_line_num,\n                            func_name,\n                        )\n                    if var_name not in new_local_vars and re.search(\n                        r\"\\b\" + re.escape(var_name) + r\"\\b\", expr_line\n                    ):\n                        _, orig_var = extract_function_info(var_name, func_name)\n                        raise SyntaxError(\n                            f\"Variable '{orig_var}' used before definition\",\n                            effective_line_num,\n                            func_name,\n                        )\n                    if var_name not in new_local_vars:\n                        new_local_vars.add(var_name)\n                    function_tokens.append(\n                        f\"{convert_expr(expr_line, variables, functions, effective_line_num, func_name, new_local_vars)} {var_name}!\"\n                    )\n                else:\n                    function_tokens.append(\n                        convert_expr(\n                            body_line,\n                            variables,\n                            functions,\n                            effective_line_num,\n                            func_name,\n                            new_local_vars,\n                        )\n                    )\n            if return_count == 0 or return_count &gt; 1:\n                raise SyntaxError(\n                    f\"Function {func_name} must return exactly one value, got {return_count}\",\n                    func_line_num,\n                    func_name,\n                )\n            result_expr = \" \".join(param_assignments + function_tokens)\n            net_effect = compute_stack_effect(result_expr, line_num, func_name)\n            if net_effect != 1:\n                raise SyntaxError(\n                    f\"The return value stack of function {func_name} is unbalanced; expected 1 but got {net_effect}.\",\n                    func_line_num,\n                    func_name,\n                )\n            return result_expr\n\n    stripped = strip_outer_parentheses(expr)\n    if stripped != expr:\n        return convert_expr(\n            stripped, variables, functions, line_num, current_function, local_vars\n        )\n\n    m_static = m_static_pattern.match(expr)\n    if m_static:\n        clip = m_static.group(1)\n        statX = m_static.group(2)\n        statY = m_static.group(3)\n        suffix = m_static.group(4) or \"\"\n        if not is_clip(clip):\n            raise SyntaxError(f\"'{clip}' is not a clip!\", line_num, current_function)\n        try:\n            int(statX)\n            int(statY)\n        except ValueError:\n            raise SyntaxError(\n                f\"Static relative pixel access indices must be integers, got '[{statX},{statY}]'\",\n                line_num,\n                current_function,\n            )\n        return f\"{clip}[{statX},{statY}]{suffix}\"\n\n    ternary_parts = parse_ternary(expr, line_num, current_function)\n    if ternary_parts is not None:\n        cond, true_expr, false_expr = ternary_parts\n        cond_conv = convert_expr(\n            cond, variables, functions, line_num, current_function, local_vars\n        )\n        true_conv = convert_expr(\n            true_expr, variables, functions, line_num, current_function, local_vars\n        )\n        false_conv = convert_expr(\n            false_expr, variables, functions, line_num, current_function, local_vars\n        )\n        return f\"{cond_conv} {true_conv} {false_conv} ?\"\n\n    operators = [\n        (\"||\", \"or\"),\n        (\"&amp;&amp;\", \"and\"),\n        (\"|\", \"bitor\"),\n        (\"^\", \"bitxor\"),\n        (\"&amp;\", \"bitand\"),\n        (\"&lt;\", \"&lt;\"),\n        (\"&lt;=\", \"&lt;=\"),\n        (\"&gt;\", \"&gt;\"),\n        (\"&gt;=\", \"&gt;=\"),\n        (\"==\", \"=\"),\n        (\"!=\", \"!=\"),\n        (\"+\", \"+\"),\n        (\"-\", \"-\"),\n        (\"*\", \"*\"),\n        (\"/\", \"/\"),\n        (\"%\", \"%\"),\n        (\"**\", \"pow\"),\n    ]\n    for op_str, postfix_op in operators:\n        left, right = find_binary_op(expr, op_str)\n        if left is not None and right is not None:\n            left_postfix = convert_expr(\n                left, variables, functions, line_num, current_function, local_vars\n            )\n            right_postfix = convert_expr(\n                right, variables, functions, line_num, current_function, local_vars\n            )\n            if letter_pattern.fullmatch(\n                left.strip()\n            ) and not left_postfix.strip().endswith(\"@\"):\n                left_postfix = left_postfix.strip() + (\n                    \"@\" if not is_constant(left_postfix) else \"\"\n                )\n            if letter_pattern.fullmatch(\n                right.strip()\n            ) and not right_postfix.strip().endswith(\"@\"):\n                right_postfix = right_postfix.strip() + (\n                    \"@\" if not is_constant(right_postfix) else \"\"\n                )\n            return f\"{left_postfix} {right_postfix} {postfix_op}\"\n\n    if expr.startswith(\"!\"):\n        operand = convert_expr(\n            expr[1:], variables, functions, line_num, current_function, local_vars\n        )\n        return f\"{operand} not\"\n\n    if expr.startswith(\"-\"):\n        operand = convert_expr(\n            expr[1:], variables, functions, line_num, current_function, local_vars\n        )\n        return f\"{operand} -1 *\"\n\n    if is_constant(expr):\n        return expr\n    if letter_pattern.fullmatch(expr):\n        return expr if expr.endswith(\"@\") else expr + \"@\"\n\n    return expr\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.find_binary_op","title":"find_binary_op","text":"<pre><code>find_binary_op(expr: str, op: str)\n</code></pre> <p>Find the last occurrence of the binary operator op at the outer level and return the left and right parts.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def find_binary_op(expr: str, op: str):\n    \"\"\"\n    Find the last occurrence of the binary operator op at the outer level and return the left and right parts.\n    \"\"\"\n    if not op:\n        return None, None\n\n    prefix = [0] * len(op)\n    j = 0\n    for i in range(1, len(op)):\n        while j &gt; 0 and op[i] != op[j]:\n            j = prefix[j - 1]\n        if op[i] == op[j]:\n            j += 1\n            prefix[i] = j\n\n    candidate_index = -1\n    level = 0\n    kmp_state = 0\n    levels = [0] * len(expr)\n\n    for i, c in enumerate(expr):\n        if c == \"(\":\n            level += 1\n        elif c == \")\":\n            level -= 1\n        levels[i] = level\n\n        while kmp_state &gt; 0 and c != op[kmp_state]:\n            kmp_state = prefix[kmp_state - 1]\n        if c == op[kmp_state]:\n            kmp_state += 1\n\n        if kmp_state == len(op):\n            candidate = i - len(op) + 1\n            if levels[candidate] == 0:\n                left_valid = (candidate == 0) or (expr[candidate - 1] in \" (,\\t\")\n                after = candidate + len(op)\n                right_valid = (after == len(expr)) or (expr[after] in \" )\\t,\")\n                if left_valid and right_valid:\n                    candidate_index = candidate\n            kmp_state = prefix[kmp_state - 1]\n\n    if candidate_index == -1:\n        return None, None\n\n    left = expr[:candidate_index].strip()\n    right = expr[candidate_index + len(op) :].strip()\n    return left, right\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.parse_args","title":"parse_args","text":"<pre><code>parse_args(args_str: str) -&gt; list[str]\n</code></pre> <p>Parse the arguments of a function call.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def parse_args(args_str: str) -&gt; list[str]:\n    \"\"\"\n    Parse the arguments of a function call.\n    \"\"\"\n    args: list[str] = []\n    current: list[str] = []\n    bracket_depth = 0\n    square_bracket_depth = 0\n    for c in args_str + \",\":\n        if c == \",\" and bracket_depth == 0 and square_bracket_depth == 0:\n            args.append(\"\".join(current).strip())\n            current = []\n        else:\n            current.append(c)\n            if c == \"(\":\n                bracket_depth += 1\n            elif c == \")\":\n                bracket_depth -= 1\n            elif c == \"[\":\n                square_bracket_depth += 1\n            elif c == \"]\":\n                square_bracket_depth -= 1\n    return [arg for arg in args if arg]\n</code></pre>"},{"location":"API/expr/infix2postfix/#y5gfunc.expr.infix2postfix.is_builtin_function","title":"is_builtin_function","text":"<pre><code>is_builtin_function(func_name: str) -&gt; bool\n</code></pre> <p>Check if the function name belongs to a built-in function.</p> Source code in <code>y5gfunc/expr/infix2postfix.py</code> <pre><code>def is_builtin_function(func_name: str) -&gt; bool:\n    \"\"\"\n    Check if the function name belongs to a built-in function.\n    \"\"\"\n    builtin_unary = [\n        \"sin\",\n        \"cos\",\n        \"log\",\n        \"exp\",\n        \"round\",\n        \"floor\",\n        \"abs\",\n        \"sqrt\",\n        \"trunc\",\n        \"bitnot\",\n        \"not\",\n        \"str\",\n    ]\n    builtin_binary = [\"min\", \"max\", \"get_prop\", \"get_prop_safe\"]\n    builtin_ternary = [\"clamp\", \"dyn\"]\n    if any(r.match(func_name) for r in build_in_func_patterns):\n        return True\n    return (\n        func_name in builtin_unary\n        or func_name in builtin_binary\n        or func_name in builtin_ternary\n    )\n</code></pre>"},{"location":"API/expr/optimize/","title":"<code>y5gfunc.expr.optimize</code>","text":""},{"location":"API/expr/optimize/#y5gfunc.expr.optimize","title":"optimize","text":"<p>Functions:</p> Name Description <code>is_token_numeric</code> <p>Check if a token string represents a numeric constant.</p> <code>optimize_akarin_expr</code> <p>Optimize akarin.Expr expressions:</p> <code>tokenize_expr</code> <p>Convert expression string to a list of tokens</p> <code>parse_numeric</code> <p>Parse a numeric token string to its actual value (int or float).</p> <code>calculate_unary</code> <p>Calculate result of unary operation</p> <code>calculate_binary</code> <p>Calculate result of binary operation</p> <code>calculate_ternary</code> <p>Calculate result of ternary operation</p> <code>format_number</code> <p>Format number back to string representation for expression (more robust).</p> <code>fold_constants</code> <p>Perform constant folding optimization</p> <code>convert_dynamic_to_static</code> <p>Convert dynamic pixel access to static when possible</p> <p>Attributes:</p> Name Type Description <code>token_pattern</code> <code>split_pattern</code> <code>number_patterns</code> <code>hex_pattern</code> <code>hex_parts_pattern</code> <code>octal_pattern</code>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.token_pattern","title":"token_pattern  <code>module-attribute</code>","text":"<pre><code>token_pattern = compile('(\\\\w+)\\\\[\\\\s*(-?\\\\d+)\\\\s*,\\\\s*(-?\\\\d+)\\\\s*\\\\](?::(?:c|m))?')\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.split_pattern","title":"split_pattern  <code>module-attribute</code>","text":"<pre><code>split_pattern = compile('\\\\s+')\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.number_patterns","title":"number_patterns  <code>module-attribute</code>","text":"<pre><code>number_patterns = [compile(pattern) for pattern in ['^0x[0-9A-Fa-f]+(\\\\.[0-9A-Fa-f]+(p[+\\\\-]?\\\\d+)?)?$', '^0[0-7]+$', '^[+\\\\-]?(\\\\d+(\\\\.\\\\d+)?([eE][+\\\\-]?\\\\d+)?)$']]\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.hex_pattern","title":"hex_pattern  <code>module-attribute</code>","text":"<pre><code>hex_pattern = compile('^0x')\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.hex_parts_pattern","title":"hex_parts_pattern  <code>module-attribute</code>","text":"<pre><code>hex_parts_pattern = compile('^(0x[0-9A-Fa-f]+)(?:\\\\.([0-9A-Fa-f]+))?(?:p([+\\\\-]?\\\\d+))?$')\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.octal_pattern","title":"octal_pattern  <code>module-attribute</code>","text":"<pre><code>octal_pattern = compile('^0[0-7]')\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.is_token_numeric","title":"is_token_numeric","text":"<pre><code>is_token_numeric(token: str) -&gt; bool\n</code></pre> <p>Check if a token string represents a numeric constant.</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def is_token_numeric(token: str) -&gt; bool:\n    \"\"\"Check if a token string represents a numeric constant.\"\"\"\n    if token.isdigit() or (\n        token.startswith(\"-\") and len(token) &gt; 1 and token[1:].isdigit()\n    ):\n        return True\n\n    for pattern in number_patterns:\n        if pattern.match(token):\n            return True\n    return False\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.optimize_akarin_expr","title":"optimize_akarin_expr","text":"<pre><code>optimize_akarin_expr(expr: str) -&gt; str\n</code></pre> <p>Optimize akarin.Expr expressions: 1. Constant folding 2. Convert dynamic pixel access to static when possible</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Input expr.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Optimized expr.</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def optimize_akarin_expr(expr: str) -&gt; str:\n    \"\"\"\n    Optimize akarin.Expr expressions:\n    1. Constant folding\n    2. Convert dynamic pixel access to static when possible\n\n    Args:\n        expr: Input expr.\n\n    Returns:\n        Optimized expr.\n    \"\"\"\n    # Initial expression preprocessing\n    expr = expr.strip()\n    if not expr:\n        return expr\n\n    # Multi-round constant folding until no further optimization is possible\n    prev_expr = None\n    current_expr = expr\n\n    while prev_expr != current_expr:\n        prev_expr = current_expr\n        current_expr = fold_constants(current_expr)\n\n    # Dynamic to static pixel access conversion\n    optimized_expr = convert_dynamic_to_static(current_expr)\n\n    return optimized_expr\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.optimize_akarin_expr(expr)","title":"<code>expr</code>","text":""},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.tokenize_expr","title":"tokenize_expr","text":"<pre><code>tokenize_expr(expr: str) -&gt; list[str]\n</code></pre> <p>Convert expression string to a list of tokens</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def tokenize_expr(expr: str) -&gt; list[str]:\n    \"\"\"Convert expression string to a list of tokens\"\"\"\n    expr = expr.strip()\n    if not expr:\n        return []\n    # Use placeholders for pixel access to prevent splitting inside brackets\n    placeholders = {}\n    placeholder_prefix = \"__PXACCESS\"\n    placeholder_suffix = \"__\"\n    count = 0\n\n    def repl(matchobj):\n        nonlocal count\n        key = f\"{placeholder_prefix}{count}{placeholder_suffix}\"\n        placeholders[key] = matchobj.group(0)  # Store the original full match\n        count += 1\n        return key\n\n    expr_with_placeholders = token_pattern.sub(repl, expr)\n\n    # Split by whitespace\n    raw_tokens = split_pattern.split(expr_with_placeholders)\n\n    # Restore placeholders and filter empty tokens\n    tokens = []\n    for token in raw_tokens:\n        if token in placeholders:\n            tokens.append(placeholders[token])\n        elif token:  # Filter out empty strings resulting from multiple spaces\n            tokens.append(token)\n\n    return tokens\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.parse_numeric","title":"parse_numeric","text":"<pre><code>parse_numeric(token: str) -&gt; Union[int, float]\n</code></pre> <p>Parse a numeric token string to its actual value (int or float).</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def parse_numeric(token: str) -&gt; Union[int, float]:\n    \"\"\"Parse a numeric token string to its actual value (int or float).\"\"\"\n    if not is_token_numeric(token):\n        raise ValueError(f\"Token '{token}' is not a valid numeric format for parsing.\")\n\n    if hex_pattern.match(token):  # Hexadecimal\n        if \".\" in token or \"p\" in token.lower():\n            # Attempt parsing hex float\n            try:\n                return float.fromhex(token)\n            except ValueError:\n                # Fallback for complex hex patterns if fromhex fails (though less likely needed now)\n                parts = hex_parts_pattern.match(token.lower())\n                if parts:\n                    integer_part = int(parts.group(1), 16)\n                    fractional_part = 0\n                    if parts.group(2):\n                        frac_hex = parts.group(2)\n                        fractional_part = int(frac_hex, 16) / (16 ** len(frac_hex))\n                    exponent = 0\n                    if parts.group(3):\n                        exponent = int(parts.group(3))\n                    return (integer_part + fractional_part) * (2**exponent)\n                else:\n                    raise ValueError(\n                        f\"Could not parse complex hex token: {token}\"\n                    )  # Should not happen\n        else:\n            return int(token, 16)  # Simple hex integer\n    elif (\n        octal_pattern.match(token)\n        and len(token) &gt; 1\n        and all(c in \"01234567\" for c in token[1:])\n    ):  # Octal\n        return int(token, 8)\n    else:  # Decimal / Scientific / Integer\n        try:\n            if \".\" in token or \"e\" in token.lower():\n                return float(token)\n            return int(token)\n        except ValueError:\n            # This should not be reached if is_token_numeric passed\n            raise ValueError(\n                f\"Internal error: Could not parse supposedly numeric token: {token}\"\n            )\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.calculate_unary","title":"calculate_unary","text":"<pre><code>calculate_unary(op: str, a: Union[int, float]) -&gt; Optional[Union[int, float]]\n</code></pre> <p>Calculate result of unary operation</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def calculate_unary(op: str, a: Union[int, float]) -&gt; Optional[Union[int, float]]:\n    \"\"\"Calculate result of unary operation\"\"\"\n    operators = {\n        \"exp\": math.exp,\n        \"log\": math.log,\n        \"sqrt\": math.sqrt,\n        \"sin\": math.sin,\n        \"cos\": math.cos,\n        \"abs\": abs,\n        \"not\": lambda x: 0.0 if float(x) &gt; 0.0 else 1.0,\n        \"bitnot\": lambda x: ~int(x),  # Integer specific\n        \"trunc\": math.trunc,  # Returns int\n        \"round\": round,  # Returns int if possible\n        \"floor\": math.floor,  # Returns float\n    }\n    if op not in operators:\n        return None\n\n    try:\n        arg = a\n        # Ensure correct type for the operation\n        if op in [\"exp\", \"log\", \"sqrt\", \"sin\", \"cos\", \"not\", \"floor\"]:\n            arg = float(a)\n        elif op == \"bitnot\":\n            # Check if float is actually an integer before converting\n            if isinstance(a, float):\n                if not a.is_integer():\n                    return None  # Cannot bitwise-not a non-integer float\n                arg = int(a)\n            else:  # Already int\n                arg = int(a)\n        # For abs, trunc, round, Python handles int/float input okay\n\n        result = operators[op](arg)\n\n        # Attempt to return int if result is numerically an integer where appropriate\n        if (\n            isinstance(result, float)\n            and result.is_integer()\n            and op in [\"abs\", \"trunc\", \"round\", \"floor\", \"bitnot\"]\n        ):\n            return int(result)\n        return result\n    except (ValueError, OverflowError, TypeError):\n        return None\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.calculate_binary","title":"calculate_binary","text":"<pre><code>calculate_binary(op: str, a: Union[int, float], b: Union[int, float]) -&gt; Optional[Union[int, float]]\n</code></pre> <p>Calculate result of binary operation</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def calculate_binary(\n    op: str, a: Union[int, float], b: Union[int, float]\n) -&gt; Optional[Union[int, float]]:\n    \"\"\"Calculate result of binary operation\"\"\"\n    operators = {\n        \"+\": lambda x, y: x + y,\n        \"-\": lambda x, y: x - y,\n        \"*\": lambda x, y: x * y,\n        \"/\": lambda x, y: float(x) / float(y) if float(y) != 0 else None,\n        \"max\": max,\n        \"min\": min,\n        \"pow\": lambda x, y: pow(float(x), float(y)),\n        \"**\": lambda x, y: pow(float(x), float(y)),\n        \"&gt;\": lambda x, y: 1.0 if float(x) &gt; float(y) else 0.0,\n        \"&lt;\": lambda x, y: 1.0 if float(x) &lt; float(y) else 0.0,\n        \"=\": lambda x, y: 1.0 if float(x) == float(y) else 0.0,\n        \"&gt;=\": lambda x, y: 1.0 if float(x) &gt;= float(y) else 0.0,\n        \"&lt;=\": lambda x, y: 1.0 if float(x) &lt;= float(y) else 0.0,\n        \"and\": lambda x, y: 1.0 if float(x) &gt; 0 and float(y) &gt; 0 else 0.0,\n        \"or\": lambda x, y: 1.0 if float(x) &gt; 0 or float(y) &gt; 0 else 0.0,\n        \"xor\": lambda x, y: 1.0 if (float(x) &gt; 0) != (float(y) &gt; 0) else 0.0,\n        \"%\": lambda x, y: x % y if y != 0 else None,\n        \"bitand\": lambda x, y: int(x) &amp; int(y),\n        \"bitor\": lambda x, y: int(x) | int(y),\n        \"bitxor\": lambda x, y: int(x) ^ int(y),\n    }\n    if op not in operators:\n        return None\n\n    try:\n        arg1, arg2 = a, b\n        # Ensure correct types for specific operations\n        if op.startswith(\"bit\") or op == \"%\":\n            # Check if floats are integers before converting\n            f_args = []\n            for v in [a, b]:\n                if isinstance(v, float):\n                    if not v.is_integer():\n                        return None  # Cannot operate on non-integer float\n                    f_args.append(int(v))\n                else:\n                    f_args.append(int(v))\n            arg1, arg2 = f_args[0], f_args[1]\n            if (op == \"%\" or op == \"/\") and arg2 == 0:\n                return None  # check zero division\n        elif op in [\n            \"&gt;\",\n            \"&lt;\",\n            \"=\",\n            \"&gt;=\",\n            \"&lt;=\",\n            \"and\",\n            \"or\",\n            \"xor\",\n        ]:  # Comparisons use float logic\n            arg1, arg2 = float(a), float(b)\n\n        result = operators[op](arg1, arg2)\n        if result is None:\n            return None\n\n        # Attempt int conversion for appropriate ops if result is integer\n        if (\n            isinstance(result, float)\n            and result.is_integer()\n            and op in [\"+\", \"-\", \"*\", \"%\", \"max\", \"min\", \"bitand\", \"bitor\", \"bitxor\"]\n        ):\n            return int(result)\n        # Boolean results are always float 1.0/0.0\n        return result\n    except (ZeroDivisionError, ValueError, OverflowError, TypeError):\n        return None\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.calculate_ternary","title":"calculate_ternary","text":"<pre><code>calculate_ternary(cond: Union[int, float], true_val: Union[int, float], false_val: Union[int, float]) -&gt; Union[int, float]\n</code></pre> <p>Calculate result of ternary operation</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def calculate_ternary(\n    cond: Union[int, float], true_val: Union[int, float], false_val: Union[int, float]\n) -&gt; Union[int, float]:\n    \"\"\"Calculate result of ternary operation\"\"\"\n    return true_val if float(cond) &gt; 0 else false_val\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.format_number","title":"format_number","text":"<pre><code>format_number(num: Union[int, float]) -&gt; str\n</code></pre> <p>Format number back to string representation for expression (more robust).</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def format_number(num: Union[int, float]) -&gt; str:\n    \"\"\"Format number back to string representation for expression (more robust).\"\"\"\n    if isinstance(num, int):\n        return str(num)\n    elif isinstance(num, float):\n        formatted = f\"{num:g}\"\n\n        if \"E\" in formatted:\n            formatted = formatted.replace(\"E\", \"e\")\n\n        return formatted\n    else:\n        # Should not happen\n        return str(num)  # Fallback\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.fold_constants","title":"fold_constants","text":"<pre><code>fold_constants(expr: str) -&gt; str\n</code></pre> <p>Perform constant folding optimization</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def fold_constants(expr: str) -&gt; str:\n    \"\"\"Perform constant folding optimization\"\"\"\n    tokens = tokenize_expr(expr)\n    # stack stores actual values (numbers) or None for non-constants/unknowns during evaluation\n    stack: list[Any] = []\n    # result_tokens stores the list of tokens for the potentially optimized expression\n    result_tokens: list[str] = []\n    # Tracks known constant variable values *during this pass*\n    variable_values: dict[str, Union[int, float, None]] = {}  # Reset each pass\n\n    i = 0\n    while i &lt; len(tokens):\n        token = tokens[i]\n\n        # 1. Handle Numeric Constants\n        if is_token_numeric(token):\n            try:\n                value = parse_numeric(token)\n                stack.append(value)\n                result_tokens.append(token)  # Append the original token string\n            except ValueError:\n                # Should not happen\n                stack.append(None)  # Treat as unknown if parsing fails\n                result_tokens.append(token)\n            i += 1\n            continue\n\n        # 2. Handle Variable Store (!)\n        # Store consumes one value from stack, updates variable map, adds '!' token.\n        is_store = (\n            token.endswith(\"!\")\n            and len(token) &gt; 1\n            and not token.startswith(\"[\")\n            and not token_pattern.match(token)\n        )\n        if is_store:\n            var_name = token[:-1]\n            if not stack:\n                raise ValueError(f\"Stack underflow at store '{token}'\")\n\n            value_to_store = stack.pop()  # Get value from evaluation stack\n            # Store value (or None) associated with var_name for this pass\n            variable_values[var_name] = (\n                value_to_store if isinstance(value_to_store, (int, float)) else None\n            )\n\n            # Store operation only adds its own token. It doesn't remove the token\n            # corresponding to the value popped from the stack. That token remains.\n            result_tokens.append(token)\n            i += 1\n            continue\n\n        # 3. Handle Variable Load (@)\n        # Load checks variable map. If constant, pushes value to stack and adds value token.\n        # If not constant, pushes None to stack and adds '@' token.\n        is_load = (\n            token.endswith(\"@\")\n            and len(token) &gt; 1\n            and not token.startswith(\"[\")\n            and not token_pattern.match(token)\n        )\n        if is_load:\n            var_name = token[:-1]\n            constant_value = variable_values.get(\n                var_name\n            )  # Check if known constant in this pass\n\n            if isinstance(constant_value, (int, float)):\n                stack.append(constant_value)\n                # Replace the load token (@) with the constant value's token string\n                result_tokens.append(format_number(constant_value))\n            else:\n                # Variable value not known or not constant, result is unknown\n                stack.append(None)\n                result_tokens.append(token)  # Keep the original load token 'x@'\n            i += 1\n            continue\n\n        # --- Operator Folding ---\n        # General strategy: Check stack values AND corresponding result tokens.\n\n        # 4. Handle Unary Operators\n        unary_ops = {\n            \"exp\",\n            \"log\",\n            \"sqrt\",\n            \"sin\",\n            \"cos\",\n            \"abs\",\n            \"not\",\n            \"bitnot\",\n            \"trunc\",\n            \"round\",\n            \"floor\",\n        }\n        if token in unary_ops:\n            can_fold = False\n            if stack and result_tokens:  # Need operand on stack and its token in result\n                op1_stack_val = stack[-1]\n                op1_token = result_tokens[-1]\n\n                # Check if stack value is number AND token is numeric string\n                if isinstance(op1_stack_val, (int, float)) and is_token_numeric(\n                    op1_token\n                ):\n                    result = calculate_unary(token, op1_stack_val)\n                    if result is not None:\n                        # Folded successfully! Update stack and result_tokens.\n                        stack.pop()\n                        stack.append(result)\n                        result_tokens.pop()  # Remove operand token\n                        result_tokens.append(\n                            format_number(result)\n                        )  # Append result token\n                        can_fold = True\n\n            if not can_fold:\n                # Cannot fold: Pop stack operand (if any), push None, append operator token.\n                if stack:\n                    stack.pop()  # Consume the operand value from stack\n                stack.append(None)  # Result is unknown\n                result_tokens.append(token)  # Keep the operator token\n\n            i += 1\n            continue\n\n        # 5. Handle Binary Operators\n        BINARY_OPS = {\n            \"+\",\n            \"-\",\n            \"*\",\n            \"/\",\n            \"max\",\n            \"min\",\n            \"pow\",\n            \"**\",\n            \"&gt;\",\n            \"&lt;\",\n            \"=\",\n            \"&gt;=\",\n            \"&lt;=\",\n            \"and\",\n            \"or\",\n            \"xor\",\n            \"%\",\n            \"bitand\",\n            \"bitor\",\n            \"bitxor\",\n        }\n        if token in BINARY_OPS:\n            can_fold = False\n            if len(stack) &gt;= 2 and len(result_tokens) &gt;= 2:\n                op2_stack_val = stack[-1]\n                op1_stack_val = stack[-2]\n                op2_token = result_tokens[-1]\n                op1_token = result_tokens[-2]\n\n                # Check stack values AND tokens\n                if (\n                    isinstance(op1_stack_val, (int, float))\n                    and isinstance(op2_stack_val, (int, float))\n                    and is_token_numeric(op1_token)\n                    and is_token_numeric(op2_token)\n                ):\n                    result = calculate_binary(token, op1_stack_val, op2_stack_val)\n                    if result is not None:\n                        # Folded successfully!\n                        stack.pop()\n                        stack.pop()\n                        stack.append(result)\n                        result_tokens.pop()\n                        result_tokens.pop()  # Remove operand tokens\n                        result_tokens.append(\n                            format_number(result)\n                        )  # Append result token\n                        can_fold = True\n\n            if not can_fold:\n                # Cannot fold: Pop stack operands (if any), push None, append operator token.\n                if len(stack) &gt;= 2:\n                    stack.pop()\n                    stack.pop()\n                elif len(stack) == 1:\n                    stack.pop()\n                stack.append(None)  # Result is unknown\n                result_tokens.append(token)  # Keep the operator token\n\n            i += 1\n            continue\n\n        # 6. Handle Ternary Operator (?)\n        if token == \"?\":\n            can_fold = False\n            if len(stack) &gt;= 3 and len(result_tokens) &gt;= 3:\n                false_val_stack = stack[-1]\n                true_val_stack = stack[-2]\n                cond_stack = stack[-3]\n                false_token = result_tokens[-1]\n                true_token = result_tokens[-2]\n                cond_token = result_tokens[-3]\n\n                # Check stack values AND tokens\n                if (\n                    isinstance(cond_stack, (int, float))\n                    and isinstance(true_val_stack, (int, float))\n                    and isinstance(false_val_stack, (int, float))\n                    and is_token_numeric(cond_token)\n                    and is_token_numeric(true_token)\n                    and is_token_numeric(false_token)\n                ):\n                    # Note: calculate_ternary itself doesn't fail easily if inputs are numbers\n                    result = calculate_ternary(\n                        cond_stack, true_val_stack, false_val_stack\n                    )\n                    # Folded successfully!\n                    stack.pop()\n                    stack.pop()\n                    stack.pop()\n                    stack.append(result)\n                    result_tokens.pop()\n                    result_tokens.pop()\n                    result_tokens.pop()  # Remove operand tokens\n                    result_tokens.append(format_number(result))  # Append result token\n                    can_fold = True\n\n            if not can_fold:\n                # Cannot fold\n                if len(stack) &gt;= 3:\n                    stack.pop()\n                    stack.pop()\n                    stack.pop()\n                elif len(stack) == 2:\n                    stack.pop()\n                    stack.pop()\n                elif len(stack) == 1:\n                    stack.pop()\n                stack.append(None)\n                result_tokens.append(token)\n            i += 1\n            continue\n\n        # 7. Handle clamp/clip operators\n        if token in {\"clamp\", \"clip\"}:\n            can_fold = False\n            if len(stack) &gt;= 3 and len(result_tokens) &gt;= 3:\n                max_val_stack = stack[-1]\n                min_val_stack = stack[-2]\n                value_val_stack = stack[-3]\n                max_token = result_tokens[-1]\n                min_token = result_tokens[-2]\n                value_token = result_tokens[-3]\n\n                if (\n                    isinstance(value_val_stack, (int, float))\n                    and isinstance(min_val_stack, (int, float))\n                    and isinstance(max_val_stack, (int, float))\n                    and is_token_numeric(value_token)\n                    and is_token_numeric(min_token)\n                    and is_token_numeric(max_token)\n                ):\n                    min_v = min(min_val_stack, max_val_stack)\n                    max_v = max(min_val_stack, max_val_stack)\n                    # Clamp logic assumes value_val_stack is the value to clamp\n                    result = max(min_v, min(max_v, value_val_stack))\n\n                    stack.pop()\n                    stack.pop()\n                    stack.pop()\n                    stack.append(result)\n                    result_tokens.pop()\n                    result_tokens.pop()\n                    result_tokens.pop()\n                    result_tokens.append(format_number(result))\n                    can_fold = True\n\n            if not can_fold:\n                if len(stack) &gt;= 3:\n                    stack.pop()\n                    stack.pop()\n                    stack.pop()\n                elif len(stack) == 2:\n                    stack.pop()\n                    stack.pop()\n                elif len(stack) == 1:\n                    stack.pop()\n                stack.append(None)\n                result_tokens.append(token)\n\n            i += 1\n            continue\n\n        # --- Stack Manipulation Ops (No Folding, Just Stack Simulation and Token Append) ---\n        # These ops inherently prevent folding across them because they add non-numeric tokens.\n\n        # 8. Handle swapN\n        if token.startswith(\"swap\"):\n            n = 1\n            if len(token) &gt; 4:\n                try:\n                    n = int(token[4:])\n                except ValueError:\n                    pass  # Treat as unknown token if N is invalid\n            if n &lt; 0:\n                raise ValueError(\"Swap count cannot be negative\")\n\n            if len(stack) &lt;= n:\n                raise ValueError(f\"Stack underflow for {token}\")\n\n            if n &gt; 0:  # Simulate swap on evaluation stack\n                stack[-1], stack[-(n + 1)] = stack[-(n + 1)], stack[-1]\n            # Always keep the token\n            result_tokens.append(token)\n            i += 1\n            continue\n\n        # 9. Handle dupN\n        if token.startswith(\"dup\"):\n            n = 0\n            if len(token) &gt; 3:\n                try:\n                    n = int(token[3:])\n                except ValueError:\n                    pass\n            if n &lt; 0:\n                raise ValueError(\"Dup index cannot be negative\")\n\n            if len(stack) &lt;= n:\n                raise ValueError(f\"Stack underflow for {token}\")\n            # Simulate dup on evaluation stack\n            stack.append(stack[-(n + 1)])\n            # Always keep the token\n            result_tokens.append(token)\n            i += 1\n            continue\n\n        # 10. Handle dropN\n        if token.startswith(\"drop\"):\n            n = 1\n            if len(token) &gt; 4:\n                try:\n                    n = int(token[4:])\n                except ValueError:\n                    pass\n            if n &lt; 0:\n                raise ValueError(\"Drop count cannot be negative\")\n            if n == 0:  # drop0 is no-op, just keep token\n                pass\n            elif len(stack) &lt; n:\n                raise ValueError(f\"Stack underflow for {token}\")\n            else:  # Simulate drop on evaluation stack\n                del stack[-n:]\n            # Always keep the token\n            result_tokens.append(token)\n            i += 1\n            continue\n\n        # 11. Handle sortN\n        if token.startswith(\"sort\"):\n            n = 0\n            if len(token) &gt; 4:\n                try:\n                    n = int(token[4:])\n                except ValueError:\n                    pass\n            if n &lt;= 0:\n                raise ValueError(\"Sort count must be positive\")\n            if len(stack) &lt; n:\n                raise ValueError(f\"Stack underflow for {token}\")\n            # Simulate sort effect: Removes N items, pushes N unknown results\n            del stack[-n:]\n            for _ in range(n):\n                stack.append(None)\n            # Always keep the token\n            result_tokens.append(token)\n            i += 1\n            continue\n\n        # --- Pixel Access (Treated as Non-foldable Operations) ---\n\n        # 12. Handle Dynamic Access like `clip[]`\n        # Consumes 2 stack items (coords), pushes None, keeps token.\n        is_dynamic_access = (\n            token.endswith(\"[]\")\n            and len(token) &gt; 2\n            and not token.startswith(\"[\")\n            and not token_pattern.match(token)\n            and not is_token_numeric(token)\n        )  # Heuristic check\n        if is_dynamic_access:\n            if len(stack) &lt; 2:\n                raise ValueError(f\"Stack underflow for dynamic access '{token}'\")\n            stack.pop()\n            stack.pop()  # Consume y, x coords from stack\n            stack.append(None)  # Result is unknown\n            result_tokens.append(token)  # Keep the token\n            i += 1\n            continue\n\n        # 13. Handle Static Access like `clip[1,2]`\n        # Pushes None, keeps token.\n        match = token_pattern.match(token)\n        if match:\n            stack.append(None)  # Result is unknown during folding pass\n            result_tokens.append(token)  # Keep the token\n            i += 1\n            continue\n\n        # Default: Unknown/Other Tokens\n        # Assume it pushes one unknown result onto the stack and keep the token.\n        # This includes unrecognized functions, malformed tokens, etc.\n        stack.append(None)\n        result_tokens.append(token)\n        i += 1\n\n    return \" \".join(result_tokens)\n</code></pre>"},{"location":"API/expr/optimize/#y5gfunc.expr.optimize.convert_dynamic_to_static","title":"convert_dynamic_to_static","text":"<pre><code>convert_dynamic_to_static(expr: str) -&gt; str\n</code></pre> <p>Convert dynamic pixel access to static when possible</p> Source code in <code>y5gfunc/expr/optimize.py</code> <pre><code>def convert_dynamic_to_static(expr: str) -&gt; str:\n    \"\"\"Convert dynamic pixel access to static when possible\"\"\"\n    tokens = tokenize_expr(expr)  # Re-tokenize the folded expression\n    if not tokens:\n        return \"\"\n\n    result_tokens = []\n    i = 0\n    while i &lt; len(tokens):\n        token = tokens[i]\n        converted = False\n\n        # Check for dynamic pixel access pattern (clip[])\n        is_dynamic_access = (\n            token.endswith(\"[]\")\n            and len(token) &gt; 2\n            and not token.startswith(\"[\")\n            and not token_pattern.match(token)\n            and not is_token_numeric(token)\n        )  # Heuristic check\n\n        if is_dynamic_access and len(result_tokens) &gt;= 2:\n            # Check if the last two tokens in the result list being built are integer constants\n            # TODO: convert float to int; need to check akarin.Expr code\n            y_token = result_tokens[-1]\n            x_token = result_tokens[-2]\n\n            if is_token_numeric(x_token) and is_token_numeric(y_token):\n                try:\n                    y_val = parse_numeric(y_token)\n                    x_val = parse_numeric(x_token)\n\n                    # Check if they are effectively integers\n                    is_x_int = isinstance(x_val, int) or (\n                        isinstance(x_val, float) and x_val.is_integer()\n                    )\n                    is_y_int = isinstance(y_val, int) or (\n                        isinstance(y_val, float) and y_val.is_integer()\n                    )\n\n                    if is_x_int and is_y_int:\n                        x_int = int(x_val)\n                        y_int = int(y_val)\n\n                        # Perform conversion\n                        clip_identifier = token[:-2]  # Get clip name\n                        # Handle potential :c or :m suffix\n                        suffix = \"\"\n                        if \":\" in clip_identifier:\n                            parts = clip_identifier.split(\":\", 1)\n                            clip_identifier = parts[0]\n                            suffix = \":\" + parts[1]\n\n                        # Pop the constant coordinate tokens from result_tokens\n                        result_tokens.pop()  # Remove y token\n                        result_tokens.pop()  # Remove x token\n\n                        # Append the new static access token\n                        result_tokens.append(\n                            f\"{clip_identifier}[{x_int},{y_int}]{suffix}\"\n                        )\n                        converted = True\n\n                except (\n                    ValueError,\n                    OverflowError,\n                ):  # Handle parse errors or large floats\n                    # If parsing or int conversion fails, don't convert\n                    pass  # Fall through to append original token\n\n        if not converted:\n            # If not converting this token, just append it\n            result_tokens.append(token)\n\n        i += 1  # Move to the next token in the *original* list\n\n    return \" \".join(result_tokens)\n</code></pre>"},{"location":"API/expr/postfix2infix/","title":"<code>y5gfunc.expr.postfix2infix</code>","text":""},{"location":"API/expr/postfix2infix/#y5gfunc.expr.postfix2infix","title":"postfix2infix","text":"<p>Functions:</p> Name Description <code>postfix2infix</code> <p>Convert postfix expr to infix code</p>"},{"location":"API/expr/postfix2infix/#y5gfunc.expr.postfix2infix.postfix2infix","title":"postfix2infix","text":"<pre><code>postfix2infix(expr: str) -&gt; LiteralString\n</code></pre> <p>Convert postfix expr to infix code</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Input postfix expr.</p> required <p>Returns:</p> Type Description <code>LiteralString</code> <p>Converted infix code.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an error was found in the input expr.</p> Source code in <code>y5gfunc/expr/postfix2infix.py</code> <pre><code>def postfix2infix(expr: str) -&gt; LiteralString:\n    \"\"\"\n    Convert postfix expr to infix code\n\n    Args:\n        expr: Input postfix expr.\n\n    Returns:\n        Converted infix code.\n\n    Raises:\n        ValueError: If an error was found in the input expr.\n    \"\"\"\n    # Preprocessing\n    expr = expr.strip()\n    expr = re.sub(r\"\\[\\s*(\\w+)\\s*,\\s*(\\w+)\\s*\\]\", r\"[\\1,\\2]\", expr)  # [x, y] =&gt; [x,y]\n    tokens = re.split(r\"\\s+\", expr)\n\n    stack = []\n    output_lines = []\n\n    # Regex patterns for numbers\n    number_pattern = re.compile(\n        r\"^(\"\n        r\"0x[0-9A-Fa-f]+(\\.[0-9A-Fa-f]+(p[+\\-]?\\d+)?)?\"\n        r\"|\"\n        r\"0[0-7]*\"\n        r\"|\"\n        r\"[+\\-]?(\\d+(\\.\\d+)?([eE][+\\-]?\\d+)?)\"\n        r\")$\"\n    )\n\n    i = 0\n    while i &lt; len(tokens):\n\n        def pop(n=1):\n            try:\n                if n == 1:\n                    return stack.pop()\n                r = stack[-n:]\n                del stack[-n:]\n                return r\n            except IndexError:\n                raise ValueError(\n                    f\"postfix2infix: Stack Underflow at token at {i}th token {token}.\"\n                )\n\n        def push(item):\n            stack.append(item)\n\n        token = tokens[i]\n\n        # Single letter\n        if token.isalpha() and len(token) == 1:\n            push(token)\n            i += 1\n            continue\n\n        # Numbers\n        if number_pattern.match(token):\n            push(token)\n            i += 1\n            continue\n\n        # Source clips (srcN)\n        if re.match(r\"^src\\d+$\", token):\n            push(token)\n            i += 1\n            continue\n\n        # Frame property\n        if re.match(r\"^[a-zA-Z]\\w*\\.[a-zA-Z]\\w*$\", token):\n            push(token)\n            i += 1\n            continue\n\n        # Dynamic pixel access\n        if token.endswith(\"[]\"):\n            clip_identifier = token[:-2]\n            absY = pop()\n            absX = pop()\n            push(f\"dyn({clip_identifier}({absX}, {absY}))\")\n            i += 1\n            continue\n\n        # Static relative pixel access\n        m = re.match(r\"^([a-zA-Z]\\w*)\\[\\s*(-?\\d+)\\s*,\\s*(-?\\d+)\\s*\\](\\:\\w+)?$\", token)\n        if m:\n            clip_identifier = m.group(1)\n            statX = int(m.group(2))\n            statY = int(m.group(3))\n            boundary_suffix = m.group(4)\n            if boundary_suffix not in [None, \":c\", \":m\"]:\n                raise ValueError(\n                    f\"postfix2infix: unknown boundary_suffix {boundary_suffix} at {i}th token {token}\"\n                )\n            push(f\"{clip_identifier}[{statX},{statY}]{boundary_suffix or \"\"}\")\n            i += 1\n            continue\n\n        # Variable operations\n        var_store_match = re.match(r\"^([a-zA-Z_]\\w*)\\!$\", token)\n        var_load_match = re.match(r\"^([a-zA-Z_]\\w*)\\@$\", token)\n        if var_store_match:\n            var_name = var_store_match.group(1)\n            val = pop()\n            output_lines.append(f\"{var_name} = {val}\")\n            i += 1\n            continue\n        elif var_load_match:\n            var_name = var_load_match.group(1)\n            push(var_name)\n            i += 1\n            continue\n\n        # Drop operations\n        drop_match = re.match(r\"^drop(\\d*)$\", token)\n        if drop_match:\n            num = int(drop_match.group(1)) if drop_match.group(1) else 1\n            pop(num)\n            i += 1\n            continue\n\n        # Sort operations\n        sort_match = re.match(r\"^sort(\\d+)$\", token)\n        if sort_match:\n            num = int(sort_match.group(1))\n            items = pop(num)\n            sorted_items_expr = f\"nth_{{}}({', '.join(items)})\"\n            for idx in range(len(items)):\n                push(sorted_items_expr.format(idx))\n            i += 1\n            continue\n\n        # Duplicate operations\n        dup_match = re.match(r\"^dup(\\d*)$\", token)\n        if dup_match:\n            n = int(dup_match.group(1)) if dup_match.group(1) else 0\n            if len(stack) &lt;= n:\n                raise ValueError(\n                    f\"postfix2infix: {i}th token {token} needs at least {n} values, while only {len(stack)} in stack.\"\n                )\n            else:\n                push(stack[-1 - n])\n            i += 1\n            continue\n\n        # Swap operations\n        swap_match = re.match(r\"^swap(\\d*)$\", token)\n        if swap_match:\n            n = int(swap_match.group(1)) if swap_match.group(1) else 1\n            if len(stack) &lt;= n:\n                raise ValueError(\n                    f\"postfix2infix: {i}th token {token} needs at least {n} values, while only {len(stack)} in stack.\"\n                )\n            else:\n                stack[-1], stack[-1 - n] = stack[-1 - n], stack[-1]\n            i += 1\n            continue\n\n        # Special constants\n        if token in (\"N\", \"X\", \"Y\", \"width\", \"height\"):\n            constants = {\n                \"N\": \"current_frame_number\",\n                \"X\": \"current_x\",\n                \"Y\": \"current_y\",\n                \"width\": \"current_width\",\n                \"height\": \"current_height\",\n            }\n            push(constants[token])\n            i += 1\n            continue\n\n        # Unary operators\n        if token in (\n            \"sin\",\n            \"cos\",\n            \"round\",\n            \"trunc\",\n            \"floor\",\n            \"bitnot\",\n            \"abs\",\n            \"sqrt\",\n            \"not\",\n        ):\n            a = pop()\n            if token == \"not\":\n                push(f\"(!({a}))\")\n            else:\n                push(f\"{token}({a})\")\n            i += 1\n            continue\n\n        # Binary operators\n        if token in (\"%\", \"**\", \"pow\", \"bitand\", \"bitor\", \"bitxor\"):\n            b = pop()\n            a = pop()\n            if token == \"%\":\n                push(f\"({a} % {b})\")\n            elif token in (\"**\", \"pow\"):\n                push(f\"pow({a}, {b})\")\n            elif token == \"bitand\":\n                push(f\"({a} &amp; {b})\")\n            elif token == \"bitor\":\n                push(f\"({a} | {b})\")\n            elif token == \"bitxor\":\n                push(f\"({a} ^ {b})\")\n            i += 1\n            continue\n\n        # Basic arithmetic, comparison and logical operators\n        if token in (\n            \"+\",\n            \"-\",\n            \"*\",\n            \"/\",\n            \"max\",\n            \"min\",\n            \"&gt;\",\n            \"&lt;\",\n            \"&gt;=\",\n            \"&lt;=\",\n            \"=\",\n            \"and\",\n            \"or\",\n            \"xor\",\n        ):\n            b = pop()\n            a = pop()\n            if token in (\"max\", \"min\"):\n                push(f\"{token}({a}, {b})\")\n            elif token == \"and\":\n                push(f\"({a} &amp;&amp; {b})\")\n            elif token == \"or\":\n                push(f\"({a} || {b})\")\n            elif token == \"xor\":\n                # (a || b) &amp;&amp; !(a &amp;&amp; b)\n                # (a &amp;&amp; !b) || (!a &amp;&amp; b)\n                push(f\"(({a} &amp;&amp; !{b}) || (!{a} &amp;&amp; {b}))\")\n            elif token == \"=\":\n                push(f\"{a} == {b}\")\n            else:\n                push(f\"({a} {token} {b})\")\n            i += 1\n            continue\n\n        # Ternary operator\n        if token == \"?\":\n            false_val = pop()\n            true_val = pop()\n            cond = pop()\n            push(f\"({cond} ? {true_val} : {false_val})\")\n            i += 1\n            continue\n        if token == \"clip\" or token == \"clamp\":\n            max = pop()\n            min = pop()\n            value = pop()\n            push(f\"(clamp({value}, {min}, {max}))\")\n            i += 1\n            continue\n\n        # Unknown tokens\n        output_lines.append(f\"# [Unknown token]: {token}  (Push as-is)\")\n        push(token)\n        i += 1\n\n    # Handle remaining stack items\n    if len(stack) == 1:\n        output_lines.append(f\"RESULT = {stack[0]}\")\n        ret = \"\\n\".join(output_lines)\n        print(ret)\n    else:\n        for idx, item in enumerate(stack):\n            output_lines.append(f\"# stack[{idx}]: {item}\")\n        ret = \"\\n\".join(output_lines)\n        raise ValueError(\n            f\"postfix2infix: Invalid expression: the stack contains not exactly one value after evaluation. \\n {ret}\"\n        )\n    return ret\n</code></pre>"},{"location":"API/expr/postfix2infix/#y5gfunc.expr.postfix2infix.postfix2infix(expr)","title":"<code>expr</code>","text":""},{"location":"API/expr/utils/","title":"<code>y5gfunc.expr.utils</code>","text":""},{"location":"API/expr/utils/#y5gfunc.expr.utils","title":"utils","text":"<p>Functions:</p> Name Description <code>ex_planes</code>"},{"location":"API/expr/utils/#y5gfunc.expr.utils.ex_planes","title":"ex_planes","text":"<pre><code>ex_planes(clip: VideoNode, expr: list[str], planes: Optional[Union[int, list[int]]] = None) -&gt; list[str]\n</code></pre> Source code in <code>y5gfunc/expr/utils.py</code> <pre><code>def ex_planes(\n    clip: vs.VideoNode, expr: list[str], planes: Optional[Union[int, list[int]]] = None\n) -&gt; list[str]:\n    if planes:\n        plane_range = range(clip.format.num_planes)\n        planes = [planes] if isinstance(planes, int) else planes\n        expr = [expr[0] if i in planes else \"\" for i in plane_range]\n    return expr\n</code></pre>"},{"location":"API/filter/aa/","title":"<code>y5gfunc.filter.aa</code>","text":""},{"location":"API/filter/aa/#y5gfunc.filter.aa","title":"aa","text":"<p>Functions:</p> Name Description <code>double_aa</code> <p>Apply light anti-aliasing to input video clip. Suitable for recent non-descalable anime.</p>"},{"location":"API/filter/aa/#y5gfunc.filter.aa.double_aa","title":"double_aa","text":"<pre><code>double_aa(clip: VideoNode, mask: Optional[VideoNode] = None, doubler: Callable[[VideoNode], VideoNode] = nn2x) -&gt; VideoNode\n</code></pre> <p>Apply light anti-aliasing to input video clip. Suitable for recent non-descalable anime.</p> <p>The function first doubles the resolution of the input clip with <code>doubler</code>, then downscales back with SSIM_downsample. Chroma planes are not touched.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip.</p> required <code>Optional[VideoNode]</code> <p>If provided, will be used as mask to merge anti-aliased clip and source clip. Otherwise, Prewitt mask is used.</p> <code>None</code> <code>Callable[[VideoNode], VideoNode]</code> <p>Function to double the clip.</p> <code>nn2x</code> <p>Returns:     Anti-aliased input video clip.</p> Source code in <code>y5gfunc/filter/aa.py</code> <pre><code>def double_aa(\n    clip: vs.VideoNode,\n    mask: Optional[vs.VideoNode] = None,\n    doubler: Callable[[vs.VideoNode], vs.VideoNode] = nn2x,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Apply light anti-aliasing to input video clip. Suitable for recent non-descalable anime.\n\n    The function first doubles the resolution of the input clip with `doubler`, then downscales back with SSIM_downsample.\n    Chroma planes are not touched.\n\n    Args:\n        clip: Input video clip.\n        mask: If provided, will be used as mask to merge anti-aliased clip and source clip. Otherwise, Prewitt mask is used.\n        doubler: Function to double the clip.\n    Returns:\n        Anti-aliased input video clip.\n    \"\"\"\n\n    return core.std.MaskedMerge(\n        clip,\n        join(\n            depth(\n                SSIM_downsample(\n                    doubler(get_y(clip)),\n                    width=clip.width,\n                    height=clip.height,\n                    src_left=-0.5,\n                    src_top=-0.5,\n                ),\n                clip,\n            ),\n            clip,\n        ),\n        mask or maximum(prewitt(clip)),\n        first_plane=True,\n    )\n</code></pre>"},{"location":"API/filter/aa/#y5gfunc.filter.aa.double_aa(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/aa/#y5gfunc.filter.aa.double_aa(mask)","title":"<code>mask</code>","text":""},{"location":"API/filter/aa/#y5gfunc.filter.aa.double_aa(doubler)","title":"<code>doubler</code>","text":""},{"location":"API/filter/deband/","title":"<code>y5gfunc.filter.deband</code>","text":""},{"location":"API/filter/deband/#y5gfunc.filter.deband","title":"deband","text":"<p>Functions:</p> Name Description <code>SynDeband</code>"},{"location":"API/filter/deband/#y5gfunc.filter.deband.SynDeband","title":"SynDeband","text":"<pre><code>SynDeband(clip: VideoNode, r1: int = 14, y1: int = 72, uv1: int = 48, r2: int = 30, y2: int = 48, uv2: int = 32, mstr: int = 6000, inflate: int = 2, include_mask: bool = False, kill: Optional[VideoNode] = None, bmask: Optional[VideoNode] = None, limit: bool = True, limit_thry: float = 0.12, limit_thrc: float = 0.1, limit_elast: float = 20) -&gt; Union[VideoNode, tuple[VideoNode, VideoNode]]\n</code></pre> Source code in <code>y5gfunc/filter/deband.py</code> <pre><code>def SynDeband(\n    clip: vs.VideoNode,\n    r1: int = 14,\n    y1: int = 72,\n    uv1: int = 48,\n    r2: int = 30,\n    y2: int = 48,\n    uv2: int = 32,\n    mstr: int = 6000,\n    inflate: int = 2,\n    include_mask: bool = False,\n    kill: Optional[vs.VideoNode] = None,\n    bmask: Optional[vs.VideoNode] = None,\n    limit: bool = True,\n    limit_thry: float = 0.12,\n    limit_thrc: float = 0.1,\n    limit_elast: float = 20,\n) -&gt; Union[vs.VideoNode, tuple[vs.VideoNode, vs.VideoNode]]:\n    assert clip.format.id == vs.YUV420P16\n\n    if kill is None:\n        kill = vstools.iterate(clip, functools.partial(remove_grain, mode=[20, 11]), 2)\n    elif not kill:\n        kill = clip\n\n    assert isinstance(kill, vs.VideoNode)\n    grain = core.std.MakeDiff(clip, kill)\n    f3kdb_params = {\n        \"grainy\": 0,\n        \"grainc\": 0,\n        \"sample_mode\": 2,\n        \"blur_first\": True,\n        \"dither_algo\": 2,\n    }\n    f3k1 = kill.neo_f3kdb.Deband(r1, y1, uv1, uv1, **f3kdb_params)\n    f3k2 = f3k1.neo_f3kdb.Deband(r2, y2, uv2, uv2, **f3kdb_params)\n    if limit:\n        f3k2 = mvf.LimitFilter(\n            f3k2, kill, thr=limit_thry, thrc=limit_thrc, elast=limit_elast\n        )\n    if bmask is None:\n        bmask = retinex_edgemask(kill).std.Binarize(mstr)\n        bmask = vstools.iterate(bmask, _inflate, inflate)\n    deband = core.std.MaskedMerge(f3k2, kill, bmask)\n    deband = core.std.MergeDiff(deband, grain)\n    if include_mask:\n        return deband, bmask\n    else:\n        return deband\n</code></pre>"},{"location":"API/filter/denoise/","title":"<code>y5gfunc.filter.denoise</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise","title":"denoise","text":"<p>Classes:</p> Name Description <code>BM3DPreset</code> <p>BM3D speed vs quality presets. <code>MAGIC</code> is better classified as tune but whatever.</p> <p>Functions:</p> Name Description <code>Fast_BM3DWrapper</code> <p>BM3D/V-BM3D denoising</p> <code>hybrid_denoise</code> <p>mc_degrain + bm3d denoise</p> <code>magic_denoise</code> <p>Uses dark magic to denoise heavy grain from videos.</p> <code>adaptive_denoise</code> <p>Attributes:</p> Name Type Description <code>bm3d_presets</code> <code>dict[str, dict[BM3DPreset, dict[str, int]]]</code>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.bm3d_presets","title":"bm3d_presets  <code>module-attribute</code>","text":"<pre><code>bm3d_presets: dict[str, dict[BM3DPreset, dict[str, int]]] = {'basic': {FAST: {'block_step': 8, 'bm_range': 9, 'ps_num': 2, 'ps_range': 4}, LC: {'block_step': 6, 'bm_range': 9, 'ps_num': 2, 'ps_range': 4}, NP: {'block_step': 4, 'bm_range': 16, 'ps_num': 2, 'ps_range': 5}, HIGH: {'block_step': 3, 'bm_range': 16, 'ps_num': 2, 'ps_range': 7}, MAGIC: {'block_step': 3, 'bm_range': 12, 'ps_num': 2, 'ps_range': 8}}, 'vbasic': {FAST: {'block_step': 8, 'bm_range': 7, 'ps_num': 2, 'ps_range': 4}, LC: {'block_step': 6, 'bm_range': 9, 'ps_num': 2, 'ps_range': 4}, NP: {'block_step': 4, 'bm_range': 12, 'ps_num': 2, 'ps_range': 5}, HIGH: {'block_step': 3, 'bm_range': 16, 'ps_num': 2, 'ps_range': 7}, MAGIC: {'block_step': 3, 'bm_range': 12, 'ps_num': 2, 'ps_range': 8}}, 'final': {FAST: {'block_step': 7, 'bm_range': 9, 'ps_num': 2, 'ps_range': 5}, LC: {'block_step': 5, 'bm_range': 9, 'ps_num': 2, 'ps_range': 5}, NP: {'block_step': 3, 'bm_range': 16, 'ps_num': 2, 'ps_range': 6}, HIGH: {'block_step': 2, 'bm_range': 16, 'ps_num': 2, 'ps_range': 8}, MAGIC: {'block_step': 2, 'bm_range': 8, 'ps_num': 2, 'ps_range': 6}}, 'vfinal': {FAST: {'block_step': 7, 'bm_range': 7, 'ps_num': 2, 'ps_range': 5}, LC: {'block_step': 5, 'bm_range': 9, 'ps_num': 2, 'ps_range': 5}, NP: {'block_step': 3, 'bm_range': 12, 'ps_num': 2, 'ps_range': 6}, HIGH: {'block_step': 2, 'bm_range': 16, 'ps_num': 2, 'ps_range': 8}, MAGIC: {'block_step': 2, 'bm_range': 8, 'ps_num': 2, 'ps_range': 6}}}\n</code></pre>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.BM3DPreset","title":"BM3DPreset","text":"<p>               Bases: <code>StrEnum</code></p> <p>BM3D speed vs quality presets. <code>MAGIC</code> is better classified as tune but whatever.</p> <p>modified from https://github.com/HomeOfVapourSynthEvolution/VapourSynth-BM3D?tab=readme-ov-file#profile-default preset 'magic' is from rksfunc</p> <p>Attributes:</p> Name Type Description <code>FAST</code> <code>LC</code> <code>NP</code> <code>HIGH</code> <code>MAGIC</code>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.BM3DPreset.FAST","title":"FAST  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FAST = 'fast'\n</code></pre>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.BM3DPreset.LC","title":"LC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LC = 'lc'\n</code></pre>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.BM3DPreset.NP","title":"NP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NP = 'np'\n</code></pre>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.BM3DPreset.HIGH","title":"HIGH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HIGH = 'high'\n</code></pre>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.BM3DPreset.MAGIC","title":"MAGIC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MAGIC = 'magic'\n</code></pre>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper","title":"Fast_BM3DWrapper","text":"<pre><code>Fast_BM3DWrapper(clip: VideoNode, bm3d: Callable = bm3dcpu, chroma: bool = True, sigma_Y: Union[float, int] = 1.2, radius_Y: int = 1, delta_sigma_Y: Union[float, int] = 0.6, preset_Y_basic: BM3DPreset = FAST, preset_Y_final: BM3DPreset = FAST, sigma_chroma: Union[float, int] = 2.4, radius_chroma: int = 0, delta_sigma_chroma: Union[float, int] = 1.2, preset_chroma_basic: BM3DPreset = FAST, preset_chroma_final: BM3DPreset = FAST, ref: Optional[VideoNode] = None, opp_matrix: ColorMatrixManager = default_opp) -&gt; VideoNode\n</code></pre> <p>BM3D/V-BM3D denoising</p> <p>This function performs a two-step BM3D (or V-BM3D if radius &gt; 0) denoising process. Luma (Y) is processed directly. Chroma (U/V) is processed by downscaling the denoised luma, joining it with the original chroma, converting to OPP color space at half resolution, denoising in OPP, converting back to YUV, and finally joining the denoised luma and denoised chroma planes.</p> <p>The 'delta_sigma' parameters add extra strength specifically to the first (basic) denoising step for both luma and chroma.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip. Must be in YUV420P16 format.</p> required <code>Callable</code> <p>The BM3D plugin implementation to use.</p> <code>bm3dcpu</code> <code>bool</code> <p>If True, process chroma planes. If False, only luma is processed and original chroma is retained.</p> <code>True</code> <code>Union[float, int]</code> <p>Denoising strength for the luma plane's final step.</p> <code>1.2</code> <code>int</code> <p>Temporal radius for luma processing. If &gt; 0, V-BM3D is used.</p> <code>1</code> <code>Union[float, int]</code> <p>Additional sigma added to <code>sigma_Y</code> for the luma plane's basic step.</p> <code>0.6</code> <code>BM3DPreset</code> <p>BM3D parameter preset for the luma basic step.</p> <code>FAST</code> <code>BM3DPreset</code> <p>BM3D parameter preset for the luma final step.</p> <code>FAST</code> <code>Union[float, int]</code> <p>Denoising strength for the chroma planes' final step.</p> <code>2.4</code> <code>int</code> <p>Temporal radius for chroma processing. If &gt; 0, V-BM3D is used.</p> <code>0</code> <code>Union[float, int]</code> <p>Additional sigma added to <code>sigma_chroma</code> for the chroma planes' basic step.</p> <code>1.2</code> <code>BM3DPreset</code> <p>BM3D parameter preset for the chroma basic step.</p> <code>FAST</code> <code>BM3DPreset</code> <p>BM3D parameter preset for the chroma final step.</p> <code>FAST</code> <code>Optional[VideoNode]</code> <p>Ref for final BM3D step. If provided, basic step is bypassed.</p> <code>None</code> <code>ColorMatrixManager</code> <p>OPP transform type to use.</p> <code>default_opp</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Denoised video clip in YUV420P16 format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input clip format is not YUV420P16.</p> <code>ValueError</code> <p>If any provided preset name is invalid.</p> Notes <ul> <li>The <code>delta_sigma_xxx</code> value is added to <code>sigma_xxx</code> only for the 'basic' denoising step. The 'final' step uses <code>sigma_xxx</code> directly.</li> </ul> Source code in <code>y5gfunc/filter/denoise.py</code> <pre><code>def Fast_BM3DWrapper(\n    clip: vs.VideoNode,\n    bm3d: Callable = core.lazy.bm3dcpu,\n    chroma: bool = True,\n    sigma_Y: Union[float, int] = 1.2,\n    radius_Y: int = 1,\n    delta_sigma_Y: Union[float, int] = 0.6,\n    preset_Y_basic: BM3DPreset = BM3DPreset.FAST,\n    preset_Y_final: BM3DPreset = BM3DPreset.FAST,\n    sigma_chroma: Union[float, int] = 2.4,\n    radius_chroma: int = 0,\n    delta_sigma_chroma: Union[float, int] = 1.2,\n    preset_chroma_basic: BM3DPreset = BM3DPreset.FAST,\n    preset_chroma_final: BM3DPreset = BM3DPreset.FAST,\n    ref: Optional[vs.VideoNode] = None,\n    opp_matrix: ColorMatrixManager = default_opp,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    BM3D/V-BM3D denoising\n\n    This function performs a two-step BM3D (or V-BM3D if radius &gt; 0) denoising process. Luma (Y) is processed directly.\n    Chroma (U/V) is processed by downscaling the denoised luma, joining it with the original chroma, converting to OPP color space\n    at half resolution, denoising in OPP, converting back to YUV, and finally joining the denoised luma and denoised chroma planes.\n\n    The 'delta_sigma' parameters add extra strength specifically to the first (basic) denoising step for both luma and chroma.\n\n    Args:\n        clip: Input video clip. Must be in YUV420P16 format.\n        bm3d: The BM3D plugin implementation to use.\n        chroma: If True, process chroma planes. If False, only luma is processed and original chroma is retained.\n        sigma_Y: Denoising strength for the luma plane's final step.\n        radius_Y: Temporal radius for luma processing. If &gt; 0, V-BM3D is used.\n        delta_sigma_Y: Additional sigma added to `sigma_Y` for the luma plane's basic step.\n        preset_Y_basic: BM3D parameter preset for the luma basic step.\n        preset_Y_final: BM3D parameter preset for the luma final step.\n        sigma_chroma: Denoising strength for the chroma planes' final step.\n        radius_chroma: Temporal radius for chroma processing. If &gt; 0, V-BM3D is used.\n        delta_sigma_chroma: Additional sigma added to `sigma_chroma` for the chroma planes' basic step.\n        preset_chroma_basic: BM3D parameter preset for the chroma basic step.\n        preset_chroma_final: BM3D parameter preset for the chroma final step.\n        ref: Ref for final BM3D step. If provided, basic step is bypassed.\n        opp_matrix: OPP transform type to use.\n\n    Returns:\n        Denoised video clip in YUV420P16 format.\n\n    Raises:\n        ValueError: If the input clip format is not YUV420P16.\n        ValueError: If any provided preset name is invalid.\n\n    Notes:\n        - The `delta_sigma_xxx` value is added to `sigma_xxx` only for the 'basic' denoising step. The 'final' step uses `sigma_xxx` directly.\n    \"\"\"\n\n    if clip.format.id != vs.YUV420P16:\n        raise ValueError(\"Fast_BM3DWrapper: Input clip format must be YUV420P16.\")\n    if ref:\n        if ref.format.id != clip.format.id:\n            raise ValueError(\n                f\"Fast_BM3DWrapper: Input clip and ref must have the same format. Got {ref.format.id} and {clip.format.id}\"\n            )\n\n    matrix = vstools.Matrix.from_video(clip, strict=True)\n\n    try:\n        to_opp = functools.partial(yuv2opp, matrix_in=matrix, opp_manager=opp_matrix)\n        to_yuv = functools.partial(\n            opp2yuv,\n            target_matrix=matrix,\n            opp_manager=opp_matrix,\n        )\n    except ValueError:\n\n        def to_opp(clip) -&gt; vs.VideoNode:\n            return rgb2opp(\n                core.resize2.Bicubic(clip, format=vs.RGBS, matrix_in=matrix),\n                opp_manager=opp_matrix,\n            )\n\n        def to_yuv(clip) -&gt; vs.VideoNode:\n            return opp2rgb(clip, opp_manager=opp_matrix).resize2.Spline36(\n                format=vs.YUV444PS, matrix=matrix\n            )\n\n    for preset in [\n        preset_Y_basic,\n        preset_Y_final,\n        preset_chroma_basic,\n        preset_chroma_final,\n    ]:\n        if preset not in [\n            BM3DPreset.FAST,\n            BM3DPreset.LC,\n            BM3DPreset.NP,\n            BM3DPreset.HIGH,\n            BM3DPreset.MAGIC,\n        ]:\n            raise ValueError(f\"Fast_BM3DWrapper: Unknown preset {preset}.\")\n\n    params = {\n        \"y_basic\": bm3d_presets[\"vbasic\" if radius_Y &gt; 0 else \"basic\"][preset_Y_basic],\n        \"y_final\": bm3d_presets[\"vfinal\" if radius_Y &gt; 0 else \"final\"][preset_Y_final],\n        \"chroma_basic\": bm3d_presets[\"vbasic\" if radius_chroma &gt; 0 else \"basic\"][\n            preset_chroma_basic\n        ],\n        \"chroma_final\": bm3d_presets[\"vfinal\" if radius_chroma &gt; 0 else \"final\"][\n            preset_chroma_final\n        ],\n    }\n\n    half_width = clip.width // 2  # half width\n    half_height = clip.height // 2  # half height\n    srcY_float, srcU_float, srcV_float = vstools.split(vstools.depth(clip, 32))\n\n    if ref is None:\n        basic_y = bm3d.BM3Dv2(\n            clip=srcY_float,\n            ref=srcY_float,\n            sigma=sigma_Y + delta_sigma_Y,\n            radius=radius_Y,\n            **params[\"y_basic\"],\n        )\n    else:\n        basic_y = vstools.depth(vstools.get_y(ref), 32)\n\n    final_y = bm3d.BM3Dv2(\n        clip=srcY_float,\n        ref=basic_y,\n        sigma=sigma_Y,\n        radius=radius_Y,\n        **params[\"y_final\"],\n    )\n\n    vyhalf = final_y.resize2.Spline36(half_width, half_height, src_left=-0.5)\n    srchalf_444 = vstools.join([vyhalf, srcU_float, srcV_float])\n    srchalf_opp = to_opp(srchalf_444)\n    if ref:\n        refhalf444 = vstools.join(vyhalf, vstools.depth(ref, 32))\n        refhalf_opp = to_opp(refhalf444)\n\n    if ref is None:\n        basic_half = bm3d.BM3Dv2(\n            clip=srchalf_opp,\n            ref=srchalf_opp,\n            sigma=sigma_chroma + delta_sigma_chroma,\n            chroma=chroma,\n            radius=radius_chroma,\n            zero_init=0,\n            **params[\"chroma_basic\"],\n        )\n    else:\n        basic_half = refhalf_opp\n\n    final_half = bm3d.BM3Dv2(\n        clip=srchalf_opp,\n        ref=basic_half,\n        sigma=sigma_chroma,\n        chroma=chroma,\n        radius=radius_chroma,\n        zero_init=0,\n        **params[\"chroma_final\"],\n    )\n\n    final_half = to_yuv(final_half)\n    _, final_u, final_v = vstools.split(final_half)\n    vfinal = vstools.join([final_y, final_u, final_v])\n    return vstools.depth(vfinal, 16)\n</code></pre>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(bm3d)","title":"<code>bm3d</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(chroma)","title":"<code>chroma</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(sigma_Y)","title":"<code>sigma_Y</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(radius_Y)","title":"<code>radius_Y</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(delta_sigma_Y)","title":"<code>delta_sigma_Y</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(preset_Y_basic)","title":"<code>preset_Y_basic</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(preset_Y_final)","title":"<code>preset_Y_final</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(sigma_chroma)","title":"<code>sigma_chroma</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(radius_chroma)","title":"<code>radius_chroma</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(delta_sigma_chroma)","title":"<code>delta_sigma_chroma</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(preset_chroma_basic)","title":"<code>preset_chroma_basic</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(preset_chroma_final)","title":"<code>preset_chroma_final</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(ref)","title":"<code>ref</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.Fast_BM3DWrapper(opp_matrix)","title":"<code>opp_matrix</code>","text":""},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.hybrid_denoise","title":"hybrid_denoise","text":"<pre><code>hybrid_denoise(clip: VideoNode, mc_degrain_prefilter: PrefilterPartial = DFTTEST(), mc_degrain_preset: Optional[MVToolsPreset] = None, mc_degrain_refine: int = 2, mc_degrain_thsad: int = 100, show_ref: bool = False, bm3d_sigma: Union[float, int] = 2, bm3d_preset: BM3DPreset = FAST, bm3d_opp_matrix: ColorMatrixManager = default_opp) -&gt; Union[VideoNode, tuple[VideoNode, VideoNode]]\n</code></pre> <p>mc_degrain + bm3d denoise</p> Source code in <code>y5gfunc/filter/denoise.py</code> <pre><code>def hybrid_denoise(\n    clip: vs.VideoNode,\n    mc_degrain_prefilter: PrefilterPartial = Prefilter.DFTTEST(),\n    mc_degrain_preset: Optional[MVToolsPreset] = None,\n    mc_degrain_refine: int = 2,\n    mc_degrain_thsad: int = 100,\n    show_ref: bool = False,\n    bm3d_sigma: Union[float, int] = 2,\n    bm3d_preset: BM3DPreset = BM3DPreset.FAST,\n    bm3d_opp_matrix: ColorMatrixManager = default_opp,\n) -&gt; Union[vs.VideoNode, tuple[vs.VideoNode, vs.VideoNode]]:\n    \"\"\"\n    mc_degrain + bm3d denoise\n    \"\"\"\n    if clip.format.id != vs.YUV420P16:\n        raise ValueError(\"Fast_BM3DWrapper: Input clip format must be YUV420P16.\")\n\n    if clip.width &lt;= 1024 and clip.height &lt;= 576:\n        block_size = 32\n        overlap = 16\n    elif clip.width &lt;= 2048 and clip.height &lt;= 1536:\n        block_size = 64\n        overlap = 32\n    else:\n        block_size = 128\n        overlap = 64\n\n    if mc_degrain_preset is None:\n        mc_degrain_preset = MVToolsPreset(\n            search_clip=prefilter_to_full_range,  # type: ignore\n            pel=2,\n            super_args=SuperArgs(sharp=SharpMode.WIENER, rfilter=RFilterMode.TRIANGLE),\n            analyze_args=AnalyzeArgs(\n                blksize=block_size,\n                overlap=overlap,\n                search=SearchMode.DIAMOND,\n                dct=SADMode.ADAPTIVE_SPATIAL_MIXED,\n                truemotion=MotionMode.SAD,\n                pelsearch=2,\n            ),\n            recalculate_args=RecalculateArgs(\n                blksize=int(block_size / 2),\n                overlap=int(overlap / 2),\n                search=SearchMode.DIAMOND,\n                dct=SADMode.ADAPTIVE_SPATIAL_MIXED,\n                truemotion=MotionMode.SAD,\n                searchparam=1,\n            ),\n        )\n\n    ref = mc_degrain(\n        clip=clip,\n        prefilter=mc_degrain_prefilter,\n        preset=mc_degrain_preset,\n        thsad=mc_degrain_thsad,\n        thsad_recalc=mc_degrain_thsad,\n        blksize=block_size,\n        refine=mc_degrain_refine,\n    )\n\n    bm3d = Fast_BM3DWrapper(\n        clip,\n        sigma_Y=bm3d_sigma,\n        sigma_chroma=bm3d_sigma,\n        preset_Y_final=bm3d_preset,\n        preset_chroma_final=bm3d_preset,\n        ref=ref,\n        opp_matrix=bm3d_opp_matrix,\n    )\n    if show_ref:\n        return bm3d, ref\n    else:\n        return bm3d\n</code></pre>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.magic_denoise","title":"magic_denoise","text":"<pre><code>magic_denoise(clip: VideoNode) -&gt; VideoNode\n</code></pre> <p>Uses dark magic to denoise heavy grain from videos.</p> Source code in <code>y5gfunc/filter/denoise.py</code> <pre><code>def magic_denoise(clip: vs.VideoNode) -&gt; vs.VideoNode:\n    \"\"\"\n    Uses dark magic to denoise heavy grain from videos.\n    \"\"\"\n    super = core.mv.Super(clip, hpad=16, vpad=16, rfilter=4)\n\n    backward2 = core.mv.Analyse(\n        super, isb=True, blksize=16, overlap=8, delta=2, search=3, dct=6\n    )\n    backward = core.mv.Analyse(super, isb=True, blksize=16, overlap=8, search=3, dct=6)\n    forward = core.mv.Analyse(super, isb=False, blksize=16, overlap=8, search=3, dct=6)\n    forward2 = core.mv.Analyse(\n        super, isb=False, blksize=16, overlap=8, delta=2, search=3, dct=6\n    )\n\n    backward2 = core.mv.Recalculate(\n        super, backward2, blksize=8, overlap=4, search=3, divide=2, dct=6\n    )\n    backward = core.mv.Recalculate(\n        super, backward, blksize=8, overlap=4, search=3, divide=2, dct=6\n    )\n    forward = core.mv.Recalculate(\n        super, forward, blksize=8, overlap=4, search=3, divide=2, dct=6\n    )\n    forward2 = core.mv.Recalculate(\n        super, forward2, blksize=8, overlap=4, search=3, divide=2, dct=6\n    )\n\n    backward_re2 = core.mv.Finest(backward2)\n    backward_re = core.mv.Finest(backward)\n    forward_re = core.mv.Finest(forward)\n    forward_re2 = core.mv.Finest(forward2)\n\n    clip = core.mv.Degrain2(\n        clip,\n        super,\n        backward_re,\n        forward_re,\n        backward_re2,\n        forward_re2,\n        thsad=220,\n        thscd1=300,\n    )\n\n    return DFTTest(\n        sloc=[(0.0, 0.8), (0.06, 1.1), (0.12, 1.0), (1.0, 1.0)],\n    ).denoise(\n        clip,\n        pmax=1000000,\n        pmin=1.25,\n        ftype=FilterType.MULT_RANGE,\n        tbsize=3,\n        ssystem=1,\n    )\n</code></pre>"},{"location":"API/filter/denoise/#y5gfunc.filter.denoise.adaptive_denoise","title":"adaptive_denoise","text":"<pre><code>adaptive_denoise(clip: VideoNode, denoised: VideoNode) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/denoise.py</code> <pre><code>def adaptive_denoise(clip: vs.VideoNode, denoised: vs.VideoNode) -&gt; vs.VideoNode:\n    bilateral = vsrgtools.bilateral(clip, denoised, 0.5)\n    amask = vstools.iterate(denoised, functools.partial(remove_grain, mode=[20, 11]), 2)\n    amask = adg_mask(amask, luma_scaling=12)\n    degrain = core.std.MaskedMerge(denoised, bilateral, amask, first_plane=True)\n    clear_edge = core.std.MaskedMerge(degrain, denoised, maximum(GammaMask(denoised)))\n    return vstools.join(clear_edge, denoised)\n</code></pre>"},{"location":"API/filter/ivtc/","title":"<code>y5gfunc.filter.ivtc</code>","text":""},{"location":"API/filter/ivtc/#y5gfunc.filter.ivtc","title":"ivtc","text":"<p>Functions:</p> Name Description <code>TIVTC_VFR</code> <p>Convenient wrapper on tivtc to perform automatic vfr decimation with one function.</p>"},{"location":"API/filter/ivtc/#y5gfunc.filter.ivtc.TIVTC_VFR","title":"TIVTC_VFR","text":"<pre><code>TIVTC_VFR(source: VideoNode, clip2: Optional[VideoNode] = None, tfmIn: Union[Path, str] = 'matches.txt', tdecIn: Union[Path, str] = 'metrics.txt', mkvOut: Union[Path, str] = 'timecodes.txt', tfm_args: dict = dict(), tdecimate_args: dict = dict(), overwrite: bool = False) -&gt; VideoNode\n</code></pre> <p>Convenient wrapper on tivtc to perform automatic vfr decimation with one function.</p> Source code in <code>y5gfunc/filter/ivtc.py</code> <pre><code>def TIVTC_VFR(\n    source: vs.VideoNode,\n    clip2: Optional[vs.VideoNode] = None,\n    tfmIn: Union[Path, str] = \"matches.txt\",\n    tdecIn: Union[Path, str] = \"metrics.txt\",\n    mkvOut: Union[Path, str] = \"timecodes.txt\",\n    tfm_args: dict = dict(),\n    tdecimate_args: dict = dict(),\n    overwrite: bool = False,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Convenient wrapper on tivtc to perform automatic vfr decimation with one function.\n    \"\"\"\n\n    analyze = True\n\n    assert isinstance(tfmIn, (str, Path))\n    assert isinstance(tdecIn, (str, Path))\n    assert isinstance(mkvOut, (str, Path))\n\n    tfmIn = resolve_path(tfmIn)\n    tdecIn = resolve_path(tdecIn)\n    mkvOut = resolve_path(mkvOut)\n\n    if tfmIn.exists() and tdecIn.exists():\n        analyze = False\n\n    if clip2 and not overwrite:\n        tfm_args.update(dict(clip2=clip2))\n\n    if analyze:\n        tfmIn = resolve_path(tfmIn)\n        tdecIn = resolve_path(tdecIn)\n        mkvOut = resolve_path(mkvOut)\n        tfm_pass1_args = tfm_args.copy()\n        tdecimate_pass1_args = tdecimate_args.copy()\n        tfm_pass1_args.update(dict(output=str(tfmIn)))\n        tdecimate_pass1_args.update(dict(output=str(tdecIn), mode=4))\n        tmpnode = core.tivtc.TFM(source, **tfm_pass1_args)\n        tmpnode = core.tivtc.TDecimate(tmpnode, **tdecimate_pass1_args)\n\n        for i, _ in enumerate(tmpnode.frames()):\n            print(f\"Analyzing frame #{i}...\", end=\"\\r\")\n\n        del tmpnode\n        time.sleep(0.5)  # let it write logs\n\n    tfm_args.update(dict(input=str(tfmIn)))\n    tdecimate_args.update(\n        dict(\n            input=str(tdecIn),\n            tfmIn=str(tfmIn),\n            mkvOut=str(mkvOut),\n            mode=5,\n            hybrid=2,\n            vfrDec=1,\n        )\n    )\n\n    output = core.tivtc.TFM(source, **tfm_args)\n    output = core.tivtc.TDecimate(output, **tdecimate_args)\n\n    return output\n</code></pre>"},{"location":"API/filter/mask/","title":"<code>y5gfunc.filter.mask</code>","text":""},{"location":"API/filter/mask/#y5gfunc.filter.mask","title":"mask","text":"<p>Functions:</p> Name Description <code>DBMask</code> <p>Lolihouse's deband mask</p> <code>AnimeMask</code> <p>Generates edge/ringing mask for anime based on gradient operator.</p> <code>GammaMask</code> <code>get_oped_mask</code> <code>kirsch</code> <code>prewitt</code> <code>retinex_edgemask</code> <code>generate_detail_mask</code> <code>comb_mask</code> <p>Comb mask from TIVTC/TFM plugin.</p>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.DBMask","title":"DBMask","text":"<pre><code>DBMask(clip: VideoNode) -&gt; VideoNode\n</code></pre> <p>Lolihouse's deband mask</p> Source code in <code>y5gfunc/filter/mask.py</code> <pre><code>def DBMask(clip: vs.VideoNode) -&gt; vs.VideoNode:\n    \"\"\"Lolihouse's deband mask\"\"\"\n    nrmasks = core.tcanny.TCanny(\n        clip, sigma=0.8, op=2, mode=1, planes=[0, 1, 2]\n    ).std.Binarize(scale_mask(7, 8, clip), planes=[0])\n    nrmaskb = core.tcanny.TCanny(clip, sigma=1.3, t_h=6.5, op=2, planes=0)\n    nrmaskg = core.tcanny.TCanny(clip, sigma=1.1, t_h=5.0, op=2, planes=0)\n    nrmask = core.akarin.Expr(\n        [nrmaskg, nrmaskb, nrmasks, clip],\n        [\n            f\"a {scale_mask(20, 8, clip)} &lt; {get_peak_value_full(clip)} a {scale_mask(48, 8, clip)} &lt; x {scale_mask(256, 16, clip)} * a {scale_mask(96, 8, clip)} &lt; y {scale_mask(256, 16, clip)} * z ? ? ?\",\n            \"\",\n        ],\n        clip.format.id,\n    )\n    nrmask = minimum(\n        vstools.iterate(nrmask, functools.partial(maximum, planes=[0]), 2), planes=[0]\n    )\n    nrmask = remove_grain(nrmask, [20, 0])\n    nrmask = vstools.get_y(\n        nrmask\n    )  # first_plane=True in [LoliHouse] Anime_WebSource_deband_1080P_10bit_adcance.vpy: L33\n    return nrmask\n</code></pre>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.AnimeMask","title":"AnimeMask","text":"<pre><code>AnimeMask(clip: VideoNode, shift: float = 0, mode: int = 1) -&gt; VideoNode\n</code></pre> <p>Generates edge/ringing mask for anime based on gradient operator.</p> <p>For Anime's ringing mask, it's recommended to set \"shift\" between 0.5 and 1.0.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Source clip. Only the First plane will be processed.</p> required <code>float</code> <p>(float, -1.5 ~ 1.5) The distance of translation. Default is 0.</p> <code>0</code> <code>int</code> <p>(-1 or 1) Type of the kernel, which simply inverts the pixel values and \"shift\". Typically, -1 is for edge, 1 is for ringing. Default is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Generated mask.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If mode(-1 or 1) is invalid.</p> Source code in <code>y5gfunc/filter/mask.py</code> <pre><code>def AnimeMask(clip: vs.VideoNode, shift: float = 0, mode: int = 1) -&gt; vs.VideoNode:\n    \"\"\"\n    Generates edge/ringing mask for anime based on gradient operator.\n\n    For Anime's ringing mask, it's recommended to set \"shift\" between 0.5 and 1.0.\n\n    Args:\n        clip: Source clip. Only the First plane will be processed.\n        shift: (float, -1.5 ~ 1.5) The distance of translation. Default is 0.\n        mode: (-1 or 1) Type of the kernel, which simply inverts the pixel values and \"shift\".\n            Typically, -1 is for edge, 1 is for ringing. Default is 1.\n\n    Returns:\n        Generated mask.\n\n    Raises:\n        ValueError: If mode(-1 or 1) is invalid.\n    \"\"\"\n\n    if clip.format.color_family != vs.GRAY:\n        clip = vstools.get_y(clip)\n\n    if mode not in [-1, 1]:\n        raise ValueError(\"AnimeMask: 'mode' have not a correct value! [-1 or 1]\")\n\n    if mode == -1:\n        clip = core.std.Invert(clip)\n        shift = -shift\n\n    mask1 = convolution(\n        clip, [0, 0, 0, 0, 2, -1, 0, -1, 0], saturate=True\n    ).resize2.Bicubic(src_left=shift, src_top=shift, range_s=\"full\", range_in_s=\"full\")\n    mask2 = convolution(\n        clip, [0, -1, 0, -1, 2, 0, 0, 0, 0], saturate=True\n    ).resize2.Bicubic(\n        src_left=-shift, src_top=-shift, range_s=\"full\", range_in_s=\"full\"\n    )\n    mask3 = convolution(\n        clip, [0, -1, 0, 0, 2, -1, 0, 0, 0], saturate=True\n    ).resize2.Bicubic(src_left=shift, src_top=-shift, range_s=\"full\", range_in_s=\"full\")\n    mask4 = convolution(\n        clip, [0, 0, 0, -1, 2, 0, 0, -1, 0], saturate=True\n    ).resize2.Bicubic(src_left=-shift, src_top=shift, range_s=\"full\", range_in_s=\"full\")\n\n    calc_expr = \"src0 2 ** src01 2 ** + src2 2 ** + src3 2 ** + sqrt \"\n\n    mask = core.akarin.Expr([mask1, mask2, mask3, mask4], [calc_expr])\n\n    return mask\n</code></pre>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.AnimeMask(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/mask/#y5gfunc.filter.mask.AnimeMask(shift)","title":"<code>shift</code>","text":""},{"location":"API/filter/mask/#y5gfunc.filter.mask.AnimeMask(mode)","title":"<code>mode</code>","text":""},{"location":"API/filter/mask/#y5gfunc.filter.mask.GammaMask","title":"GammaMask","text":"<pre><code>GammaMask(clip: VideoNode, gamma: float = 0.7) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/mask.py</code> <pre><code>def GammaMask(\n    clip: vs.VideoNode,\n    gamma: float = 0.7,\n) -&gt; vs.VideoNode:\n    y = vstools.get_y(clip)\n    gammarized = Gammarize(y, gamma)\n    _d_mask = core.tcanny.TCanny(gammarized, sigma=2, sigma_v=2, t_h=4, op=2)\n    _b_mask = core.tcanny.TCanny(y, sigma=2, sigma_v=2, t_h=3, op=2)\n    return vstools.iterate(\n        minimum(\n            vstools.iterate(core.akarin.Expr([_b_mask, _d_mask], \"x y max\"), maximum, 2)\n        ),\n        inflate,\n        2,\n    )\n</code></pre>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.get_oped_mask","title":"get_oped_mask","text":"<pre><code>get_oped_mask(clip: VideoNode, ncop: VideoNode, nced: VideoNode, op_start: int, ed_start: int, threshold: int = 7) -&gt; tuple[VideoNode, VideoNode]\n</code></pre> Source code in <code>y5gfunc/filter/mask.py</code> <pre><code>def get_oped_mask(\n    clip: vs.VideoNode,\n    ncop: vs.VideoNode,\n    nced: vs.VideoNode,\n    op_start: int,\n    ed_start: int,\n    threshold: int = 7,\n) -&gt; tuple[vs.VideoNode, vs.VideoNode]:\n    assert clip.format == ncop.format == nced.format\n    assert clip.format.color_family == vs.YUV\n\n    op_end = op_start + ncop.num_frames\n    ed_end = ed_start + nced.num_frames\n\n    assert 0 &lt;= op_start &lt;= op_end &lt; ed_start &lt;= ed_end &lt; clip.num_frames\n\n    if op_start != 0:\n        ncop = (\n            core.std.Trim(clip, first=0, last=op_start - 1)\n            + ncop\n            + core.std.Trim(clip, first=op_end + 1, last=clip.num_frames - 1)\n        )\n    else:\n        ncop = ncop + core.std.Trim(clip, first=op_end, last=clip.num_frames - 1)\n\n    if ed_end != clip.num_frames - 1:\n        nced = (\n            core.std.Trim(clip, first=0, last=ed_start - 1)\n            + nced\n            + core.std.Trim(clip, first=ed_end + 1, last=clip.num_frames - 1)\n        )\n    else:\n        nced = core.std.Trim(clip, first=0, last=ed_start - 1) + nced\n\n    nc = replace_ranges(clip, ncop, range(op_start, op_end + 1))\n    nc = replace_ranges(nc, nced, range(ed_start, ed_end + 1))\n\n    thr = scale_mask(threshold, 8, clip)\n    max = get_peak_value_full(clip)\n\n    diff = core.akarin.Expr([nc, clip], f\"x y - abs {thr} &lt; 0 {max} ?\")\n    diff = vstools.get_y(diff)\n\n    diff = vstools.iterate(diff, maximum, 5)\n    diff = vstools.iterate(diff, minimum, 6)\n\n    return nc, diff\n</code></pre>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.kirsch","title":"kirsch","text":"<pre><code>kirsch(src: VideoNode) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/mask.py</code> <pre><code>def kirsch(src: vs.VideoNode) -&gt; vs.VideoNode:\n    kirsch1 = convolution(src, matrix=[5, 5, 5, -3, 0, -3, -3, -3, -3], saturate=False)\n    kirsch2 = convolution(src, matrix=[-3, 5, 5, -3, 0, 5, -3, -3, -3], saturate=False)\n    kirsch3 = convolution(src, matrix=[-3, -3, 5, -3, 0, 5, -3, -3, 5], saturate=False)\n    kirsch4 = convolution(src, matrix=[-3, -3, -3, -3, 0, 5, -3, 5, 5], saturate=False)\n    return core.akarin.Expr([kirsch1, kirsch2, kirsch3, kirsch4], \"x y max z max a max\")\n</code></pre>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.prewitt","title":"prewitt","text":"<pre><code>prewitt(clip: VideoNode, mthr: Union[int, float] = 24) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/mask.py</code> <pre><code>def prewitt(clip: vs.VideoNode, mthr: Union[int, float] = 24) -&gt; vs.VideoNode:\n    mthr = scale_mask(mthr, 8, clip)\n    prewitt1 = convolution(\n        clip, [1, 1, 0, 1, 0, -1, 0, -1, -1], divisor=1, saturate=False\n    )\n    prewitt2 = convolution(\n        clip, [1, 1, 1, 0, 0, 0, -1, -1, -1], divisor=1, saturate=False\n    )\n    prewitt3 = convolution(\n        clip, [1, 0, -1, 1, 0, -1, 1, 0, -1], divisor=1, saturate=False\n    )\n    prewitt4 = convolution(\n        clip, [0, -1, -1, 1, 0, -1, 1, 1, 0], divisor=1, saturate=False\n    )\n    prewitt = core.akarin.Expr(\n        [prewitt1, prewitt2, prewitt3, prewitt4], \"x y max z max a max\"\n    )\n    prewitt = inflate(\n        remove_grain(core.akarin.Expr(prewitt, f\"x {mthr} &lt;= x 2 / x 1.4 pow ?\"), 4)\n    )\n    return prewitt\n</code></pre>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.retinex_edgemask","title":"retinex_edgemask","text":"<pre><code>retinex_edgemask(src: VideoNode) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/mask.py</code> <pre><code>def retinex_edgemask(src: vs.VideoNode) -&gt; vs.VideoNode:\n    luma = vstools.get_y(src)\n    max_value = get_peak_value_full(src)\n    ret = retinex(luma, sigma=[50, 200, 350], upper_thr=0.005)\n    tcanny = minimum(\n        ret.tcanny.TCanny(mode=1, sigma=1), coordinates=[1, 0, 1, 0, 0, 1, 0, 1]\n    )\n    return core.akarin.Expr([kirsch(luma), tcanny], f\"x y + {max_value} min\")\n</code></pre>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.generate_detail_mask","title":"generate_detail_mask","text":"<pre><code>generate_detail_mask(source: VideoNode, upscaled: VideoNode, threshold: float = 0.05) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/mask.py</code> <pre><code>def generate_detail_mask(\n    source: vs.VideoNode, upscaled: vs.VideoNode, threshold: float = 0.05\n) -&gt; vs.VideoNode:\n    assert source.format == upscaled.format\n    threshold = scale_mask(threshold, 32, source)\n    mask = core.akarin.Expr([source, upscaled], \"src0 src1 - abs\").std.Binarize(\n        threshold=threshold\n    )\n    mask = vstools.iterate(mask, maximum, 3)\n    mask = vstools.iterate(mask, inflate, 3)\n    return mask\n</code></pre>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.comb_mask","title":"comb_mask","text":"<pre><code>comb_mask(clip: VideoNode, cthresh: int = 6, mthresh: int = 9, expand: bool = True, metric: int = 0, planes: Optional[Union[int, list[int]]] = None) -&gt; VideoNode\n</code></pre> <p>Comb mask from TIVTC/TFM plugin.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input clip.</p> required <code>int</code> <p>Spatial combing threshold.</p> <code>6</code> <code>int</code> <p>Motion adaptive threshold.</p> <code>9</code> <code>bool</code> <p>Assume left and right pixels of combed pixel as combed too.</p> <code>True</code> <code>int</code> <p>Sets which spatial combing metric is used to detect combed pixels.     - Metric 0 is what TFM used previous to v0.9.12.0.     - Metric 1 is from Donald Graft's decomb.dll.</p> <code>0</code> <code>Optional[Union[int, list[int]]]</code> <p>Planes to process.</p> <code>None</code> Source code in <code>y5gfunc/filter/mask.py</code> <pre><code>def comb_mask(\n    clip: vs.VideoNode,\n    cthresh: int = 6,\n    mthresh: int = 9,\n    expand: bool = True,\n    metric: int = 0,\n    planes: Optional[Union[int, list[int]]] = None,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Comb mask from TIVTC/TFM plugin.\n\n    Args:\n        clip: Input clip.\n        cthresh: Spatial combing threshold.\n        mthresh: Motion adaptive threshold.\n        expand: Assume left and right pixels of combed pixel as combed too.\n        metric: Sets which spatial combing metric is used to detect combed pixels.\n                - Metric 0 is what TFM used previous to v0.9.12.0.\n                - Metric 1 is from Donald Graft's decomb.dll.\n        planes: Planes to process.\n    \"\"\"\n\n    cth_max = 65025 if metric else 255\n    if (cthresh &gt; cth_max) or (cthresh &lt; 0):\n        raise ValueError(\n            f\"comb_mask: cthresh must be between 0 and {cth_max} when metric = {metric}.\"\n        )\n    if (mthresh &gt; 255) or (mthresh &lt; 0):\n        raise ValueError(\"comb_mask: mthresh must be between 0 and 255.\")\n    if planes is None:\n        planes = list(range(clip.format.num_planes))\n    if isinstance(planes, int):\n        planes = [planes]\n\n    peak = get_peak_value(clip)\n    ex_m0 = [\n        f\"x[0,-2] a! x[0,-1] b! x c! x[0,1] d! x[0,2] e! \"\n        f\"c@ b@ - d1! c@ d@ - d2! \"\n        f\"c@ 4 * a@ + e@ + b@ d@ + 3 * - abs fd! \"\n        f\"d1@ {cthresh} &gt; d2@ {cthresh} &gt; and \"\n        f\"d1@ -{cthresh} &lt; d2@ -{cthresh} &lt; and or \"\n        f\"fd@ {cthresh * 6} &gt; and {peak} 0 ?\"\n    ]\n\n    ex_m1 = [f\"x[0,-1] x - x[0,1] x - * {cthresh} &gt; {peak} 0 ?\"]\n    ex_motion = [f\"x y - abs {mthresh} &gt; {peak} 0 ?\"]\n    ex_spatial = ex_m1 if metric else ex_m0\n\n    spatial_mask = clip.akarin.Expr(ex_planes(clip, ex_spatial, planes))\n    if mthresh == 0:\n        return (\n            spatial_mask\n            if not expand\n            else maximum(\n                spatial_mask, planes=planes, coordinates=[0, 0, 0, 1, 1, 0, 0, 0]\n            )\n        )\n\n    motion_mask = core.akarin.Expr(\n        [clip, clip[0] + clip], ex_planes(clip, ex_motion, planes)\n    )\n    motion_mask = maximum(\n        motion_mask, planes=planes, coordinates=[0, 1, 0, 0, 0, 0, 1, 0]\n    )\n    comb_mask = core.akarin.Expr([spatial_mask, motion_mask], \"x y min\")\n\n    return (\n        comb_mask\n        if not expand\n        else maximum(comb_mask, planes=planes, coordinates=[0, 0, 0, 1, 1, 0, 0, 0])\n    )\n</code></pre>"},{"location":"API/filter/mask/#y5gfunc.filter.mask.comb_mask(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/mask/#y5gfunc.filter.mask.comb_mask(cthresh)","title":"<code>cthresh</code>","text":""},{"location":"API/filter/mask/#y5gfunc.filter.mask.comb_mask(mthresh)","title":"<code>mthresh</code>","text":""},{"location":"API/filter/mask/#y5gfunc.filter.mask.comb_mask(expand)","title":"<code>expand</code>","text":""},{"location":"API/filter/mask/#y5gfunc.filter.mask.comb_mask(metric)","title":"<code>metric</code>","text":""},{"location":"API/filter/mask/#y5gfunc.filter.mask.comb_mask(planes)","title":"<code>planes</code>","text":""},{"location":"API/filter/morpho/","title":"<code>y5gfunc.filter.morpho</code>","text":""},{"location":"API/filter/morpho/#y5gfunc.filter.morpho","title":"morpho","text":"<p>Functions:</p> Name Description <code>minimum</code> <code>maximum</code> <code>convolution</code> <code>inflate</code> <code>deflate</code> <p>Attributes:</p> Name Type Description <code>NEIGHBOR_OFFSETS</code>"},{"location":"API/filter/morpho/#y5gfunc.filter.morpho.NEIGHBOR_OFFSETS","title":"NEIGHBOR_OFFSETS  <code>module-attribute</code>","text":"<pre><code>NEIGHBOR_OFFSETS = [(-1, -1), (0, -1), (1, -1), (-1, 0), (1, 0), (-1, 1), (0, 1), (1, 1)]\n</code></pre>"},{"location":"API/filter/morpho/#y5gfunc.filter.morpho.minimum","title":"minimum","text":"<pre><code>minimum(clip: VideoNode, planes: Optional[Union[list[int], int]] = None, threshold: Optional[float] = None, coordinates: list[int] = [1, 1, 1, 1, 1, 1, 1, 1], boundary: int = 1, use_std: bool = is_optimized_cpu()) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/morpho.py</code> <pre><code>def minimum(\n    clip: vs.VideoNode,\n    planes: Optional[Union[list[int], int]] = None,\n    threshold: Optional[float] = None,\n    coordinates: list[int] = [1, 1, 1, 1, 1, 1, 1, 1],\n    boundary: int = 1,\n    use_std: bool = is_optimized_cpu(),\n) -&gt; vs.VideoNode:\n    if use_std:\n        return core.std.Minimum(clip, planes, threshold, coordinates)  # type: ignore\n    else:\n        return _create_minmax_expr(\n            clip,\n            \"min! drop{} min@\".format(sum(coordinates)),\n            \" x[0,0] {} - swap max\",\n            planes,\n            threshold,\n            coordinates,\n            boundary,\n        )\n</code></pre>"},{"location":"API/filter/morpho/#y5gfunc.filter.morpho.maximum","title":"maximum","text":"<pre><code>maximum(clip: VideoNode, planes: Optional[Union[list[int], int]] = None, threshold: Optional[float] = None, coordinates: list[int] = [1, 1, 1, 1, 1, 1, 1, 1], boundary: int = 1, use_std: bool = is_optimized_cpu()) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/morpho.py</code> <pre><code>def maximum(\n    clip: vs.VideoNode,\n    planes: Optional[Union[list[int], int]] = None,\n    threshold: Optional[float] = None,\n    coordinates: list[int] = [1, 1, 1, 1, 1, 1, 1, 1],\n    boundary: int = 1,\n    use_std: bool = is_optimized_cpu(),\n) -&gt; vs.VideoNode:\n    if use_std:\n        return core.std.Maximum(clip, planes, threshold, coordinates)  # type: ignore\n    else:\n        return _create_minmax_expr(\n            clip,\n            \"drop{}\".format(sum(coordinates)),\n            \" x[0,0] {} + swap min\",\n            planes,\n            threshold,\n            coordinates,\n            boundary,\n        )\n</code></pre>"},{"location":"API/filter/morpho/#y5gfunc.filter.morpho.convolution","title":"convolution","text":"<pre><code>convolution(clip: VideoNode, matrix: list[int], bias: float = 0.0, divisor: float = 0.0, planes: Optional[Union[list[int], int]] = None, saturate: bool = True, mode: str = 's', use_std: bool = is_optimized_cpu()) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/morpho.py</code> <pre><code>def convolution(\n    clip: vs.VideoNode,\n    matrix: list[int],\n    bias: float = 0.0,\n    divisor: float = 0.0,\n    planes: Optional[Union[list[int], int]] = None,\n    saturate: bool = True,\n    mode: str = \"s\",\n    use_std: bool = is_optimized_cpu(),\n) -&gt; vs.VideoNode:\n    if planes is None:\n        planes = list(range(clip.format.num_planes))\n    if isinstance(planes, int):\n        planes = [planes]\n\n    if mode != \"s\" or len(matrix) != 9 or use_std:\n        return core.std.Convolution(clip, matrix, bias, divisor, planes, saturate, mode)\n\n    if len(matrix) == 9:\n        if abs(divisor) &lt; 1e-9:\n            actual_divisor = sum(matrix) if abs(sum(matrix)) &gt; 1e-9 else 1.0\n        else:\n            actual_divisor = divisor\n\n        coeffs = [f\"{c:.6f}\" for c in matrix]\n\n        expr_parts = []\n\n        if len(matrix) == 9:\n            offsets = [\n                (-1, -1),\n                (0, -1),\n                (1, -1),\n                (-1, 0),\n                (0, 0),\n                (1, 0),\n                (-1, 1),\n                (0, 1),\n                (1, 1),\n            ]\n\n        for i, (dx, dy) in enumerate(offsets):\n            expr_parts.append(f\"x[{dx},{dy}] {coeffs[i]} *\")\n            if i &gt; 0:\n                expr_parts.append(\"+\")\n\n        expr_parts.append(f\" {actual_divisor:.6f} / {bias:.6f} + \")\n\n        peak = get_peak_value(clip)\n\n        if saturate:\n            expr_parts.append(f\"0 {peak} clip\")\n        else:\n            expr_parts.append(\"abs\")\n            expr_parts.append(f\"{peak} min\")\n\n        expr = \" \".join(expr_parts)\n        expressions = [\n            expr if i in planes else \"x\" for i in range(clip.format.num_planes)\n        ]\n\n        return core.akarin.Expr(clip, expressions, boundary=1)\n\n    return core.std.Convolution(clip, matrix, bias, divisor, planes, saturate, mode)\n</code></pre>"},{"location":"API/filter/morpho/#y5gfunc.filter.morpho.inflate","title":"inflate","text":"<pre><code>inflate(clip: VideoNode, planes: Optional[Union[list[int], int]] = None, threshold: Optional[float] = None, boundary: int = 1, use_std: bool = is_optimized_cpu()) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/morpho.py</code> <pre><code>def inflate(\n    clip: vs.VideoNode,\n    planes: Optional[Union[list[int], int]] = None,\n    threshold: Optional[float] = None,\n    boundary: int = 1,\n    use_std: bool = is_optimized_cpu(),\n) -&gt; vs.VideoNode:\n    if planes is None:\n        planes = list(range(clip.format.num_planes))\n    if isinstance(planes, int):\n        planes = [planes]\n\n    if use_std:\n        return core.std.Inflate(clip, planes, threshold)  # type: ignore\n\n    expr_parts = []\n\n    for i, (dx, dy) in enumerate(NEIGHBOR_OFFSETS):\n        expr_parts.append(f\"x[{dx},{dy}] 8 / \")\n        if i &gt; 0:\n            expr_parts.append(\"+ \")\n\n    expr_parts.append(\"x max\")\n    if threshold:\n        expr_parts.append(f\" x {threshold} + min\")\n    expr = \"\".join(expr_parts)\n\n    expressions = [\n        expr if (i in planes) else \"x\" for i in range(clip.format.num_planes)\n    ]\n\n    return core.akarin.Expr(clips=[clip], expr=expressions, boundary=boundary)\n</code></pre>"},{"location":"API/filter/morpho/#y5gfunc.filter.morpho.deflate","title":"deflate","text":"<pre><code>deflate(clip: VideoNode, planes: Optional[Union[list[int], int]] = None, threshold: Optional[float] = None, boundary: int = 1, use_std: bool = is_optimized_cpu()) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/morpho.py</code> <pre><code>def deflate(\n    clip: vs.VideoNode,\n    planes: Optional[Union[list[int], int]] = None,\n    threshold: Optional[float] = None,\n    boundary: int = 1,\n    use_std: bool = is_optimized_cpu(),\n) -&gt; vs.VideoNode:\n    if planes is None:\n        planes = list(range(clip.format.num_planes))\n    if isinstance(planes, int):\n        planes = [planes]\n\n    if use_std:\n        return core.std.Deflate(clip, planes, threshold)  # type: ignore\n\n    expr_parts = []\n\n    for i, (dx, dy) in enumerate(NEIGHBOR_OFFSETS):\n        expr_parts.append(f\"x[{dx},{dy}] 8 / \")\n        if i &gt; 0:\n            expr_parts.append(\"+\")\n\n    expr_parts.append(\"x min\")\n    if threshold:\n        expr_parts.append(f\" x {threshold} - max\")\n    expr = \"\".join(expr_parts)\n\n    expressions = [\n        expr if (i in planes) else \"x\" for i in range(clip.format.num_planes)\n    ]\n\n    return core.akarin.Expr(clips=[clip], expr=expressions, boundary=boundary)\n</code></pre>"},{"location":"API/filter/resample/","title":"<code>y5gfunc.filter.resample</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample","title":"resample","text":"<p>Classes:</p> Name Description <code>ColorMatrixManager</code> <p>Manager for a specific RGB-OPP conversion matrix and its related transformations.</p> <p>Functions:</p> Name Description <code>register_opp_matrix</code> <p>Register a new OPP matrix variant and create its manager.</p> <code>yuv2opp</code> <p>Convert YUV to OPP color space.</p> <code>opp2yuv</code> <p>Convert OPP to YUV color space.</p> <code>rgb2opp</code> <p>Convert RGB to OPP color space.</p> <code>opp2rgb</code> <p>Convert OPP to RGB color space.</p> <code>nn2x</code> <p>Doubles the resolution of input clip with nnedi3.</p> <code>Gammarize</code> <code>SSIM_downsample</code> <p>SSIM downsampler</p> <code>Descale</code> <p>Attributes:</p> Name Type Description <code>STANDARD_OPP</code> <code>NORMALIZED_OPP</code> <code>MAWEN_OPP</code> <code>default_opp</code>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.STANDARD_OPP","title":"STANDARD_OPP  <code>module-attribute</code>","text":"<pre><code>STANDARD_OPP = register_opp_matrix('standard', Matrix([[Rational(1, 3), Rational(1, 3), Rational(1, 3)], [Rational(1, 2), Rational(-1, 2), 0], [Rational(1, 4), Rational(1, 4), Rational(-1, 2)]]))\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.NORMALIZED_OPP","title":"NORMALIZED_OPP  <code>module-attribute</code>","text":"<pre><code>NORMALIZED_OPP = register_opp_matrix('normalized', Matrix([[Rational(1, 3), Rational(1, 3), Rational(1, 3)], [S(1) / sqrt(6), S(-1) / sqrt(6), 0], [S(1) / sqrt(18), S(1) / sqrt(18), S(-2) / sqrt(18)]]))\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.MAWEN_OPP","title":"MAWEN_OPP  <code>module-attribute</code>","text":"<pre><code>MAWEN_OPP = register_opp_matrix('mawen', Matrix([[Rational(1, 3), Rational(1, 3), Rational(1, 3)], [Rational(1, 2), 0, Rational(-1, 2)], [Rational(1, 4), Rational(-1, 2), Rational(1, 4)]]))\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.default_opp","title":"default_opp  <code>module-attribute</code>","text":"<pre><code>default_opp = STANDARD_OPP\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager","title":"ColorMatrixManager","text":"<pre><code>ColorMatrixManager(rgb_opp_matrix: Matrix, name: str)\n</code></pre> <p>Manager for a specific RGB-OPP conversion matrix and its related transformations.</p> <p>Initialize the ColorMatrixManager with a specific RGB to OPP matrix.</p> <p>Parameters:</p> Name Type Description Default <code>Matrix</code> <p>A 3x3 sympy.Matrix for RGB to OPP conversion</p> required <code>str</code> <p>Identifier for this specific OPP transform variant</p> required <p>Methods:</p> Name Description <code>register_yuv_matrix</code> <p>Register a YUV to RGB matrix type.</p> <code>initialize</code> <p>Initialize all matrices and coefficients.</p> <code>get_yuv_to_opp_coefs</code> <p>Get YUV to OPP conversion coefficients for a specific matrix type.</p> <code>get_opp_to_yuv_coefs</code> <p>Get OPP to YUV conversion coefficients for a specific matrix type.</p> <code>get_rgb_to_opp_coefs</code> <p>Get RGB to OPP conversion coefficients.</p> <code>get_opp_to_rgb_coefs</code> <p>Get OPP to RGB conversion coefficients.</p> <p>Attributes:</p> Name Type Description <code>name</code> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def __init__(self, rgb_opp_matrix: sympy.Matrix, name: str):\n    \"\"\"\n    Initialize the ColorMatrixManager with a specific RGB to OPP matrix.\n\n    Args:\n        rgb_opp_matrix: A 3x3 sympy.Matrix for RGB to OPP conversion\n        name: Identifier for this specific OPP transform variant\n    \"\"\"\n    self._rgb_opp_matrix = rgb_opp_matrix\n    self._rgb_from_opp_matrix = rgb_opp_matrix.inv()\n    self.name = name\n\n    self._yuv_to_rgb_matrices: dict[vstools.Matrix, sympy.Matrix] = {}\n    self._yuv_to_opp_matrices: dict[vstools.Matrix, sympy.Matrix] = {}\n    self._opp_to_yuv_matrices: dict[vstools.Matrix, sympy.Matrix] = {}\n\n    self._yuv_to_opp_coefs: dict[vstools.Matrix, list[float]] = {}\n    self._opp_to_yuv_coefs: dict[vstools.Matrix, list[float]] = {}\n\n    self._rgb_to_opp_coefs: Optional[list[float]] = None\n    self._opp_to_rgb_coefs: Optional[list[float]] = None\n\n    self._initialized = False\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager(rgb_opp_matrix)","title":"<code>rgb_opp_matrix</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager(name)","title":"<code>name</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name = name\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager.register_yuv_matrix","title":"register_yuv_matrix","text":"<pre><code>register_yuv_matrix(matrix_ids: Union[Matrix, list[Matrix]], yuv_to_rgb_matrix: Matrix) -&gt; None\n</code></pre> <p>Register a YUV to RGB matrix type.</p> <p>Parameters:</p> Name Type Description Default <code>Union[Matrix, list[Matrix]]</code> <p>The matrix id</p> required <code>Matrix</code> <p>A sympy 3x3 Matrix representing YUV-&gt;RGB conversion</p> required Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def register_yuv_matrix(\n    self,\n    matrix_ids: Union[vstools.Matrix, list[vstools.Matrix]],\n    yuv_to_rgb_matrix: sympy.Matrix,\n) -&gt; None:\n    \"\"\"\n    Register a YUV to RGB matrix type.\n\n    Args:\n        matrix_ids: The matrix id\n        yuv_to_rgb_matrix: A sympy 3x3 Matrix representing YUV-&gt;RGB conversion\n    \"\"\"\n    if isinstance(matrix_ids, vstools.Matrix):\n        matrix_ids = [matrix_ids]\n\n    for matrix_id in matrix_ids:\n        self._yuv_to_rgb_matrices[matrix_id] = yuv_to_rgb_matrix\n        if self._initialized:\n            self._recalculate_for_matrix(matrix_id)\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager.register_yuv_matrix(matrix_ids)","title":"<code>matrix_ids</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager.register_yuv_matrix(yuv_to_rgb_matrix)","title":"<code>yuv_to_rgb_matrix</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager.initialize","title":"initialize","text":"<pre><code>initialize() -&gt; None\n</code></pre> <p>Initialize all matrices and coefficients.</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def initialize(self) -&gt; None:\n    \"\"\"Initialize all matrices and coefficients.\"\"\"\n    if self._initialized:\n        return\n\n    # Calculate direct RGB\u2194OPP coefficients\n    self._rgb_to_opp_coefs = self._matrix_to_coefs(self._rgb_opp_matrix)\n    self._opp_to_rgb_coefs = self._matrix_to_coefs(self._rgb_from_opp_matrix)\n\n    # Calculate matrices and coefficients for all registered matrix types\n    for matrix_type in self._yuv_to_rgb_matrices:\n        self._recalculate_for_matrix(matrix_type)\n\n    self._initialized = True\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager.get_yuv_to_opp_coefs","title":"get_yuv_to_opp_coefs","text":"<pre><code>get_yuv_to_opp_coefs(matrix_type: Matrix) -&gt; list[float]\n</code></pre> <p>Get YUV to OPP conversion coefficients for a specific matrix type.</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def get_yuv_to_opp_coefs(self, matrix_type: vstools.Matrix) -&gt; list[float]:\n    \"\"\"Get YUV to OPP conversion coefficients for a specific matrix type.\"\"\"\n    if not self._initialized:\n        self.initialize()\n\n    if matrix_type not in self._yuv_to_opp_coefs:\n        raise ValueError(f\"Unsupported matrix type: {matrix_type}\")\n\n    return self._yuv_to_opp_coefs[matrix_type]\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager.get_opp_to_yuv_coefs","title":"get_opp_to_yuv_coefs","text":"<pre><code>get_opp_to_yuv_coefs(matrix_type: Matrix) -&gt; list[float]\n</code></pre> <p>Get OPP to YUV conversion coefficients for a specific matrix type.</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def get_opp_to_yuv_coefs(self, matrix_type: vstools.Matrix) -&gt; list[float]:\n    \"\"\"Get OPP to YUV conversion coefficients for a specific matrix type.\"\"\"\n    if not self._initialized:\n        self.initialize()\n\n    if matrix_type not in self._opp_to_yuv_coefs:\n        raise ValueError(f\"Unsupported matrix type: {matrix_type}\")\n\n    return self._opp_to_yuv_coefs[matrix_type]\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager.get_rgb_to_opp_coefs","title":"get_rgb_to_opp_coefs","text":"<pre><code>get_rgb_to_opp_coefs() -&gt; list[float]\n</code></pre> <p>Get RGB to OPP conversion coefficients.</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def get_rgb_to_opp_coefs(self) -&gt; list[float]:\n    \"\"\"Get RGB to OPP conversion coefficients.\"\"\"\n    if not self._initialized:\n        self.initialize()\n\n    return self._rgb_to_opp_coefs  # type: ignore\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.ColorMatrixManager.get_opp_to_rgb_coefs","title":"get_opp_to_rgb_coefs","text":"<pre><code>get_opp_to_rgb_coefs() -&gt; list[float]\n</code></pre> <p>Get OPP to RGB conversion coefficients.</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def get_opp_to_rgb_coefs(self) -&gt; list[float]:\n    \"\"\"Get OPP to RGB conversion coefficients.\"\"\"\n    if not self._initialized:\n        self.initialize()\n\n    return self._opp_to_rgb_coefs  # type: ignore\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.register_opp_matrix","title":"register_opp_matrix","text":"<pre><code>register_opp_matrix(name: str, rgb_opp_matrix: Matrix) -&gt; ColorMatrixManager\n</code></pre> <p>Register a new OPP matrix variant and create its manager.</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Name identifier for this OPP variant</p> required <code>Matrix</code> <p>The 3x3 RGB to OPP conversion matrix</p> required <p>Returns:</p> Type Description <code>ColorMatrixManager</code> <p>The created ColorMatrixManager instance</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def register_opp_matrix(name: str, rgb_opp_matrix: sympy.Matrix) -&gt; ColorMatrixManager:\n    \"\"\"\n    Register a new OPP matrix variant and create its manager.\n\n    Args:\n        name: Name identifier for this OPP variant\n        rgb_opp_matrix: The 3x3 RGB to OPP conversion matrix\n\n    Returns:\n        The created ColorMatrixManager instance\n    \"\"\"\n    if name in _opp_managers:\n        raise ValueError(f\"OPP matrix variant '{name}' already registered\")\n\n    manager = ColorMatrixManager(rgb_opp_matrix, name)\n    _register_standard_matrices(manager)\n    _opp_managers[name] = manager\n    return manager\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.register_opp_matrix(name)","title":"<code>name</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.register_opp_matrix(rgb_opp_matrix)","title":"<code>rgb_opp_matrix</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.yuv2opp","title":"yuv2opp","text":"<pre><code>yuv2opp(clip: VideoNode, matrix_in: Optional[Matrix] = None, range_in: Optional[ColorRange] = None, opp_manager: ColorMatrixManager = default_opp) -&gt; VideoNode\n</code></pre> <p>Convert YUV to OPP color space.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input YUV clip</p> required <code>Optional[Matrix]</code> <p>Source matrix override, if None, read from clip properties</p> <code>None</code> <code>Optional[ColorRange]</code> <p>Source range override, if None, read from clip properties</p> <code>None</code> <code>ColorMatrixManager</code> <p>ColorMatrixManager for the specific OPP variant to use</p> <code>default_opp</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Clip in OPP color space with appropriate frame properties</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def yuv2opp(\n    clip: vs.VideoNode,\n    matrix_in: Optional[vstools.Matrix] = None,\n    range_in: Optional[ColorRange] = None,\n    opp_manager: ColorMatrixManager = default_opp,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Convert YUV to OPP color space.\n\n    Args:\n        clip: Input YUV clip\n        matrix_in: Source matrix override, if None, read from clip properties\n        range_in: Source range override, if None, read from clip properties\n        opp_manager: ColorMatrixManager for the specific OPP variant to use\n\n    Returns:\n        Clip in OPP color space with appropriate frame properties\n    \"\"\"\n    if matrix_in is None:\n        matrix_in = vstools.Matrix.from_video(clip, strict=True)\n    if range_in is None:\n        range_in = ColorRange.from_video(clip, strict=True)\n\n    coef = opp_manager.get_yuv_to_opp_coefs(matrix_in)\n\n    opp = core.fmtc.matrix(\n        clip, fulls=not range_in, fulld=True, col_fam=vs.YUV, coef=coef\n    )\n    return opp.std.SetFrameProps(\n        _Matrix=vs.MATRIX_UNSPECIFIED,\n        BM3D_OPP=1,\n        BM3D_OPP_VARIANT=opp_manager.name,\n        BM3D_OPP_SRC_RANGE=range_in,\n        BM3D_OPP_SRC_MATRIX=matrix_in,\n    )\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.yuv2opp(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.yuv2opp(matrix_in)","title":"<code>matrix_in</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.yuv2opp(range_in)","title":"<code>range_in</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.yuv2opp(opp_manager)","title":"<code>opp_manager</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.opp2yuv","title":"opp2yuv","text":"<pre><code>opp2yuv(clip: VideoNode, target_matrix: Optional[Matrix] = None, target_range: Optional[ColorRange] = None, opp_manager: Optional[ColorMatrixManager] = None) -&gt; VideoNode\n</code></pre> <p>Convert OPP to YUV color space.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input OPP clip</p> required <code>Optional[Matrix]</code> <p>Target YUV color space, if None, read from clip properties</p> <code>None</code> <code>Optional[ColorRange]</code> <p>Target range, if None, read from clip properties</p> <code>None</code> <code>Optional[ColorMatrixManager]</code> <p>ColorMatrixManager for the specific OPP variant, if None, read from clip properties</p> <code>None</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Clip in YUV color space</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def opp2yuv(\n    clip: vs.VideoNode,\n    target_matrix: Optional[vstools.Matrix] = None,\n    target_range: Optional[ColorRange] = None,\n    opp_manager: Optional[ColorMatrixManager] = None,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Convert OPP to YUV color space.\n\n    Args:\n        clip: Input OPP clip\n        target_matrix: Target YUV color space, if None, read from clip properties\n        target_range: Target range, if None, read from clip properties\n        opp_manager: ColorMatrixManager for the specific OPP variant, if None, read from clip properties\n\n    Returns:\n        Clip in YUV color space\n    \"\"\"\n    assert (\n        get_prop(clip, \"BM3D_OPP\", int) == 1\n    ), \"Input must be an OPP clip (BM3D_OPP=1)\"\n\n    if opp_manager is None:\n        variant_name = get_prop(clip, \"BM3D_OPP_VARIANT\", str, str)\n        if variant_name not in _opp_managers:\n            raise ValueError(f\"Unknown OPP variant: {variant_name}\")\n        opp_manager = _opp_managers[variant_name]\n\n    if target_matrix is None:\n        target_matrix = get_prop(clip, \"BM3D_OPP_SRC_MATRIX\", int, vstools.Matrix)\n\n    primaries = Primaries.from_matrix(target_matrix)\n    transfer = Transfer.from_matrix(target_matrix)\n\n    if target_range is None:\n        target_range = get_prop(clip, \"BM3D_OPP_SRC_RANGE\", int, ColorRange)\n\n    coef = opp_manager.get_opp_to_yuv_coefs(target_matrix)  # type: ignore\n\n    yuv = core.fmtc.matrix(\n        clip, fulls=True, fulld=not target_range, col_fam=vs.YUV, coef=coef\n    )\n    return yuv.std.SetFrameProps(\n        _Matrix=target_matrix, _Primaries=primaries, _Transfer=transfer\n    ).std.RemoveFrameProps(\n        [\"BM3D_OPP\", \"BM3D_OPP_VARIANT\", \"BM3D_OPP_SRC_MATRIX\", \"BM3D_OPP_SRC_RANGE\"]\n    )\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.opp2yuv(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.opp2yuv(target_matrix)","title":"<code>target_matrix</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.opp2yuv(target_range)","title":"<code>target_range</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.opp2yuv(opp_manager)","title":"<code>opp_manager</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.rgb2opp","title":"rgb2opp","text":"<pre><code>rgb2opp(clip: VideoNode, opp_manager: ColorMatrixManager = default_opp) -&gt; VideoNode\n</code></pre> <p>Convert RGB to OPP color space.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input RGB clip</p> required <code>ColorMatrixManager</code> <p>ColorMatrixManager for the specific OPP variant to use</p> <code>default_opp</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Clip in OPP color space</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def rgb2opp(\n    clip: vs.VideoNode,\n    opp_manager: ColorMatrixManager = default_opp,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Convert RGB to OPP color space.\n\n    Args:\n        clip: Input RGB clip\n        opp_manager: ColorMatrixManager for the specific OPP variant to use\n\n    Returns:\n        Clip in OPP color space\n    \"\"\"\n    assert clip.format.color_family == vs.RGB, \"Input must be in RGB format\"\n\n    coef = opp_manager.get_rgb_to_opp_coefs()\n\n    opp = core.fmtc.matrix(clip, fulls=True, fulld=True, col_fam=vs.YUV, coef=coef)\n    return opp.std.SetFrameProps(\n        _Matrix=vs.MATRIX_UNSPECIFIED, BM3D_OPP=1, BM3D_OPP_VARIANT=opp_manager.name\n    )\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.rgb2opp(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.rgb2opp(opp_manager)","title":"<code>opp_manager</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.opp2rgb","title":"opp2rgb","text":"<pre><code>opp2rgb(clip: VideoNode, opp_manager: Optional[ColorMatrixManager] = None) -&gt; VideoNode\n</code></pre> <p>Convert OPP to RGB color space.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input OPP clip</p> required <code>Optional[ColorMatrixManager]</code> <p>ColorMatrixManager for the specific OPP variant, if None, read from clip properties</p> <code>None</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Clip in RGB color space</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def opp2rgb(\n    clip: vs.VideoNode,\n    opp_manager: Optional[ColorMatrixManager] = None,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Convert OPP to RGB color space.\n\n    Args:\n        clip: Input OPP clip\n        opp_manager: ColorMatrixManager for the specific OPP variant, if None, read from clip properties\n\n    Returns:\n        Clip in RGB color space\n    \"\"\"\n    assert (\n        get_prop(clip, \"BM3D_OPP\", int) == 1\n    ), \"Input must be an OPP clip (BM3D_OPP=1)\"\n\n    if opp_manager is None:\n        variant_name = get_prop(clip, \"BM3D_OPP_VARIANT\", str, str, \"standard\")\n        if variant_name not in _opp_managers:\n            raise ValueError(f\"Unknown OPP variant: {variant_name}\")\n        opp_manager = _opp_managers[variant_name]\n\n    coef = opp_manager.get_opp_to_rgb_coefs()  # type: ignore\n\n    rgb = core.fmtc.matrix(clip, fulls=True, fulld=True, col_fam=vs.RGB, coef=coef)\n    return rgb.std.SetFrameProps(\n        _Matrix=vstools.Matrix.RGB, _Transfer=Transfer.SRGB\n    ).std.RemoveFrameProps(\n        [\"BM3D_OPP\", \"BM3D_OPP_VARIANT\", \"BM3D_OPP_SRC_MATRIX\", \"BM3D_OPP_SRC_RANGE\"]\n    )\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.opp2rgb(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.opp2rgb(opp_manager)","title":"<code>opp_manager</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.nn2x","title":"nn2x","text":"<pre><code>nn2x(clip: VideoNode, opencl: bool = True, nnedi3_args: dict[str, int] = {'field': 1, 'nsize': 4, 'nns': 4, 'qual': 2}) -&gt; VideoNode\n</code></pre> <p>Doubles the resolution of input clip with nnedi3.</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def nn2x(\n    clip: vs.VideoNode,\n    opencl: bool = True,\n    nnedi3_args: dict[str, int] = {\"field\": 1, \"nsize\": 4, \"nns\": 4, \"qual\": 2},\n) -&gt; vs.VideoNode:\n    \"\"\"Doubles the resolution of input clip with nnedi3.\"\"\"\n    if hasattr(core, \"sneedif\") and opencl:\n        nnedi3 = functools.partial(core.sneedif.NNEDI3, **nnedi3_args)\n        return nnedi3(nnedi3(clip, dh=True), dw=True)\n    elif hasattr(core, \"nnedi3cl\") and opencl:\n        nnedi3 = functools.partial(core.nnedi3cl.NNEDI3CL, **nnedi3_args)\n        return nnedi3(nnedi3(clip, dh=True), dw=True)\n    else:\n        nnedi3 = functools.partial(core.nnedi3.nnedi3, **nnedi3_args)\n        return nnedi3(nnedi3(clip, dh=True).std.Transpose(), dh=True).std.Transpose()\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.Gammarize","title":"Gammarize","text":"<pre><code>Gammarize(clip: VideoNode, gamma, tvrange=False) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def Gammarize(clip: vs.VideoNode, gamma, tvrange=False) -&gt; vs.VideoNode:\n    if clip.format.name.startswith(\"YUV\"):\n        is_yuv = True\n        y = get_y(clip)\n    elif clip.format.name.startswith(\"Gray\"):\n        is_yuv = False\n        y = clip\n    else:\n        raise ValueError(\"Gammarize: Input clip must be either YUV or GRAY.\")\n\n    range = ColorRange.LIMITED if tvrange else ColorRange.FULL\n\n    thrl = get_lowest_value(clip, range_in=range)\n    thrh = get_peak_value(clip, range_in=range)\n    rng = scale_mask(219, 8, clip) if tvrange else scale_mask(255, 8, clip)\n    corrected = y.akarin.Expr(\n        f\"x {rng} / {gamma} pow {rng} * {thrl} + {thrl} max {thrh} min\"\n    )\n\n    return join(corrected, clip) if is_yuv else corrected\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample","title":"SSIM_downsample","text":"<pre><code>SSIM_downsample(clip: VideoNode, width: int, height: int, smooth: Union[float, Callable] = 1, gamma: bool = True, fulls: bool = False, fulld: bool = False, curve: str = '709', sigmoid: bool = True, epsilon: float = 1e-06, **rersample_args: Any) -&gt; VideoNode\n</code></pre> <p>SSIM downsampler</p> <p>SSIM downsampler is an image downscaling technique that aims to optimize for the perceptual quality of the downscaled results. Image downscaling is considered as an optimization problem where the difference between the input and output images is measured using famous Structural SIMilarity (SSIM) index. The solution is derived in closed-form, which leads to the simple, efficient implementation. The downscaled images retain perceptually important features and details, resulting in an accurate and spatio-temporally consistent representation of the high resolution input.</p> <p>All the internal calculations are done at 32-bit float, except gamma correction is done at integer.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>The input clip.</p> required <code>int</code> <p>The width of the output clip.</p> required <code>int</code> <p>The height of the output clip</p> required <code>Union[float, Callable]</code> <p>The method to smooth the image. If it's an int, it specifies the \"radius\" of the internel used boxfilter, i.e. the window has a size of (2smooth+1)x(2smooth+1). If it's a float, it specifies the \"sigma\" of core.tcanny.TCanny, i.e. the standard deviation of gaussian blur. If it's a function, it acs as a general smoother.</p> <code>1</code> <code>bool</code> <p>Set to true to turn on gamma correction for the y channel.</p> <code>True</code> <code>bool</code> <p>Specifies if the luma is limited range (False) or full range (True)</p> <code>False</code> <code>bool</code> <p>Same as fulls, but for output.</p> <code>False</code> <code>str</code> <p>Type of gamma mapping.</p> <code>'709'</code> <code>bool</code> <p>When True, applies a sigmoidal curve after the power-like curve (or before when converting from linear to gamma-corrected). This helps reducing the dark halo artefacts around sharp edges caused by resizing in linear luminance.</p> <code>True</code> <p>Additional arguments passed to <code>core.resize2</code> in the form of keyword arguments.</p> required <p>Returns:</p> Type Description <code>VideoNode</code> <p>Downsampled clip in 32-bit format.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>smooth</code> is neigher a int, float nor a function.</p> Ref <p>[1] Oeztireli, A. C., &amp; Gross, M. (2015). Perceptually based downscaling of images. ACM Transactions on Graphics (TOG), 34(4), 77.</p> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def SSIM_downsample(\n    clip: vs.VideoNode,\n    width: int,\n    height: int,\n    smooth: Union[float, Callable] = 1,\n    gamma: bool = True,\n    fulls: bool = False,\n    fulld: bool = False,\n    curve: str = \"709\",\n    sigmoid: bool = True,\n    epsilon: float = 1e-6,\n    **rersample_args: Any,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    SSIM downsampler\n\n    SSIM downsampler is an image downscaling technique that aims to optimize for the perceptual quality of the downscaled results.\n    Image downscaling is considered as an optimization problem\n    where the difference between the input and output images is measured using famous Structural SIMilarity (SSIM) index.\n    The solution is derived in closed-form, which leads to the simple, efficient implementation.\n    The downscaled images retain perceptually important features and details,\n    resulting in an accurate and spatio-temporally consistent representation of the high resolution input.\n\n    All the internal calculations are done at 32-bit float, except gamma correction is done at integer.\n\n    Args:\n        clip: The input clip.\n        width: The width of the output clip.\n        height: The height of the output clip\n        smooth: The method to smooth the image.\n            If it's an int, it specifies the \"radius\" of the internel used boxfilter, i.e. the window has a size of (2*smooth+1)x(2*smooth+1).\n            If it's a float, it specifies the \"sigma\" of core.tcanny.TCanny, i.e. the standard deviation of gaussian blur.\n            If it's a function, it acs as a general smoother.\n        gamma: Set to true to turn on gamma correction for the y channel.\n        fulls: Specifies if the luma is limited range (False) or full range (True)\n        fulld: Same as fulls, but for output.\n        curve: Type of gamma mapping.\n        sigmoid: When True, applies a sigmoidal curve after the power-like curve (or before when converting from linear to gamma-corrected).\n            This helps reducing the dark halo artefacts around sharp edges caused by resizing in linear luminance.\n        resample_args: Additional arguments passed to `core.resize2` in the form of keyword arguments.\n\n    Returns:\n        Downsampled clip in 32-bit format.\n\n    Raises:\n        TypeError: If `smooth` is neigher a int, float nor a function.\n\n    Ref:\n        [1] Oeztireli, A. C., &amp; Gross, M. (2015). Perceptually based downscaling of images. ACM Transactions on Graphics (TOG), 34(4), 77.\n\n    \"\"\"\n    if callable(smooth):\n        Filter = smooth\n    elif isinstance(smooth, int):\n        Filter = functools.partial(box_blur, radius=smooth + 1)\n    elif isinstance(smooth, float):\n        Filter = functools.partial(core.tcanny.TCanny, sigma=smooth, mode=-1)\n    else:\n        raise TypeError('SSIM_downsample: \"smooth\" must be a int, float or a function!')\n\n    if gamma:\n        import nnedi3_resample as nnrs\n\n        clip = nnrs.GammaToLinear(\n            depth(clip, 16),\n            fulls=fulls,\n            fulld=fulld,\n            curve=curve,\n            sigmoid=sigmoid,\n            planes=[0],\n        )\n\n    clip = depth(clip, 32)\n\n    l1 = core.resize2.Bicubic(clip, width, height, **rersample_args)  # type: ignore\n    l2 = core.resize2.Bicubic(\n        core.akarin.Expr([clip], [\"x 2 **\"]),\n        width,\n        height,\n        **rersample_args,  # type: ignore\n    )\n\n    m = Filter(l1)\n    sl_plus_m_square = Filter(core.akarin.Expr([l1], [\"x 2 **\"]))\n    sh_plus_m_square = Filter(l2)\n    m_square = core.akarin.Expr([m], [\"x 2 **\"])\n    r = core.akarin.Expr(\n        [sl_plus_m_square, sh_plus_m_square, m_square],\n        [\n            f\"x z - {epsilon} &lt; 0 y z - x z - / sqrt ?\"\n        ],  # akarin.Expr adds \"0 max\" to sqrt by default\n    )\n    t = Filter(core.akarin.Expr([r, m], [\"x y *\"]))\n    m = Filter(m)\n    r = Filter(r)\n    d = core.akarin.Expr([m, r, l1, t], [\"x y z * + a -\"])\n\n    if gamma:\n        d = nnrs.LinearToGamma(\n            depth(d, 16),\n            fulls=fulls,\n            fulld=fulld,\n            curve=curve,\n            sigmoid=sigmoid,\n            planes=[0],\n        )\n\n    return depth(d, 32)\n</code></pre>"},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(width)","title":"<code>width</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(height)","title":"<code>height</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(smooth)","title":"<code>smooth</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(gamma)","title":"<code>gamma</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(fulls)","title":"<code>fulls</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(fulld)","title":"<code>fulld</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(curve)","title":"<code>curve</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(sigmoid)","title":"<code>sigmoid</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.SSIM_downsample(resample_args)","title":"<code>resample_args</code>","text":""},{"location":"API/filter/resample/#y5gfunc.filter.resample.Descale","title":"Descale","text":"<pre><code>Descale(src: VideoNode, width: int, height: int, kernel: str, custom_kernel: Optional[Callable] = None, taps: int = 3, b: Union[int, float] = 0.0, c: Union[int, float] = 0.5, blur: Union[int, float] = 1.0, post_conv: Optional[list[Union[float, int]]] = None, src_left: Union[int, float] = 0.0, src_top: Union[int, float] = 0.0, src_width: Optional[Union[int, float]] = None, src_height: Optional[Union[int, float]] = None, border_handling: int = 0, ignore_mask: Optional[VideoNode] = None, force: bool = False, force_h: bool = False, force_v: bool = False, opt: int = 0) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/filter/resample.py</code> <pre><code>def Descale(\n    src: vs.VideoNode,\n    width: int,\n    height: int,\n    kernel: str,\n    custom_kernel: Optional[Callable] = None,\n    taps: int = 3,\n    b: Union[int, float] = 0.0,\n    c: Union[int, float] = 0.5,\n    blur: Union[int, float] = 1.0,\n    post_conv: Optional[list[Union[float, int]]] = None,\n    src_left: Union[int, float] = 0.0,\n    src_top: Union[int, float] = 0.0,\n    src_width: Optional[Union[int, float]] = None,\n    src_height: Optional[Union[int, float]] = None,\n    border_handling: int = 0,\n    ignore_mask: Optional[vs.VideoNode] = None,\n    force: bool = False,\n    force_h: bool = False,\n    force_v: bool = False,\n    opt: int = 0,\n) -&gt; vs.VideoNode:\n    def _get_resize_name(kernal_name: str) -&gt; str:\n        if kernal_name == \"Decustom\":\n            return \"ScaleCustom\"\n        if kernal_name.startswith(\"De\"):\n            return kernal_name[2:].capitalize()\n        return kernal_name\n\n    def _get_descaler_name(kernal_name: str) -&gt; str:\n        if kernal_name == \"ScaleCustom\":\n            return \"Decustom\"\n        if kernal_name.startswith(\"De\"):\n            return kernal_name\n        return \"De\" + kernal_name[0].lower() + kernal_name[1:]\n\n    assert width &gt; 0 and height &gt; 0\n    assert opt in [0, 1, 2]\n    assert isinstance(src, vs.VideoNode) and src.format.id == vs.GRAYS\n\n    kernel = kernel.capitalize()\n\n    if src_width is None:\n        src_width = width\n    if src_height is None:\n        src_height = height\n\n    if width &gt; src.width or height &gt; src.height:\n        kernel = _get_resize_name(kernel)\n    else:\n        kernel = _get_descaler_name(kernel)\n\n    descaler = getattr(core.descale, kernel)\n    assert callable(descaler)\n    extra_params: dict[str, dict[str, Union[float, int, Callable]]] = {}\n    if _get_descaler_name(kernel) == \"Debicubic\":\n        extra_params = {\n            \"dparams\": {\"b\": b, \"c\": c},\n        }\n    elif _get_descaler_name(kernel) == \"Delanczos\":\n        extra_params = {\n            \"dparams\": {\"taps\": taps},\n        }\n    elif _get_descaler_name(kernel) == \"Decustom\":\n        assert callable(custom_kernel)\n        extra_params = {\n            \"dparams\": {\"custom_kernel\": custom_kernel},\n        }\n    descaled = descaler(\n        src=src,\n        width=width,\n        height=height,\n        blur=blur,\n        post_conv=post_conv,\n        src_left=src_left,\n        src_top=src_top,\n        src_width=src_width,\n        src_height=src_height,\n        border_handling=border_handling,\n        ignore_mask=ignore_mask,\n        force=force,\n        force_h=force_h,\n        force_v=force_v,\n        opt=opt,\n        **extra_params.get(\"dparams\", {}),\n    )\n\n    assert isinstance(descaled, vs.VideoNode)\n\n    return descaled\n</code></pre>"},{"location":"API/filter/rescale/","title":"<code>y5gfunc.filter.rescale</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale","title":"rescale","text":"<p>Classes:</p> Name Description <code>DescaleMode</code> <p>Functions:</p> Name Description <code>descale_cropping_args</code> <code>rescale</code> <p>Automatically descale and rescale</p>"},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.DescaleMode","title":"DescaleMode","text":"<p>               Bases: <code>StrEnum</code></p> <p>Attributes:</p> Name Type Description <code>W</code> <code>H</code> <code>WH</code> <code>HW</code>"},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.DescaleMode.W","title":"W  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>W = 'w'\n</code></pre>"},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.DescaleMode.H","title":"H  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>H = 'h'\n</code></pre>"},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.DescaleMode.WH","title":"WH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>WH = 'wh'\n</code></pre>"},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.DescaleMode.HW","title":"HW  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HW = 'hw'\n</code></pre>"},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.descale_cropping_args","title":"descale_cropping_args","text":"<pre><code>descale_cropping_args(clip: VideoNode, src_height: float, base_height: int, base_width: int, crop_top: int = 0, crop_bottom: int = 0, crop_left: int = 0, crop_right: int = 0, mode: DescaleMode = WH) -&gt; dict[str, Union[int, float]]\n</code></pre> Source code in <code>y5gfunc/filter/rescale.py</code> <pre><code>def descale_cropping_args(\n    clip: vs.VideoNode,\n    src_height: float,\n    base_height: int,\n    base_width: int,\n    crop_top: int = 0,\n    crop_bottom: int = 0,\n    crop_left: int = 0,\n    crop_right: int = 0,\n    mode: DescaleMode = DescaleMode.WH,\n) -&gt; dict[str, Union[int, float]]:\n    effective_src_h = clip.height + crop_top + crop_bottom\n    if effective_src_h &lt;= 0:\n        raise ValueError(\n            \"descale_cropping_args: Effective source height (clip.height + crop_top + crop_bottom) must be positive.\"\n        )\n\n    ratio = src_height / effective_src_h\n    effective_src_w = clip.width + crop_left + crop_right\n    if effective_src_w &lt;= 0:\n        raise ValueError(\n            \"descale_cropping_args: Effective source width (clip.width + crop_left + crop_right) must be positive.\"\n        )\n\n    src_width = ratio * effective_src_w\n\n    cropped_src_width = ratio * clip.width\n    cropped_src_height = ratio * clip.height\n\n    margin_left = (base_width - src_width) / 2 + ratio * crop_left\n    margin_right = (base_width - src_width) / 2 + ratio * crop_right\n    margin_top = (base_height - src_height) / 2 + ratio * crop_top\n    margin_bottom = (base_height - src_height) / 2 + ratio * crop_bottom\n\n    cropped_width = max(0, base_width - floor(margin_left) - floor(margin_right))\n    cropped_height = max(0, base_height - floor(margin_top) - floor(margin_bottom))\n\n    cropped_src_left = margin_left - floor(margin_left)\n    cropped_src_top = margin_top - floor(margin_top)\n\n    args: dict[str, Union[int, float]] = dict(width=clip.width, height=clip.height)\n\n    args_w: dict[str, Union[int, float]] = dict(\n        width=cropped_width, src_width=cropped_src_width, src_left=cropped_src_left\n    )\n\n    args_h: dict[str, Union[int, float]] = dict(\n        height=cropped_height, src_height=cropped_src_height, src_top=cropped_src_top\n    )\n\n    if mode == DescaleMode.WH:\n        args.update(args_w)\n        args.update(args_h)\n    elif mode == DescaleMode.HW:\n        args.update(args_h)\n        args.update(args_w)\n    elif mode == DescaleMode.W:\n        args.update(args_w)\n    elif mode == DescaleMode.H:\n        args.update(args_h)\n\n    return args\n</code></pre>"},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale","title":"rescale","text":"<pre><code>rescale(clip: VideoNode, descale_kernel: Union[Literal['Debicubic', 'Delanczos', 'Despline16', 'Despline36', 'Despline64', 'Debilinear', 'Depoint'], list[str]] = 'Debicubic', src_height: Union[Union[float, int], list[Union[float, int]]] = 720, bw: Optional[Union[int, list[int]]] = None, bh: Optional[Union[int, list[int]]] = None, descale_mode: DescaleMode = WH, show_upscaled: bool = False, show_fft: bool = False, detail_mask_threshold: float = 0.05, use_detail_mask: bool = True, show_detail_mask: bool = False, exclude_common_mask: bool = True, show_common_mask: bool = False, nnedi3_args: dict[str, int] = {'field': 1, 'nsize': 4, 'nns': 4, 'qual': 2}, taps: Union[int, list[int]] = 4, b: Union[Union[float, int], list[Union[float, int]]] = 0.33, c: Union[Union[float, int], list[Union[float, int]]] = 0.33, threshold_max: float = 0.007, threshold_min: float = -1, show_osd: bool = True, ex_thr: Union[float, int] = 0.015, norm_order: int = 1, crop_size: int = 5, scene_stable: bool = False, scene_descale_threshold_ratio: float = 0.5, scenecut_threshold: Union[float, int] = 0.1, opencl: bool = True) -&gt; Union[VideoNode, tuple[VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode, VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, list[VideoNode]], tuple[VideoNode, list[VideoNode], VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode, VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode, VideoNode, VideoNode, VideoNode, VideoNode]]\n</code></pre> <p>Automatically descale and rescale</p> <p>This function attempts to find the 'native' resolution of a video clip that may have been upscaled during production. It tests various descaling parameters by descaling the input clip, re-upscaling it with the same kernel, and comparing the result to the original clip luma.</p> <p>The parameter set yielding the minimum difference (within thresholds) is considered the 'best' guess for the original upscale parameters. The clip descaled with these parameters is then re-upscaled to the original dimensions using a potentially higher-quality method (NNEDI3 + SSIM_downsample).</p> <p>A detail mask can be generated and used to merge the rescaled result with the original clip, preserving details that might exist only in the original resolution (like credits). Scene-based decision logic can be enabled via <code>scene_stable</code>.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video node. Expected to be in YUV format for proper handling.</p> required <code>Union[Literal['Debicubic', 'Delanczos', 'Despline16', 'Despline36', 'Despline64', 'Debilinear', 'Depoint'], list[str]]</code> <p>Descale kernel(s) to test (e.g., \"Debicubic\", \"Delanczos\").</p> <code>'Debicubic'</code> <code>Union[Union[float, int], list[Union[float, int]]]</code> <p>Potential native source height(s) to test.</p> <code>720</code> <code>Optional[Union[int, list[int]]]</code> <p>Base width for descaling calculations.</p> <code>None</code> <code>Optional[Union[int, list[int]]]</code> <p>Base height for descaling calculations.</p> <code>None</code> <code>DescaleMode</code> <p>Order of applying width/height descaling.</p> <code>WH</code> <code>bool</code> <p>If True, return the list of intermediate same-kernel upscaled clips used for comparison.</p> <code>False</code> <code>bool</code> <p>If True, return FFT spectrums of the original and final clip.</p> <code>False</code> <code>float</code> <p>Threshold for generating the detail mask. Lower values detect more 'detail'. Useful to mask original resolution contents.</p> <code>0.05</code> <code>bool</code> <p>If True, merge the final rescaled clip with the original using the detail mask.</p> <code>True</code> <code>bool</code> <p>If True, return the final selected detail mask.</p> <code>False</code> <code>bool</code> <p>If True, use the common mask to exclude potential native details from the difference calculation. Useful when descaling scenes with native resolution contents.</p> <code>True</code> <code>bool</code> <p>If True, return the mask generated by combining all candidate detail masks (used for error calculation exclusion).</p> <code>False</code> <code>dict[str, int]</code> <p>Arguments passed to the NNEDI3 function for the high-quality upscale.</p> <code>{'field': 1, 'nsize': 4, 'nns': 4, 'qual': 2}</code> <code>Union[int, list[int]]</code> <p>Taps parameter(s) for Delanczos/Despline kernels.</p> <code>4</code> <code>Union[Union[float, int], list[Union[float, int]]]</code> <p>Bicubic 'b' parameter(s) for Debicubic kernel.</p> <code>0.33</code> <code>Union[Union[float, int], list[Union[float, int]]]</code> <p>Bicubic 'c' parameter(s) for Debicubic kernel.</p> <code>0.33</code> <code>float</code> <p>Maximum difference metric allowed for a frame to be considered 'descaled' (use large value to disable).</p> <code>0.007</code> <code>float</code> <p>Minimum difference metric required for a frame to be considered 'descaled' (use negative value to disable).</p> <code>-1</code> <code>bool</code> <p>If True, return a clip with On-Screen Display showing frame stats.</p> <code>True</code> <code>Union[float, int]</code> <p>Exclusion threshold for difference calculation; differences below this are ignored.</p> <code>0.015</code> <code>int</code> <p>Order of the norm used for calculating frame difference (1 = MAE).</p> <code>1</code> <code>int</code> <p>Pixels to crop from each border before calculating difference.</p> <code>5</code> <code>bool</code> <p>If True, use scene-based logic to choose parameters for entire scenes rather than frame-by-frame.</p> <code>False</code> <code>float</code> <p>Minimum ratio of frames in a scene that must be successfully descaled for the scene to use the best descaled parameters.</p> <code>0.5</code> <code>Union[float, int]</code> <p>Threshold for scene change detection (used if scene_stable=True).</p> <code>0.1</code> <code>bool</code> <p>If True, attempt to use OpenCL versions of NNEDI3 if available.</p> <code>True</code> <p>Returns:</p> Type Description <code>Union[VideoNode, tuple[VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, VideoNode, VideoNode, VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, list[VideoNode]], tuple[VideoNode, list[VideoNode], VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode, VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode, VideoNode, VideoNode, VideoNode], tuple[VideoNode, list[VideoNode], VideoNode, VideoNode, VideoNode, VideoNode, VideoNode, VideoNode]]</code> <p>A tuple containing the final rescaled video node as the first element. The exact tuple structure varies depending on which flags are enabled.</p>"},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(descale_kernel)","title":"<code>descale_kernel</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(src_height)","title":"<code>src_height</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(bw)","title":"<code>bw</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(bh)","title":"<code>bh</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(descale_mode)","title":"<code>descale_mode</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(show_upscaled)","title":"<code>show_upscaled</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(show_fft)","title":"<code>show_fft</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(detail_mask_threshold)","title":"<code>detail_mask_threshold</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(use_detail_mask)","title":"<code>use_detail_mask</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(show_detail_mask)","title":"<code>show_detail_mask</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(exclude_common_mask)","title":"<code>exclude_common_mask</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(show_common_mask)","title":"<code>show_common_mask</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(nnedi3_args)","title":"<code>nnedi3_args</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(taps)","title":"<code>taps</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(b)","title":"<code>b</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(c)","title":"<code>c</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(threshold_max)","title":"<code>threshold_max</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(threshold_min)","title":"<code>threshold_min</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(show_osd)","title":"<code>show_osd</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(ex_thr)","title":"<code>ex_thr</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(norm_order)","title":"<code>norm_order</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(crop_size)","title":"<code>crop_size</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(scene_stable)","title":"<code>scene_stable</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(scene_descale_threshold_ratio)","title":"<code>scene_descale_threshold_ratio</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(scenecut_threshold)","title":"<code>scenecut_threshold</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale(opencl)","title":"<code>opencl</code>","text":""},{"location":"API/filter/rescale/#y5gfunc.filter.rescale.rescale--tips","title":"Tips:","text":"<pre><code>To rescale from multiple native resolution, use this function for every possible src_height, then choose the largest MaxDelta one.\n\nFor example, to descale a show with mixed native resolution 714.75P and 956P:\n```python\nrescaled1, osd1 = rescale(clip=src, src_height=ranger(714.5, 715, 0.025)+[713, 714, 716, 717])\nrescaled2, osd2 = rescale(clip=src, src_height=ranger(955, 957,0.1)+[953, 954, 958])\n\nselect_expr = \"src0.MaxDelta src0.Descaled * src1.MaxDelta src1.Descaled * argmax2\"\n\nosd = core.akarin.Select([osd1, osd2], [rescaled1, rescaled2], select_expr)\nrescaled = core.akarin.Select([rescaled1, rescaled2], [rescaled1, rescaled2], select_expr)\n```\n</code></pre> Source code in <code>y5gfunc/filter/rescale.py</code> <pre><code>def rescale(\n    clip: vs.VideoNode,\n    descale_kernel: Union[\n        Literal[\n            \"Debicubic\",\n            \"Delanczos\",\n            \"Despline16\",\n            \"Despline36\",\n            \"Despline64\",\n            \"Debilinear\",\n            \"Depoint\",\n        ],\n        list[str],\n    ] = \"Debicubic\",\n    src_height: Union[Union[float, int], list[Union[float, int]]] = 720,\n    bw: Optional[Union[int, list[int]]] = None,\n    bh: Optional[Union[int, list[int]]] = None,\n    descale_mode: DescaleMode = DescaleMode.WH,\n    show_upscaled: bool = False,\n    show_fft: bool = False,\n    detail_mask_threshold: float = 0.05,\n    use_detail_mask: bool = True,\n    show_detail_mask: bool = False,\n    exclude_common_mask: bool = True,\n    show_common_mask: bool = False,\n    nnedi3_args: dict[str, int] = {\"field\": 1, \"nsize\": 4, \"nns\": 4, \"qual\": 2},\n    taps: Union[int, list[int]] = 4,\n    b: Union[Union[float, int], list[Union[float, int]]] = 0.33,\n    c: Union[Union[float, int], list[Union[float, int]]] = 0.33,\n    threshold_max: float = 0.007,\n    threshold_min: float = -1,\n    show_osd: bool = True,\n    ex_thr: Union[float, int] = 0.015,\n    norm_order: int = 1,\n    crop_size: int = 5,\n    scene_stable: bool = False,\n    scene_descale_threshold_ratio: float = 0.5,\n    scenecut_threshold: Union[float, int] = 0.1,\n    opencl: bool = True,\n) -&gt; Union[\n    vs.VideoNode,\n    tuple[vs.VideoNode, vs.VideoNode],\n    tuple[vs.VideoNode, vs.VideoNode, vs.VideoNode],\n    tuple[vs.VideoNode, vs.VideoNode, vs.VideoNode, vs.VideoNode],\n    tuple[vs.VideoNode, vs.VideoNode, vs.VideoNode, vs.VideoNode, vs.VideoNode],\n    tuple[\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n    ],\n    tuple[\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n    ],\n    tuple[vs.VideoNode, list[vs.VideoNode]],\n    tuple[vs.VideoNode, list[vs.VideoNode], vs.VideoNode],\n    tuple[vs.VideoNode, list[vs.VideoNode], vs.VideoNode, vs.VideoNode],\n    tuple[vs.VideoNode, list[vs.VideoNode], vs.VideoNode, vs.VideoNode, vs.VideoNode],\n    tuple[\n        vs.VideoNode,\n        list[vs.VideoNode],\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n    ],\n    tuple[\n        vs.VideoNode,\n        list[vs.VideoNode],\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n    ],\n    tuple[\n        vs.VideoNode,\n        list[vs.VideoNode],\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n        vs.VideoNode,\n    ],\n]:\n    \"\"\"\n    Automatically descale and rescale\n\n    This function attempts to find the 'native' resolution of a video clip that may have been upscaled during production. It tests various\n    descaling parameters by descaling the input clip, re-upscaling it with the *same* kernel, and comparing the result to the original clip luma.\n\n    The parameter set yielding the minimum difference (within thresholds) is considered the 'best' guess for the original upscale parameters. The clip\n    descaled with these parameters is then re-upscaled to the original dimensions using a potentially higher-quality method (NNEDI3 + SSIM_downsample).\n\n    A detail mask can be generated and used to merge the rescaled result with the original clip, preserving details that might exist only in the original\n    resolution (like credits). Scene-based decision logic can be enabled via `scene_stable`.\n\n    Args:\n        clip: Input video node. Expected to be in YUV format for proper handling.\n        descale_kernel: Descale kernel(s) to test (e.g., \"Debicubic\", \"Delanczos\").\n        src_height: Potential native source height(s) to test.\n        bw: Base width for descaling calculations.\n        bh: Base height for descaling calculations.\n        descale_mode: Order of applying width/height descaling.\n        show_upscaled: If True, return the list of intermediate same-kernel upscaled clips used for comparison.\n        show_fft: If True, return FFT spectrums of the original and final clip.\n        detail_mask_threshold: Threshold for generating the detail mask. Lower values detect more 'detail'.\n            Useful to mask original resolution contents.\n        use_detail_mask: If True, merge the final rescaled clip with the original using the detail mask.\n        show_detail_mask: If True, return the final selected detail mask.\n        exclude_common_mask: If True, use the common mask to exclude potential native details from the difference calculation.\n            Useful when descaling scenes with native resolution contents.\n        show_common_mask: If True, return the mask generated by combining all candidate detail masks (used for error calculation exclusion).\n        nnedi3_args: Arguments passed to the NNEDI3 function for the high-quality upscale.\n        taps: Taps parameter(s) for Delanczos/Despline kernels.\n        b: Bicubic 'b' parameter(s) for Debicubic kernel.\n        c: Bicubic 'c' parameter(s) for Debicubic kernel.\n        threshold_max: Maximum difference metric allowed for a frame to be considered 'descaled' (use large value to disable).\n        threshold_min: Minimum difference metric required for a frame to be considered 'descaled' (use negative value to disable).\n        show_osd: If True, return a clip with On-Screen Display showing frame stats.\n        ex_thr: Exclusion threshold for difference calculation; differences below this are ignored.\n        norm_order: Order of the norm used for calculating frame difference (1 = MAE).\n        crop_size: Pixels to crop from each border before calculating difference.\n        scene_stable: If True, use scene-based logic to choose parameters for entire scenes rather than frame-by-frame.\n        scene_descale_threshold_ratio: Minimum ratio of frames in a scene that must be successfully descaled for the scene to use the best descaled parameters.\n        scenecut_threshold: Threshold for scene change detection (used if scene_stable=True).\n        opencl: If True, attempt to use OpenCL versions of NNEDI3 if available.\n\n    Returns:\n        A tuple containing the final rescaled video node as the first element. The exact tuple structure varies depending on which flags are enabled.\n\n    ## Tips:\n        To rescale from multiple native resolution, use this function for every possible src_height, then choose the largest MaxDelta one.\n\n        For example, to descale a show with mixed native resolution 714.75P and 956P:\n        ```python\n        rescaled1, osd1 = rescale(clip=src, src_height=ranger(714.5, 715, 0.025)+[713, 714, 716, 717])\n        rescaled2, osd2 = rescale(clip=src, src_height=ranger(955, 957,0.1)+[953, 954, 958])\n\n        select_expr = \"src0.MaxDelta src0.Descaled * src1.MaxDelta src1.Descaled * argmax2\"\n\n        osd = core.akarin.Select([osd1, osd2], [rescaled1, rescaled2], select_expr)\n        rescaled = core.akarin.Select([rescaled1, rescaled2], [rescaled1, rescaled2], select_expr)\n        ```\n    \"\"\"\n\n    KERNEL_MAP = {\n        \"Debicubic\": 1,\n        \"Delanczos\": 2,\n        \"Debilinear\": 3,\n        \"Despline16\": 5,\n        \"Despline36\": 6,\n        \"Despline64\": 7,\n    }\n\n    descale_kernel = (\n        [descale_kernel] if isinstance(descale_kernel, str) else descale_kernel\n    )\n    src_height = [src_height] if isinstance(src_height, (int, float)) else src_height\n    if bw is None:\n        bw = clip.width\n    if bh is None:\n        bh = clip.height\n    bw = [bw] if isinstance(bw, int) else bw\n    bh = [bh] if isinstance(bh, int) else bh\n    taps = [taps] if isinstance(taps, int) else taps\n    b = [b] if isinstance(b, (float, int)) else b\n    c = [c] if isinstance(c, (float, int)) else c\n\n    clip = vstools.depth(clip, 32)\n\n    def scene_descale(\n        n: int,\n        f: list[vs.VideoFrame],\n        cache: list[int],\n        prefetch: vs.VideoNode,\n        length: int,\n        scene_descale_threshold_ratio: float = scene_descale_threshold_ratio,\n    ) -&gt; vs.VideoFrame:\n        fout = f[0].copy()\n        if n == 0 or n == prefetch.num_frames:\n            fout.props[\"_SceneChangePrev\"] = 1\n\n        if cache[n] == -1:  # not cached\n            i = n\n            scene_start = n\n            while i &gt;= 0:\n                frame = prefetch.get_frame(i)\n                if frame.props[\"_SceneChangePrev\"] == 1:  # scene srart\n                    scene_start = i\n                    break\n                i -= 1\n            i = scene_start\n            scene_length = 0\n\n            min_index_buffer = [0] * length\n            num_descaled = 0\n\n            while i &lt; prefetch.num_frames:\n                frame = prefetch.get_frame(i)\n                min_index_buffer[frame.props[\"MinIndex\"]] += 1  # type: ignore\n                if frame.props[\"Descaled\"]:\n                    num_descaled += 1\n                scene_length += 1\n                i += 1\n                if frame.props[\"_SceneChangeNext\"] == 1:  # scene end\n                    break\n\n            scene_min_index = (\n                max(enumerate(min_index_buffer), key=lambda x: x[1])[0]\n                if num_descaled &gt;= scene_descale_threshold_ratio * scene_length\n                else length\n            )\n\n            cache[scene_start : scene_start + scene_length] = [\n                scene_min_index\n            ] * scene_length\n\n        fout.props[\"SceneMinIndex\"] = cache[n]\n        return fout\n\n    def _get_resize_name(descale_name: str) -&gt; str:\n        if descale_name.startswith(\"De\"):\n            return descale_name[2:].capitalize()\n        return descale_name\n\n    def _generate_common_mask(detail_mask_clips: list[vs.VideoNode]) -&gt; vs.VideoNode:\n        load_expr = [f\"src{i} * \" for i in range(len(detail_mask_clips))]\n        merge_expr = \" \".join(load_expr)\n        merge_expr = merge_expr[:4] + merge_expr[6:]\n        return core.akarin.Expr(clips=detail_mask_clips, expr=merge_expr)\n\n    def _select_per_frame(\n        reference: vs.VideoNode,\n        upscaled_clips: list[vs.VideoNode],\n        candidate_clips: list[vs.VideoNode],\n        params_list: list[dict],\n        common_mask_clip: vs.VideoNode,\n        threshold_max: float = threshold_max,\n        threshold_min: float = threshold_min,\n        ex_thr: float = ex_thr,\n        norm_order: int = norm_order,\n        crop_size: int = crop_size,\n    ) -&gt; vs.VideoNode:\n        def _crop(clip: vs.VideoNode, crop_size: int = crop_size) -&gt; vs.VideoNode:\n            return clip.std.CropRel(*([crop_size] * 4)) if crop_size &gt; 0 else clip\n\n        if len(upscaled_clips) != len(candidate_clips) or len(upscaled_clips) != len(\n            params_list\n        ):\n            raise ValueError(\n                \"upscaled_clips, rescaled_clips, and params_list must have the same length.\"\n            )\n\n        calc_diff_expr = (\n            f\"src0 src1 - abs dup {ex_thr} &gt; swap {norm_order} pow 0 ? src2 - 0 1 clip\"\n        )\n\n        diffs = [\n            core.akarin.Expr(\n                [_crop(reference), _crop(upscaled_clip), _crop(common_mask_clip)],\n                calc_diff_expr,\n            ).std.PlaneStats()\n            for upscaled_clip in upscaled_clips\n        ]\n\n        for diff in diffs:\n            diff = diff.akarin.PropExpr(\n                lambda: {\n                    \"PlaneStatsAverage\": f\"x.PlaneStatsAverage {1 / norm_order} pow\"\n                }\n            )\n\n        load_PlaneStatsAverage_exprs = [\n            f\"src{i}.PlaneStatsAverage\" for i in range(len(diffs))\n        ]\n        diff_expr = \" \".join(load_PlaneStatsAverage_exprs)\n\n        min_index_expr = diff_expr + f\" argmin{len(diffs)}\"\n        min_diff_expr = (\n            diff_expr + f\" sort{len(diffs)} min_diff! drop{len(diffs)-1} min_diff@\"\n        )\n\n        max_index_expr = diff_expr + f\" argmax{len(diffs)}\"\n        max_diff_expr = diff_expr + f\" sort{len(diffs)} drop{len(diffs)-1}\"\n\n        max_delta_expr = max_diff_expr + \" \" + min_diff_expr + \" / \"\n\n        def props() -&gt; dict[str, str]:\n            d = {\n                \"MinIndex\": min_index_expr,\n                \"MinDiff\": min_diff_expr,\n                \"MaxIndex\": max_index_expr,\n                \"MaxDiff\": max_diff_expr,\n                \"MaxDelta\": max_delta_expr,\n            }\n            for i in range(len(diffs)):\n                d[f\"Diff{i}\"] = load_PlaneStatsAverage_exprs[i]\n                params = params_list[i]\n                d[f\"KernelId{i}\"] = KERNEL_MAP.get(params[\"Kernel\"], 0)  # type: ignore\n                d[f\"Bw{i}\"] = (params.get(\"BaseWidth\", 0),)  # type: ignore\n                d[f\"Bh{i}\"] = params.get(\"BaseHeight\", 0)\n                d[f\"SrcHeight{i}\"] = params[\"SrcHeight\"]\n                d[f\"B{i}\"] = params.get(\"B\", 0)\n                d[f\"C{i}\"] = params.get(\"C\", 0)\n                d[f\"Taps{i}\"] = params.get(\"Taps\", 0)\n            return d\n\n        prop_src = core.akarin.PropExpr(diffs, props)\n\n        # Kernel is different because it's a string.\n        for i in range(len(diffs)):\n            prop_src = core.akarin.Text(\n                prop_src, params_list[i][\"Kernel\"], prop=f\"Kernel{i}\"\n            )\n\n        minDiff_clip = core.akarin.Select(\n            clip_src=candidate_clips, prop_src=[prop_src], expr=\"x.MinIndex\"\n        )\n\n        final_clip = core.akarin.Select(\n            clip_src=[reference, minDiff_clip],\n            prop_src=[prop_src],\n            expr=f\"x.MinDiff {threshold_max} &gt; x.MinDiff {threshold_min} &lt;= or 0 1 ?\",\n        )\n\n        final_clip = final_clip.std.CopyFrameProps(prop_src)\n        final_clip = core.akarin.PropExpr(\n            [final_clip],\n            lambda: {\n                \"Descaled\": f\"x.MinDiff {threshold_max} &lt;= x.MinDiff {threshold_min} &gt; and\"\n            },\n        )\n\n        return final_clip\n\n    def _fft(clip: vs.VideoNode) -&gt; vs.VideoNode:\n        return core.fftspectrum_rs.FFTSpectrum(clip=vstools.depth(clip, 8))\n\n    upscaled_clips: list[vs.VideoNode] = []\n    rescaled_clips: list[vs.VideoNode] = []\n    detail_masks: list[vs.VideoNode] = []\n    params_list: list[dict] = []\n\n    src_luma = vstools.get_y(clip)\n\n    for kernel_name, sh, base_w, base_h, _taps, _b, _c in product(\n        descale_kernel, src_height, bw, bh, taps, b, c\n    ):\n        extra_params: dict[str, dict[str, Union[float, int]]] = {}\n        if kernel_name == \"Debicubic\":\n            extra_params = {\n                \"dparams\": {\"b\": _b, \"c\": _c},\n                \"rparams\": {\"filter_param_a\": _b, \"filter_param_b\": _c},\n            }\n        elif kernel_name == \"Delanczos\":\n            extra_params = {\n                \"dparams\": {\"taps\": _taps},\n                \"rparams\": {\"filter_param_a\": _taps},\n            }\n        else:\n            extra_params = {}\n\n        dargs = descale_cropping_args(\n            clip=clip,\n            src_height=sh,\n            base_height=base_h,\n            base_width=base_w,\n            mode=descale_mode,\n        )\n\n        descaled = getattr(core.descale, kernel_name)(\n            src_luma, **dargs, **extra_params.get(\"dparams\", {})\n        )\n\n        upscaled = getattr(core.resize2, _get_resize_name(kernel_name))(\n            descaled,\n            width=clip.width,\n            height=clip.height,\n            src_left=dargs[\"src_left\"],\n            src_top=dargs[\"src_top\"],\n            src_width=dargs[\"src_width\"],\n            src_height=dargs[\"src_height\"],\n            **extra_params.get(\"rparams\", {}),\n        )\n\n        n2x = nn2x(descaled, opencl=opencl, nnedi3_args=nnedi3_args)\n\n        rescaled = SSIM_downsample(\n            clip=n2x,\n            width=clip.width,\n            height=clip.height,\n            sigmoid=False,\n            src_left=dargs[\"src_left\"] * 2 - 0.5,  # type: ignore\n            src_top=dargs[\"src_top\"] * 2 - 0.5,  # type: ignore\n            src_width=dargs[\"src_width\"] * 2,  # type: ignore\n            src_height=dargs[\"src_height\"] * 2,  # type: ignore\n        )\n\n        upscaled_clips.append(upscaled)\n        rescaled_clips.append(rescaled)\n\n        if use_detail_mask or show_detail_mask or exclude_common_mask:\n            detail_mask = generate_detail_mask(\n                src_luma, upscaled, detail_mask_threshold\n            )\n            detail_masks.append(detail_mask)\n\n        params_list.append(\n            {\n                \"Kernel\": kernel_name,\n                \"SrcHeight\": sh,\n                \"BaseWidth\": base_w,\n                \"BaseHeight\": base_h,\n                \"Taps\": _taps,\n                \"B\": _b,\n                \"C\": _c,\n            }\n        )\n\n    common_mask_clip = (\n        _generate_common_mask(detail_mask_clips=detail_masks)\n        if exclude_common_mask\n        else core.std.BlankClip(clip=detail_masks[0], color=0)\n    )\n    if not scene_stable:\n        rescaled = _select_per_frame(\n            reference=src_luma,\n            upscaled_clips=upscaled_clips,\n            candidate_clips=rescaled_clips,\n            params_list=params_list,\n            common_mask_clip=common_mask_clip,\n        )\n        detail_mask = core.akarin.Select(\n            clip_src=detail_masks, prop_src=rescaled, expr=\"src0.MinIndex\"\n        )\n        detail_mask = core.akarin.Select(\n            clip_src=[core.std.BlankClip(clip=detail_mask), detail_mask],\n            prop_src=rescaled,\n            expr=\"src0.Descaled\",\n        )\n        upscaled = core.akarin.Select(\n            clip_src=upscaled_clips, prop_src=rescaled, expr=\"src0.MinIndex\"\n        )\n    else:\n        # detail mask: matched one when descaling, otherwise blank clip\n        # upscaled clip: matched one when descaling, otherwise frame level decision\n        # rescaled clip: mostly-choosed index in a scene when descaling, otherwise src_luma\n        # 'Descaled', 'SceneMinIndex': scene-level information\n        # other props: frame-level information\n        per_frame = _select_per_frame(\n            reference=src_luma,\n            upscaled_clips=upscaled_clips,\n            candidate_clips=upscaled_clips,\n            params_list=params_list,\n            common_mask_clip=common_mask_clip,\n        )\n        upscaled_per_frame = core.akarin.Select(\n            clip_src=upscaled_clips, prop_src=per_frame, expr=\"src0.MinIndex\"\n        )\n        scene = core.misc.SCDetect(clip, scenecut_threshold)\n        prefetch = core.std.BlankClip(clip)\n        prefetch = core.akarin.PropExpr(\n            [scene, per_frame],\n            lambda: {\n                \"_SceneChangeNext\": \"x._SceneChangeNext\",\n                \"_SceneChangePrev\": \"x._SceneChangePrev\",\n                \"MinIndex\": \"y.MinIndex\",\n                \"Descaled\": \"y.Descaled\",\n            },\n        )\n        cache = [-1] * clip.num_frames\n        length = len(upscaled_clips)\n        per_scene = core.std.ModifyFrame(\n            per_frame,\n            [per_frame, per_frame],\n            functools.partial(\n                scene_descale,\n                prefetch=prefetch,\n                cache=cache,\n                length=length,\n                scene_descale_threshold_ratio=scene_descale_threshold_ratio,\n            ),\n        )\n        rescaled = core.akarin.Select(\n            rescaled_clips + [src_luma], [per_scene], \"src0.SceneMinIndex\"\n        )\n        rescaled = core.std.CopyFrameProps(rescaled, per_scene)\n        rescaled = core.akarin.PropExpr(\n            [rescaled],\n            lambda: {\"Descaled\": f\"x.SceneMinIndex {len(upscaled_clips)} = not\"},\n        )\n        detail_mask = core.akarin.Select(\n            clip_src=detail_masks + [core.std.BlankClip(clip=detail_masks[0])],\n            prop_src=rescaled,\n            expr=\"src0.SceneMinIndex\",\n        )\n        upscaled = core.akarin.Select(\n            clip_src=upscaled_clips + [upscaled_per_frame],\n            prop_src=rescaled,\n            expr=\"src0.SceneMinIndex\",\n        )\n\n    if use_detail_mask:\n        rescaled = core.std.MaskedMerge(rescaled, src_luma, detail_mask)\n\n    final = (\n        vstools.join(rescaled, clip) if clip.format.color_family == vs.YUV else rescaled\n    )\n\n    if not scene_stable:\n        format_string = (\n            \"\\nMinIndex: {MinIndex}\\n\"\n            \"MinDiff: {MinDiff}\\n\"\n            \"Descaled: {Descaled}\\n\"\n            f\"Threshold_Max: {threshold_max}\\n\"\n            f\"Threshold_Min: {threshold_min}\\n\\n\"\n        )\n    else:\n        format_string = (\n            \"\\nMinIndex: {MinIndex}\\n\"\n            \"MinDiff: {MinDiff}\\n\"\n            \"Descaled: {Descaled}\\n\"\n            \"SceneMinIndex: {SceneMinIndex}\\n\"\n            f\"Threshold_Max: {threshold_max}\\n\"\n            f\"Threshold_Min: {threshold_min}\\n\"\n        )\n\n    format_string += (\n        \"|    i   |          Diff          |   Kernel   | SrcHeight |    Bw     |     Bh    | B      | C      | Taps   |\\n\"\n        \"|--------|------------------------|------------|-----------|-----------|-----------|--------|--------|--------|\\n\"\n    )\n\n    for i, upscaled in enumerate(upscaled_clips):\n        format_string += (\n            f\"| {i:04}   | {{Diff{i}}}  | {{Kernel{i}}}  | {{SrcHeight{i}}}   | \"\n            f\"{{Bw{i}}} | {{Bh{i}}} |\"\n            f\"{{B{i}}}   | {{C{i}}}   | {{Taps{i}}}   |\\n\"\n        )\n        upscaled_clips[i] = upscaled.text.Text(str(params_list[i]))\n\n    osd_clip = core.akarin.Text(final, format_string)\n\n    if show_fft:\n        src_fft = _fft(clip)\n        rescaled_fft = _fft(final)\n\n    # FUCK YOU PYLINT\n    if show_upscaled:\n        if show_common_mask:\n            if show_osd:\n                if show_detail_mask and show_fft:\n                    return (\n                        final,\n                        upscaled_clips,\n                        detail_mask,\n                        common_mask_clip,\n                        src_fft,\n                        rescaled_fft,\n                        osd_clip,\n                    )\n                elif show_detail_mask:\n                    return (\n                        final,\n                        upscaled_clips,\n                        detail_mask,\n                        common_mask_clip,\n                        osd_clip,\n                    )\n                elif show_fft:\n                    return (\n                        final,\n                        upscaled_clips,\n                        common_mask_clip,\n                        src_fft,\n                        rescaled_fft,\n                        osd_clip,\n                    )\n                else:\n                    return final, upscaled_clips, common_mask_clip, osd_clip\n            else:\n                if show_detail_mask and show_fft:\n                    return (\n                        final,\n                        upscaled_clips,\n                        detail_mask,\n                        common_mask_clip,\n                        src_fft,\n                        rescaled_fft,\n                    )\n                elif show_detail_mask:\n                    return final, upscaled_clips, detail_mask, common_mask_clip\n                elif show_fft:\n                    return (\n                        final,\n                        upscaled_clips,\n                        common_mask_clip,\n                        src_fft,\n                        rescaled_fft,\n                    )\n                else:\n                    return final, upscaled_clips, common_mask_clip\n        else:\n            if show_osd:\n                if show_detail_mask and show_fft:\n                    return (\n                        final,\n                        upscaled_clips,\n                        detail_mask,\n                        src_fft,\n                        rescaled_fft,\n                        osd_clip,\n                    )\n                elif show_detail_mask:\n                    return final, upscaled_clips, detail_mask, osd_clip\n                elif show_fft:\n                    return final, upscaled_clips, src_fft, rescaled_fft, osd_clip\n                else:\n                    return final, upscaled_clips, osd_clip\n            else:\n                if show_detail_mask and show_fft:\n                    return final, upscaled_clips, detail_mask, src_fft, rescaled_fft\n                elif show_detail_mask:\n                    return final, upscaled_clips, detail_mask\n                elif show_fft:\n                    return final, upscaled_clips, src_fft, rescaled_fft\n                else:\n                    return final, upscaled_clips\n    else:\n        if show_common_mask:\n            if show_osd:\n                if show_detail_mask and show_fft:\n                    return (\n                        final,\n                        detail_mask,\n                        common_mask_clip,\n                        src_fft,\n                        rescaled_fft,\n                        osd_clip,\n                    )\n                elif show_detail_mask:\n                    return final, detail_mask, common_mask_clip, osd_clip\n                elif show_fft:\n                    return final, common_mask_clip, src_fft, rescaled_fft, osd_clip\n                else:\n                    return final, common_mask_clip, osd_clip\n            else:\n                if show_detail_mask and show_fft:\n                    return final, detail_mask, common_mask_clip, src_fft, rescaled_fft\n                elif show_detail_mask:\n                    return final, detail_mask, common_mask_clip\n                elif show_fft:\n                    return final, common_mask_clip, src_fft, rescaled_fft\n                else:\n                    return final, common_mask_clip\n        else:\n            if show_osd:\n                if show_detail_mask and show_fft:\n                    return final, detail_mask, src_fft, rescaled_fft, osd_clip\n                elif show_detail_mask:\n                    return final, detail_mask, osd_clip\n                elif show_fft:\n                    return final, src_fft, rescaled_fft, osd_clip\n                else:\n                    return final, osd_clip\n            else:\n                if show_detail_mask and show_fft:\n                    return final, detail_mask, src_fft, rescaled_fft\n                elif show_detail_mask:\n                    return final, detail_mask\n                elif show_fft:\n                    return final, src_fft, rescaled_fft\n                else:\n                    return final\n</code></pre>"},{"location":"API/filter/scenecut/","title":"<code>y5gfunc.filter.scenecut</code>","text":""},{"location":"API/filter/scenecut/#y5gfunc.filter.scenecut","title":"scenecut","text":"<p>Functions:</p> Name Description <code>histogram_correlation</code> <p>cv2.HISTCMP_CORREL</p> <code>scd_koala</code> <p>Koala-36M Based Scenecut Detector</p>"},{"location":"API/filter/scenecut/#y5gfunc.filter.scenecut.histogram_correlation","title":"histogram_correlation","text":"<pre><code>histogram_correlation(hist1: ndarray, hist2: ndarray) -&gt; float\n</code></pre> <p>cv2.HISTCMP_CORREL</p> Source code in <code>y5gfunc/filter/scenecut.py</code> <pre><code>def histogram_correlation(hist1: np.ndarray, hist2: np.ndarray) -&gt; float:\n    \"\"\"cv2.HISTCMP_CORREL\"\"\"\n    hist1 = hist1.flatten()\n    hist2 = hist2.flatten()\n\n    x_mean = np.mean(hist1)\n    y_mean = np.mean(hist2)\n\n    numerator = np.sum((hist1 - x_mean) * (hist2 - y_mean))\n    denominator = np.sqrt(np.sum((hist1 - x_mean) ** 2) * np.sum((hist2 - y_mean) ** 2))\n\n    if denominator == 0:\n        return 0\n    return numerator / denominator\n</code></pre>"},{"location":"API/filter/scenecut/#y5gfunc.filter.scenecut.scd_koala","title":"scd_koala","text":"<pre><code>scd_koala(clip: VideoNode, min_scene_len: int = 12, filter_size: int = 3, window_size: int = 8, deviation: float = 3.0, edge_func: Callable[[VideoNode], VideoNode] = partial(AnimeMask, mode=-1)) -&gt; VideoNode\n</code></pre> <p>Koala-36M Based Scenecut Detector</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip.</p> required <code>int</code> <p>Minimum scene length.</p> <code>12</code> <code>int</code> <p>Boxcar filter size.</p> <code>3</code> <code>int</code> <p>Window to use for calculating threshold.</p> <code>8</code> <code>float</code> <p>Multiplier for standard deviations when calculating threshold.</p> <code>3.0</code> <code>Callable[[VideoNode], VideoNode]</code> <p>Function to detect edges in the input clip.</p> <code>partial(AnimeMask, mode=-1)</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Input video clip with frame prop \"_Scenecut\" set to 1 at scenecuts.</p> Source code in <code>y5gfunc/filter/scenecut.py</code> <pre><code>def scd_koala(\n    clip: vs.VideoNode,\n    min_scene_len: int = 12,\n    filter_size: int = 3,\n    window_size: int = 8,\n    deviation: float = 3.0,\n    edge_func: Callable[[vs.VideoNode], vs.VideoNode] = partial(AnimeMask, mode=-1),\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Koala-36M Based Scenecut Detector\n\n    Args:\n        clip: Input video clip.\n        min_scene_len: Minimum scene length.\n        filter_size: Boxcar filter size.\n        window_size: Window to use for calculating threshold.\n        deviation: Multiplier for standard deviations when calculating threshold.\n        edge_func: Function to detect edges in the input clip.\n\n    Returns:\n        Input video clip with frame prop \"_Scenecut\" set to 1 at scenecuts.\n    \"\"\"\n    if filter_size &gt; window_size:\n        raise ValueError(\"scd_koala: filter_size should be &lt;= window_size.\")\n    num_frames = clip.num_frames\n\n    resized_clip = core.resize2.Bicubic(clip, width=256, height=256, format=vs.RGB24)\n\n    gray_clip = core.std.ShufflePlanes(resized_clip, planes=0, colorfamily=vs.GRAY)\n    small_gray = core.resize2.Bicubic(gray_clip, width=128, height=128)\n\n    edges = edge_func(small_gray)\n\n    combined_edges = core.akarin.Expr([small_gray, edges], expr=\"x y max\")\n    prev_edge_clip = combined_edges.std.DuplicateFrames(0).std.Trim(\n        first=0, length=num_frames\n    )\n    ssim_result = muvsfunc.SSIM(prev_edge_clip, combined_edges)\n\n    scores = []\n\n    for n, curr_frame in enumerate(resized_clip.frames()):\n        if n == 0:\n            prev_frame = curr_frame\n            continue\n\n        prev_array = np.dstack(\n            [np.array(prev_frame[p]) for p in range(prev_frame.format.num_planes)]  # type: ignore\n        )\n        curr_array = np.dstack(\n            [np.array(curr_frame[p]) for p in range(curr_frame.format.num_planes)]  # type: ignore\n        )\n\n        prev_hist = []\n        curr_hist = []\n\n        for c in range(3):\n            channel_data = prev_array[:, :, c]\n            mask = (channel_data &gt; 0) &amp; (channel_data &lt; 255)\n            hist, _ = np.histogram(channel_data[mask], bins=254, range=(1, 255))\n            prev_hist.append(hist)\n\n            channel_data = curr_array[:, :, c]\n            mask = (channel_data &gt; 0) &amp; (channel_data &lt; 255)\n            hist, _ = np.histogram(channel_data[mask], bins=254, range=(1, 255))\n            curr_hist.append(hist)\n\n        delta_histogram = histogram_correlation(\n            np.array(prev_hist), np.array(curr_hist)\n        )\n\n        ssim_frame = ssim_result.get_frame(n)\n        delta_edges = ssim_frame.props.get(\"PlaneSSIM\", 0)\n\n        score = (\n            4.61480465 * delta_histogram + 3.75211168 * delta_edges - 5.485968377115124  # type: ignore\n        )\n        scores.append(score)\n        prev_frame = curr_frame\n\n    cut_found = [score &lt; 0.0 for score in scores]\n    cut_found.append(True)\n\n    filter_kernel = np.ones(filter_size) / filter_size  # type: ignore\n    filtered = np.convolve(scores, filter_kernel, mode=\"same\")\n\n    for i in range(len(scores)):\n        if i &gt;= window_size and filtered[i] &lt; float(filter_size) / float(\n            filter_size + 1\n        ):\n            window = filtered[i - window_size : i]\n            threshold = np.mean(window) - (deviation * np.std(window))\n            if filtered[i] &lt; threshold:\n                cut_found[i] = True\n\n    scene_cuts = []\n    last_cut = 0\n\n    for i in range(len(cut_found)):\n        if cut_found[i]:\n            current_frame = i + 1\n            scene_length = current_frame - last_cut\n\n            if scene_length &gt;= min_scene_len:\n                scene_cuts.append(current_frame)\n\n            last_cut = current_frame\n\n    def set_scenecut_prop(n, f, scene_cuts):\n        fout = f.copy()\n        if n in scene_cuts:\n            fout.props._Scenecut = 1\n        else:\n            fout.props._Scenecut = 0\n        return fout\n\n    marked_clip = core.std.ModifyFrame(\n        clip, clip, partial(set_scenecut_prop, scene_cuts=scene_cuts)\n    )\n\n    return marked_clip\n</code></pre>"},{"location":"API/filter/scenecut/#y5gfunc.filter.scenecut.scd_koala(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/scenecut/#y5gfunc.filter.scenecut.scd_koala(min_scene_len)","title":"<code>min_scene_len</code>","text":""},{"location":"API/filter/scenecut/#y5gfunc.filter.scenecut.scd_koala(filter_size)","title":"<code>filter_size</code>","text":""},{"location":"API/filter/scenecut/#y5gfunc.filter.scenecut.scd_koala(window_size)","title":"<code>window_size</code>","text":""},{"location":"API/filter/scenecut/#y5gfunc.filter.scenecut.scd_koala(deviation)","title":"<code>deviation</code>","text":""},{"location":"API/filter/scenecut/#y5gfunc.filter.scenecut.scd_koala(edge_func)","title":"<code>edge_func</code>","text":""},{"location":"API/filter/stripe/","title":"<code>y5gfunc.filter.stripe</code>","text":""},{"location":"API/filter/stripe/#y5gfunc.filter.stripe","title":"stripe","text":"<p>Functions:</p> Name Description <code>is_stripe</code> <p>Detects scenes potentially containing strong vertical stripes using FFT analysis.</p>"},{"location":"API/filter/stripe/#y5gfunc.filter.stripe.is_stripe","title":"is_stripe","text":"<pre><code>is_stripe(clip: VideoNode, threshold: Union[float, int] = 2, freq_range: Union[int, float] = 0.25, scenecut_threshold: Union[float, int] = 0.1) -&gt; VideoNode\n</code></pre> <p>Detects scenes potentially containing strong vertical stripes using FFT analysis.</p> <p>This function analyzes the frequency spectrum of each frame to identify scenes where the energy in high vertical frequencies significantly outweighs the energy in high horizontal frequencies. This pattern is often indicative of vertical stripes.</p> <p>The analysis is performed per scene, meaning the ratio of vertical to horizontal frequency energy is averaged over all frames within a detected scene. All frames in that scene are then marked based on this average ratio.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip. Must be 32-bit per sample.</p> required <code>Union[float, int]</code> <p>The threshold for the ratio of average vertical high-frequency energy to average horizontal high-frequency energy within a scene. If a scene's ratio exceeds this value, it's marked as potentially containing stripes.</p> <code>2</code> <code>Union[int, float]</code> <p>Defines the proportion of the spectrum (from each edge towards the center) considered as \"high frequency\". For example, 0.25 means the outer 25% of frequencies horizontally and vertically are analyzed. Must be between 0 and 0.5 (exclusive of 0, inclusive of 0.5 isn't practically useful).</p> <code>0.25</code> <code>Union[float, int]</code> <p>Threshold used for scene change detection via <code>core.misc.SCDetect</code>. Controls how sensitive the scene detection is. Lower values detect more scene changes.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>The input clip with a frame property <code>_Stripe</code> added. <code>_Stripe</code> is 1 (True) if the frame belongs to a scene detected as potentially containing stripes (ratio &gt; threshold), and 0 (False) otherwise.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input clip is not 32-bit per sample.</p> <code>ValueError</code> <p>if freq_range is not between 0 and 0.5.</p> Source code in <code>y5gfunc/filter/stripe.py</code> <pre><code>def is_stripe(\n    clip: vs.VideoNode,\n    threshold: Union[float, int] = 2,\n    freq_range: Union[int, float] = 0.25,\n    scenecut_threshold: Union[float, int] = 0.1,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Detects scenes potentially containing strong vertical stripes using FFT analysis.\n\n    This function analyzes the frequency spectrum of each frame to identify scenes where the energy in high vertical frequencies\n    significantly outweighs the energy in high horizontal frequencies. This pattern is often indicative of vertical stripes.\n\n    The analysis is performed per scene, meaning the ratio of vertical to horizontal frequency energy is averaged over all frames\n    within a detected scene. All frames in that scene are then marked based on this average ratio.\n\n    Args:\n        clip: Input video clip. Must be 32-bit per sample.\n        threshold: The threshold for the ratio of average vertical high-frequency energy to average horizontal\n            high-frequency energy within a scene. If a scene's ratio exceeds this value, it's marked as potentially containing stripes.\n        freq_range: Defines the proportion of the spectrum (from each edge towards the center) considered as \"high frequency\".\n            For example, 0.25 means the outer 25% of frequencies horizontally and vertically are analyzed.\n            Must be between 0 and 0.5 (exclusive of 0, inclusive of 0.5 isn't practically useful).\n        scenecut_threshold: Threshold used for scene change detection via `core.misc.SCDetect`.\n            Controls how sensitive the scene detection is. Lower values detect more scene changes.\n\n    Returns:\n        The input clip with a frame property `_Stripe` added. `_Stripe` is 1 (True) if the frame belongs to a scene detected as\n            potentially containing stripes (ratio &gt; threshold), and 0 (False) otherwise.\n\n    Raises:\n        ValueError: If input clip is not 32-bit per sample.\n        ValueError: if freq_range is not between 0 and 0.5.\n    \"\"\"\n\n    def scene_fft(\n        n: int, f: list[vs.VideoFrame], cache: list[float], prefetch: vs.VideoNode\n    ) -&gt; vs.VideoFrame:\n        fout = f[0].copy()\n        if n == 0 or n == prefetch.num_frames:\n            fout.props[\"_SceneChangePrev\"] = 1\n\n        if cache[n] == -1.0:  # not cached\n            i = n\n            scene_start = n\n            while i &gt;= 0:\n                frame = prefetch.get_frame(i)\n                if frame.props[\"_SceneChangePrev\"] == 1:  # scene srart\n                    scene_start = i\n                    break\n                i -= 1\n            i = scene_start\n            scene_length = 0\n            hor_accum = 1e-9\n            ver_accum = 0\n            while i &lt; prefetch.num_frames:\n                frame = prefetch.get_frame(i)\n                hor_accum += frame.props[\"hor\"]  # type: ignore\n                ver_accum += frame.props[\"ver\"]  # type: ignore\n                scene_length += 1\n                i += 1\n                if frame.props[\"_SceneChangeNext\"] == 1:  # scene end\n                    break\n\n            ratio = ver_accum / hor_accum\n\n            cache[scene_start : scene_start + scene_length] = [ratio] * scene_length\n\n        fout.props[\"ratio\"] = cache[n]\n        return fout\n\n    if clip.format.bits_per_sample != 32:\n        raise ValueError(\"is_stripe: input clip must be 32-bit per sample.\")\n    if not 0 &lt; freq_range &lt; 0.5:\n        raise ValueError(\"is_stripe: freq_range must be between 0 and 0.5.\")\n\n    freq_drop_range = 1 - freq_range\n    freq_drop_lr = int(clip.width * freq_drop_range)\n    freq_drop_bt = int(clip.height * freq_drop_range)\n\n    fft = core.fftspectrum_rs.FFTSpectrum(clip)\n\n    left = core.std.Crop(fft, right=freq_drop_lr)\n    right = core.std.Crop(fft, left=freq_drop_lr)\n    hor = core.std.StackHorizontal([left, right]).std.PlaneStats()\n\n    top = core.std.Crop(fft, bottom=freq_drop_bt)\n    bottom = core.std.Crop(fft, top=freq_drop_bt)\n    ver = core.std.StackHorizontal([top, bottom]).std.PlaneStats()\n\n    scene = core.misc.SCDetect(clip, threshold=scenecut_threshold)\n\n    prefetch = core.std.BlankClip(clip)\n    prefetch = core.akarin.PropExpr(\n        [hor, ver, scene],\n        lambda: {\n            \"hor\": \"x.PlaneStatsAverage\",\n            \"ver\": \"y.PlaneStatsAverage\",\n            \"_SceneChangeNext\": \"z._SceneChangeNext\",\n            \"_SceneChangePrev\": \"z._SceneChangePrev\",\n        },\n    )\n\n    cache = [-1.0] * scene.num_frames\n\n    ret = core.std.ModifyFrame(\n        scene,\n        [scene, scene],\n        functools.partial(scene_fft, prefetch=prefetch, cache=cache),\n    )\n    ret = core.akarin.PropExpr(\n        [ret], lambda: {\"_Stripe\": f\"x.ratio {threshold} &gt;\"}\n    )  # x.ratio &gt; threshold: Stripe\n\n    return ret\n</code></pre>"},{"location":"API/filter/stripe/#y5gfunc.filter.stripe.is_stripe(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/stripe/#y5gfunc.filter.stripe.is_stripe(threshold)","title":"<code>threshold</code>","text":""},{"location":"API/filter/stripe/#y5gfunc.filter.stripe.is_stripe(freq_range)","title":"<code>freq_range</code>","text":""},{"location":"API/filter/stripe/#y5gfunc.filter.stripe.is_stripe(scenecut_threshold)","title":"<code>scenecut_threshold</code>","text":""},{"location":"API/filter/temporal/","title":"<code>y5gfunc.filter.temporal</code>","text":""},{"location":"API/filter/temporal/#y5gfunc.filter.temporal","title":"temporal","text":"<p>Functions:</p> Name Description <code>temporal_stabilize</code> <p>Temporally stabilizes a processed video clip using motion compensation based on a reference clip.</p>"},{"location":"API/filter/temporal/#y5gfunc.filter.temporal.temporal_stabilize","title":"temporal_stabilize","text":"<pre><code>temporal_stabilize(processed_clip: VideoNode, ref_clip: VideoNode, delta: int = 3, pel: int = 1, retain: float = 0.6) -&gt; VideoNode\n</code></pre> <p>Temporally stabilizes a processed video clip using motion compensation based on a reference clip.</p> <p>This function aims to reduce temporal inconsistencies (like flickering or unsteadiness) in the <code>processed_clip</code> by referencing a <code>reference_clip</code>. It calculates the difference between <code>reference_clip</code> and <code>processed_clip</code>, stabilizes this difference using motion vectors derived from <code>processed_clip</code>, and then applies the stabilized difference back onto <code>reference_clip</code>.</p> <p>A common use case is when <code>processed_clip</code> is the result of filtering applied to <code>reference_clip</code>, and that filtering introduced temporal instability. This function attempts to apply a temporally consistent version of the filter's effect.</p> <p>The core stabilization logic uses motion vector analysis on <code>processed_clip</code> and motion compensation on the difference clip. A limiting step ensures the stabilized difference doesn't deviate too drastically from the original difference, controlled by the <code>retain</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>The input video clip that likely contains temporal instabilities.</p> required <code>VideoNode</code> <p>The reference video clip,  the original source before the processing that introduced instability.</p> required <code>int</code> <p>Temporal radius for temporal stabilize (1-6). This value corresponds to the <code>mv.DegrainN</code> function used.</p> <code>3</code> <code>int</code> <p>Subpixel accuracy for motion estimation passed to <code>mv.Super</code>. Higher values increase accuracy but also computational cost.</p> <code>1</code> <code>float</code> <p>Weight for merging the limited stabilized difference with the full stabilized difference. A value of 1.0 means only the full stabilized difference is used, while 0.0 means only the limited difference (closer to the original difference) is used. It controls the strength of the stabilization effect versus preserving the original difference characteristics. Range [0.0, 1.0].</p> <code>0.6</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>A new video clip, ideally resembling <code>processed_clip</code> but with reduced temporal instability.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>processed_clip</code> and <code>reference_clip</code> have different video formats.</p> <code>ValueError</code> <p>if <code>pel</code> is not an ingeter in [1, 2, 4].</p> <code>ValueError</code> <p>If <code>delta</code> is not an integer between 1 and 6 (inclusive).</p> Source code in <code>y5gfunc/filter/temporal.py</code> <pre><code>def temporal_stabilize(\n    processed_clip: vs.VideoNode,\n    ref_clip: vs.VideoNode,\n    delta: int = 3,\n    pel: int = 1,\n    retain: float = 0.6,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Temporally stabilizes a processed video clip using motion compensation based on a reference clip.\n\n    This function aims to reduce temporal inconsistencies (like flickering or unsteadiness) in the `processed_clip` by referencing a `reference_clip`.\n    It calculates the difference between `reference_clip` and `processed_clip`, stabilizes this difference using motion vectors derived from `processed_clip`,\n    and then applies the stabilized difference back onto `reference_clip`.\n\n    A common use case is when `processed_clip` is the result of filtering applied to `reference_clip`, and that filtering\n    introduced temporal instability. This function attempts to apply a temporally consistent version of the filter's effect.\n\n    The core stabilization logic uses motion vector analysis on `processed_clip` and motion compensation on the difference clip.\n    A limiting step ensures the stabilized difference doesn't deviate too drastically from the original difference, controlled by the `retain` parameter.\n\n    Args:\n        processed_clip: The input video clip that likely contains temporal instabilities.\n        ref_clip: The reference video clip,  the original source before the processing that introduced instability.\n        delta: Temporal radius for temporal stabilize (1-6). This value corresponds to the `mv.DegrainN` function used.\n        pel: Subpixel accuracy for motion estimation passed to `mv.Super`. Higher values increase accuracy but also computational cost.\n        retain: Weight for merging the limited stabilized difference with the full stabilized difference. A value of 1.0 means only the full\n            stabilized difference is used, while 0.0 means only the limited difference (closer to the original difference) is used. It controls\n            the strength of the stabilization effect versus preserving the original difference characteristics. Range [0.0, 1.0].\n\n    Returns:\n        A new video clip, ideally resembling `processed_clip` but with reduced temporal instability.\n\n    Raises:\n        ValueError: If `processed_clip` and `reference_clip` have different video formats.\n        ValueError: if `pel` is not an ingeter in [1, 2, 4].\n        ValueError: If `delta` is not an integer between 1 and 6 (inclusive).\n    \"\"\"\n    if processed_clip.format != ref_clip.format:\n        raise ValueError(\n            \"temporal_stabilize: format of processed_clip and ref_clip mismatch.\"\n        )\n    if pel not in [1, 2, 4]:\n        raise ValueError(\"temporal_stabilize: pel (1, 2, 4) invalid.\")\n    if delta not in [1, 2, 3, 4, 5, 6]:\n        raise ValueError(\"temporal_stabilize: delta (1~6) invalid.\")\n\n    diff = core.std.MakeDiff(ref_clip, processed_clip)\n    clip_super = core.mv.Super(processed_clip, pel=pel)\n    diff_super = core.mv.Super(diff, pel=pel, levels=1)\n\n    backward_vectors = [\n        core.mv.Analyse(clip_super, isb=True, delta=i + 1, overlap=8, blksize=16)\n        for i in range(delta)\n    ]\n    forward_vectors = [\n        core.mv.Analyse(clip_super, isb=False, delta=i + 1, overlap=8, blksize=16)\n        for i in range(delta)\n    ]\n    vectors = [\n        vector\n        for vector_group in zip(backward_vectors, forward_vectors)\n        for vector in vector_group\n    ]\n\n    stabilize_func = getattr(core.mv, f\"Degrain{delta}\")\n    diff_stabilized = stabilize_func(diff, diff_super, *vectors)\n\n    diff_stabilized_limited = core.akarin.Expr(\n        [diff, diff_stabilized],\n        f\"x {get_neutral_value(processed_clip)} - abs y {get_neutral_value(processed_clip)} - abs &lt; x y ?\",\n    )\n    diff_stabilized = core.std.Merge(\n        diff_stabilized_limited, diff_stabilized, weight=retain\n    )\n    clip_stabilized = core.std.MakeDiff(ref_clip, diff_stabilized)\n    return clip_stabilized\n</code></pre>"},{"location":"API/filter/temporal/#y5gfunc.filter.temporal.temporal_stabilize(processed_clip)","title":"<code>processed_clip</code>","text":""},{"location":"API/filter/temporal/#y5gfunc.filter.temporal.temporal_stabilize(ref_clip)","title":"<code>ref_clip</code>","text":""},{"location":"API/filter/temporal/#y5gfunc.filter.temporal.temporal_stabilize(delta)","title":"<code>delta</code>","text":""},{"location":"API/filter/temporal/#y5gfunc.filter.temporal.temporal_stabilize(pel)","title":"<code>pel</code>","text":""},{"location":"API/filter/temporal/#y5gfunc.filter.temporal.temporal_stabilize(retain)","title":"<code>retain</code>","text":""},{"location":"API/filter/tonemap/","title":"<code>y5gfunc.filter.tonemap</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap","title":"tonemap","text":"<p>Classes:</p> Name Description <code>ColorSpace</code> <p>Color spaces used in tonemapping operations.</p> <code>ColorPrimaries</code> <p>Color primaries standards.</p> <code>GamutMapping</code> <p>Gamut mapping functions.</p> <code>ToneMappingFunction</code> <p>Tone mapping functions.</p> <code>Metadata</code> <p>Metadata sources for tone-mapping.</p> <p>Functions:</p> Name Description <code>tonemap</code> <p>Color mapping using placebo.Tonemap.</p>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorSpace","title":"ColorSpace","text":"<p>               Bases: <code>IntEnum</code></p> <p>Color spaces used in tonemapping operations.</p> <p>Attributes:</p> Name Type Description <code>SDR</code> <p>Standard Dynamic Range</p> <code>HDR10</code> <p>High Dynamic Range (HDR10)</p> <code>HLG</code> <p>Hybrid Log-Gamma</p> <code>DOLBY_VISION</code> <p>Dolby Vision</p>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorSpace.SDR","title":"SDR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SDR = 0\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorSpace.HDR10","title":"HDR10  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HDR10 = 1\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorSpace.HLG","title":"HLG  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HLG = 2\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorSpace.DOLBY_VISION","title":"DOLBY_VISION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DOLBY_VISION = 3\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries","title":"ColorPrimaries","text":"<p>               Bases: <code>IntEnum</code></p> <p>Color primaries standards.</p> <p>Attributes:</p> Name Type Description <code>UNKNOWN</code> <p>Unknown primaries</p> <code>BT601_525</code> <p>ITU-R Rec. BT.601 (525-line = NTSC, SMPTE-C)</p> <code>BT601_625</code> <p>ITU-R Rec. BT.601 (625-line = PAL, SECAM)</p> <code>BT709</code> <p>ITU-R Rec. BT.709 (HD), also sRGB</p> <code>BT470M</code> <p>ITU-R Rec. BT.470 M</p> <code>EBU_TECH_3213E</code> <p>EBU Tech. 3213-E / JEDEC P22 phosphors</p> <code>BT2020</code> <p>ITU-R Rec. BT.2020 (UltraHD)</p> <code>APPLE_RGB</code> <p>Apple RGB</p> <code>ADOBE_RGB</code> <p>Adobe RGB (1998)</p> <code>PROPHOTO_RGB</code> <p>ProPhoto RGB (ROMM)</p> <code>CIE1931_RGB</code> <p>CIE 1931 RGB primaries</p> <code>DCI_P3</code> <p>DCI-P3 (Digital Cinema)</p> <code>DCI_P3_D65</code> <p>DCI-P3 (Digital Cinema) with D65 white point</p> <code>V_GAMUT</code> <p>Panasonic V-Gamut (VARICAM)</p> <code>S_GAMUT</code> <p>Sony S-Gamut</p> <code>FILM_C</code> <p>Traditional film primaries with Illuminant C</p> <code>ACES0</code> <p>ACES Primaries #0 (ultra wide)</p> <code>ACES1</code> <p>ACES Primaries #1</p>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.UNKNOWN","title":"UNKNOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>UNKNOWN = 0\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.BT601_525","title":"BT601_525  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BT601_525 = 1\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.BT601_625","title":"BT601_625  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BT601_625 = 2\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.BT709","title":"BT709  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BT709 = 3\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.BT470M","title":"BT470M  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BT470M = 4\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.EBU_TECH_3213E","title":"EBU_TECH_3213E  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>EBU_TECH_3213E = 5\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.BT2020","title":"BT2020  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BT2020 = 6\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.APPLE_RGB","title":"APPLE_RGB  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>APPLE_RGB = 7\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.ADOBE_RGB","title":"ADOBE_RGB  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ADOBE_RGB = 8\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.PROPHOTO_RGB","title":"PROPHOTO_RGB  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PROPHOTO_RGB = 9\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.CIE1931_RGB","title":"CIE1931_RGB  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CIE1931_RGB = 10\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.DCI_P3","title":"DCI_P3  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DCI_P3 = 11\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.DCI_P3_D65","title":"DCI_P3_D65  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DCI_P3_D65 = 12\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.V_GAMUT","title":"V_GAMUT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>V_GAMUT = 13\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.S_GAMUT","title":"S_GAMUT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>S_GAMUT = 14\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.FILM_C","title":"FILM_C  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FILM_C = 15\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.ACES0","title":"ACES0  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ACES0 = 16\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ColorPrimaries.ACES1","title":"ACES1  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ACES1 = 17\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping","title":"GamutMapping","text":"<p>               Bases: <code>IntEnum</code></p> <p>Gamut mapping functions.</p> <p>Attributes:</p> Name Type Description <code>CLIP</code> <p>Performs no gamut-mapping, just hard clips out-of-range colors per-channel</p> <code>PERCEPTUAL</code> <p>Performs a perceptually balanced (saturation) gamut mapping with a soft knee function</p> <code>SOFTCLIP</code> <p>Performs perceptually balanced gamut mapping using a soft knee function and hue shifting</p> <code>RELATIVE</code> <p>Performs relative colorimetric clipping, maintaining exponential brightness/chromaticity relationship</p> <code>SATURATION</code> <p>Performs simple RGB-&gt;RGB saturation mapping; never clips but may distort hues</p> <code>ABSOLUTE</code> <p>Performs absolute colorimetric clipping without adapting white point</p> <code>DESATURATE</code> <p>Performs constant-luminance colorimetric clipping, desaturating colors towards white</p> <code>DARKEN</code> <p>Uniformly darkens the input to prevent highlight clipping, then clamps colorimetrically</p> <code>HIGHLIGHT</code> <p>Performs no gamut mapping, but highlights out-of-gamut pixels</p> <code>LINEAR</code> <p>Linearly/uniformly desaturates the image to bring it into the target gamut</p>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.CLIP","title":"CLIP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CLIP = 0\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.PERCEPTUAL","title":"PERCEPTUAL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PERCEPTUAL = 1\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.SOFTCLIP","title":"SOFTCLIP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SOFTCLIP = 2\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.RELATIVE","title":"RELATIVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RELATIVE = 3\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.SATURATION","title":"SATURATION  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SATURATION = 4\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.ABSOLUTE","title":"ABSOLUTE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ABSOLUTE = 5\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.DESATURATE","title":"DESATURATE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DESATURATE = 6\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.DARKEN","title":"DARKEN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>DARKEN = 7\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.HIGHLIGHT","title":"HIGHLIGHT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HIGHLIGHT = 8\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.GamutMapping.LINEAR","title":"LINEAR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LINEAR = 9\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction","title":"ToneMappingFunction","text":"<p>               Bases: <code>IntEnum</code></p> <p>Tone mapping functions.</p> <p>Attributes:</p> Name Type Description <code>CLIP</code> <p>No tone-mapping, just clips out-of-range colors</p> <code>SPLINE</code> <p>Simple spline consisting of two polynomials joined by a pivot point</p> <code>ST2094_40</code> <p>EETF from SMPTE ST 2094-40 Annex B, using Bezier curves</p> <code>ST2094_10</code> <p>EETF from SMPTE ST 2094-10 Annex B.2</p> <code>BT2390</code> <p>EETF from ITU-R Report BT.2390, a hermite spline roll-off with linear segment</p> <code>BT2446A</code> <p>EETF from ITU-R Report BT.2446, method A</p> <code>REINHARD</code> <p>Simple non-linear curve named after Erik Reinhard</p> <code>MOBIUS</code> <p>Generalization of reinhard algorithm (legacy/low-quality)</p> <code>HABLE</code> <p>Piece-wise, filmic tone-mapping algorithm by John Hable (legacy/low-quality)</p> <code>GAMMA</code> <p>Fits a gamma (power) function between source and target (legacy/low-quality)</p> <code>LINEAR</code> <p>Linearly stretches input range to output range in PQ space</p> <code>LINEARLIGHT</code> <p>Like LINEAR but in linear light instead of PQ</p>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.CLIP","title":"CLIP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CLIP = 0\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.SPLINE","title":"SPLINE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SPLINE = 1\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.ST2094_40","title":"ST2094_40  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ST2094_40 = 2\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.ST2094_10","title":"ST2094_10  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ST2094_10 = 3\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.BT2390","title":"BT2390  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BT2390 = 4\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.BT2446A","title":"BT2446A  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BT2446A = 5\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.REINHARD","title":"REINHARD  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REINHARD = 6\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.MOBIUS","title":"MOBIUS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MOBIUS = 7\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.HABLE","title":"HABLE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HABLE = 8\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.GAMMA","title":"GAMMA  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>GAMMA = 9\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.LINEAR","title":"LINEAR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LINEAR = 10\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.ToneMappingFunction.LINEARLIGHT","title":"LINEARLIGHT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LINEARLIGHT = 11\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.Metadata","title":"Metadata","text":"<p>               Bases: <code>IntEnum</code></p> <p>Metadata sources for tone-mapping.</p> <p>Attributes:</p> Name Type Description <code>AUTO</code> <p>Automatic selection based on available metadata</p> <code>NONE</code> <p>No metadata (disabled)</p> <code>HDR10</code> <p>HDR10 static metadata</p> <code>HDR10_PLUS</code> <p>HDR10+ (MaxRGB) dynamic metadata</p> <code>LUMINANCE</code> <p>Luminance (CIE Y) derived metadata</p>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.Metadata.AUTO","title":"AUTO  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>AUTO = 0\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.Metadata.NONE","title":"NONE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NONE = 1\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.Metadata.HDR10","title":"HDR10  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HDR10 = 2\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.Metadata.HDR10_PLUS","title":"HDR10_PLUS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HDR10_PLUS = 3\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.Metadata.LUMINANCE","title":"LUMINANCE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LUMINANCE = 4\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap","title":"tonemap","text":"<pre><code>tonemap(clip: VideoNode, src_csp: ColorSpace, dst_csp: ColorSpace, dst_prim: Optional[Union[ColorPrimaries, Primaries]] = None, src_max: Optional[Union[float, int]] = None, src_min: Optional[Union[float, int]] = None, dst_max: Optional[Union[float, int]] = None, dst_min: Optional[Union[float, int]] = None, dynamic_peak_detection: bool = True, smoothing_period: Union[float, int] = 20.0, scene_threshold_low: Union[float, int] = 1.0, scene_threshold_high: Union[float, int] = 3.0, percentile: Union[float, int] = 99.995, gamut_mapping: GamutMapping = PERCEPTUAL, tone_mapping_function: ToneMappingFunction = SPLINE, tone_mapping_param: Optional[Union[float, int]] = None, metadata: Metadata = AUTO, use_dovi: Optional[bool] = None, visualize_lut: bool = False, show_clipping: bool = False, contrast_recovery: Union[float, int] = 0.3, log_level: int = 2) -&gt; VideoNode\n</code></pre> <p>Color mapping using placebo.Tonemap.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ColorSpace</code> <p>Source colorspace (SDR, HDR10, HLG, DOLBY_VISION)</p> required <code>ColorSpace</code> <p>Destination colorspace (SDR, HDR10, HLG, DOLBY_VISION)</p> required <code>Optional[Union[ColorPrimaries, Primaries]]</code> <p>Destination color primaries</p> <code>None</code> <code>Optional[Union[float, int]]</code> <p>Source maximum display level in nits (cd/m\u00b2)</p> <code>None</code> <code>Optional[Union[float, int]]</code> <p>Source minimum display level in nits (cd/m\u00b2)</p> <code>None</code> <code>Optional[Union[float, int]]</code> <p>Destination maximum display level in nits (cd/m\u00b2)</p> <code>None</code> <code>Optional[Union[float, int]]</code> <p>Destination minimum display level in nits (cd/m\u00b2)</p> <code>None</code> <code>bool</code> <p>Enables HDR peak detection</p> <code>True</code> <code>Union[float, int]</code> <p>Smoothing coefficient for detected values (in frames)</p> <code>20.0</code> <code>Union[float, int]</code> <p>Lower bound for scene change detection (in units of 1% PQ)</p> <code>1.0</code> <code>Union[float, int]</code> <p>Upper bound for scene change detection (in units of 1% PQ)</p> <code>3.0</code> <code>Union[float, int]</code> <p>Percentile of brightness histogram to consider as true peak</p> <code>99.995</code> <code>GamutMapping</code> <p>Gamut mapping function to handle out-of-gamut colors</p> <code>PERCEPTUAL</code> <code>ToneMappingFunction</code> <p>Tone mapping function</p> <code>SPLINE</code> <code>Optional[Union[float, int]]</code> <p>Optional parameter for tone mapping function</p> <code>None</code> <code>Metadata</code> <p>Data source to use when tone-mapping</p> <code>AUTO</code> <code>Optional[bool]</code> <p>Whether to use Dolby Vision RPU for ST2086 metadata</p> <code>None</code> <code>bool</code> <p>Display a (PQ-PQ) graph of the active tone-mapping LUT</p> <code>False</code> <code>bool</code> <p>Highlight hard-clipped pixels during tone-mapping</p> <code>False</code> <code>Union[float, int]</code> <p>HDR contrast recovery strength</p> <code>0.3</code> <code>int</code> <p>Logging verbosity level</p> <code>2</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Tonemapped video clip</p> Source code in <code>y5gfunc/filter/tonemap.py</code> <pre><code>def tonemap(\n    clip: vs.VideoNode,\n    src_csp: ColorSpace,\n    dst_csp: ColorSpace,\n    dst_prim: Optional[Union[ColorPrimaries, vstools.Primaries]] = None,\n    src_max: Optional[Union[float, int]] = None,\n    src_min: Optional[Union[float, int]] = None,\n    dst_max: Optional[Union[float, int]] = None,\n    dst_min: Optional[Union[float, int]] = None,\n    dynamic_peak_detection: bool = True,\n    smoothing_period: Union[float, int] = 20.0,\n    scene_threshold_low: Union[float, int] = 1.0,\n    scene_threshold_high: Union[float, int] = 3.0,\n    percentile: Union[float, int] = 99.995,\n    gamut_mapping: GamutMapping = GamutMapping.PERCEPTUAL,\n    tone_mapping_function: ToneMappingFunction = ToneMappingFunction.SPLINE,\n    tone_mapping_param: Optional[Union[float, int]] = None,\n    metadata: Metadata = Metadata.AUTO,\n    use_dovi: Optional[bool] = None,\n    visualize_lut: bool = False,\n    show_clipping: bool = False,\n    contrast_recovery: Union[float, int] = 0.3,\n    log_level: int = 2,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Color mapping using placebo.Tonemap.\n\n    Args:\n        clip: Input video clip\n        src_csp: Source colorspace (SDR, HDR10, HLG, DOLBY_VISION)\n        dst_csp: Destination colorspace (SDR, HDR10, HLG, DOLBY_VISION)\n        dst_prim: Destination color primaries\n        src_max: Source maximum display level in nits (cd/m\u00b2)\n        src_min: Source minimum display level in nits (cd/m\u00b2)\n        dst_max: Destination maximum display level in nits (cd/m\u00b2)\n        dst_min: Destination minimum display level in nits (cd/m\u00b2)\n        dynamic_peak_detection: Enables HDR peak detection\n        smoothing_period: Smoothing coefficient for detected values (in frames)\n        scene_threshold_low: Lower bound for scene change detection (in units of 1% PQ)\n        scene_threshold_high: Upper bound for scene change detection (in units of 1% PQ)\n        percentile: Percentile of brightness histogram to consider as true peak\n        gamut_mapping: Gamut mapping function to handle out-of-gamut colors\n        tone_mapping_function: Tone mapping function\n        tone_mapping_param: Optional parameter for tone mapping function\n        metadata: Data source to use when tone-mapping\n        use_dovi: Whether to use Dolby Vision RPU for ST2086 metadata\n        visualize_lut: Display a (PQ-PQ) graph of the active tone-mapping LUT\n        show_clipping: Highlight hard-clipped pixels during tone-mapping\n        contrast_recovery: HDR contrast recovery strength\n        log_level: Logging verbosity level\n\n    Returns:\n        Tonemapped video clip\n    \"\"\"\n    src_csp_int = int(src_csp)\n    dst_csp_int = int(dst_csp)\n\n    if isinstance(dst_prim, ColorPrimaries):\n        dst_prim_int = int(dst_prim)\n    elif isinstance(dst_prim, vstools.Primaries):\n        dst_prim_int = dst_prim.value_libplacebo\n    else:\n        dst_prim_int = None\n\n    gamut_mapping_int = int(gamut_mapping)\n    metadata_int = int(metadata)\n\n    tone_mapping_function_int = int(tone_mapping_function)\n\n    return core.placebo.Tonemap(\n        clip=clip,\n        src_csp=src_csp_int,\n        dst_csp=dst_csp_int,\n        dst_prim=dst_prim_int,  # type: ignore\n        src_max=src_max,  # type: ignore\n        src_min=src_min,  # type: ignore\n        dst_max=dst_max,  # type: ignore\n        dst_min=dst_min,  # type: ignore\n        dynamic_peak_detection=dynamic_peak_detection,\n        smoothing_period=smoothing_period,\n        scene_threshold_low=scene_threshold_low,\n        scene_threshold_high=scene_threshold_high,\n        percentile=percentile,\n        gamut_mapping=gamut_mapping_int,\n        tone_mapping_function=tone_mapping_function_int,\n        tone_mapping_param=tone_mapping_param,  # type: ignore\n        metadata=metadata_int,\n        use_dovi=use_dovi,  # type: ignore\n        visualize_lut=visualize_lut,\n        show_clipping=show_clipping,\n        contrast_recovery=contrast_recovery,\n        log_level=log_level,\n    )\n</code></pre>"},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(clip)","title":"<code>clip</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(src_csp)","title":"<code>src_csp</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(dst_csp)","title":"<code>dst_csp</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(dst_prim)","title":"<code>dst_prim</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(src_max)","title":"<code>src_max</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(src_min)","title":"<code>src_min</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(dst_max)","title":"<code>dst_max</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(dst_min)","title":"<code>dst_min</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(dynamic_peak_detection)","title":"<code>dynamic_peak_detection</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(smoothing_period)","title":"<code>smoothing_period</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(scene_threshold_low)","title":"<code>scene_threshold_low</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(scene_threshold_high)","title":"<code>scene_threshold_high</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(percentile)","title":"<code>percentile</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(gamut_mapping)","title":"<code>gamut_mapping</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(tone_mapping_function)","title":"<code>tone_mapping_function</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(tone_mapping_param)","title":"<code>tone_mapping_param</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(metadata)","title":"<code>metadata</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(use_dovi)","title":"<code>use_dovi</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(visualize_lut)","title":"<code>visualize_lut</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(show_clipping)","title":"<code>show_clipping</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(contrast_recovery)","title":"<code>contrast_recovery</code>","text":""},{"location":"API/filter/tonemap/#y5gfunc.filter.tonemap.tonemap(log_level)","title":"<code>log_level</code>","text":""},{"location":"API/filter/utils/","title":"<code>y5gfunc.filter.utils</code>","text":""},{"location":"API/filter/utils/#y5gfunc.filter.utils","title":"utils","text":"<p>Functions:</p> Name Description <code>is_optimized_cpu</code> <p>Attributes:</p> Name Type Description <code>get_peak_value_full</code>"},{"location":"API/filter/utils/#y5gfunc.filter.utils.get_peak_value_full","title":"get_peak_value_full  <code>module-attribute</code>","text":"<pre><code>get_peak_value_full = partial(get_peak_value, range_in=FULL)\n</code></pre>"},{"location":"API/filter/utils/#y5gfunc.filter.utils.is_optimized_cpu","title":"is_optimized_cpu","text":"<pre><code>is_optimized_cpu() -&gt; bool\n</code></pre> Source code in <code>y5gfunc/filter/utils.py</code> <pre><code>def is_optimized_cpu() -&gt; bool:\n    machine = platform.machine()\n\n    if \"arm64\" or \"x86_64\" in machine.lower():\n        return True\n\n    return False\n</code></pre>"},{"location":"API/preview/output/","title":"<code>y5gfunc.preview.output</code>","text":""},{"location":"API/preview/output/#y5gfunc.preview.output","title":"output","text":"<p>Functions:</p> Name Description <code>reset_output_index</code> <p>Resets the global output index counter and the set of used indices.</p> <code>set_preview</code> <p>Outputs VapourSynth clips in vspreview.</p> <p>Attributes:</p> Name Type Description <code>used_indices</code>"},{"location":"API/preview/output/#y5gfunc.preview.output.used_indices","title":"used_indices  <code>module-attribute</code>","text":"<pre><code>used_indices = set()\n</code></pre>"},{"location":"API/preview/output/#y5gfunc.preview.output.reset_output_index","title":"reset_output_index","text":"<pre><code>reset_output_index(index: int = 0) -&gt; None\n</code></pre> <p>Resets the global output index counter and the set of used indices.</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>The value to reset the automatic index counter to.</p> <code>0</code> Source code in <code>y5gfunc/preview/output.py</code> <pre><code>def reset_output_index(index: int = 0) -&gt; None:\n    \"\"\"Resets the global output index counter and the set of used indices.\n\n    Args:\n        index: The value to reset the automatic index counter to.\n    \"\"\"\n    global _output_index\n    _output_index = index\n    global used_indices\n    used_indices = set()\n</code></pre>"},{"location":"API/preview/output/#y5gfunc.preview.output.reset_output_index(index)","title":"<code>index</code>","text":""},{"location":"API/preview/output/#y5gfunc.preview.output.set_preview","title":"set_preview","text":"<pre><code>set_preview(*args, debug: bool = True) -&gt; None\n</code></pre> <p>Outputs VapourSynth clips in vspreview.</p> <p>This function handles assigning output indices automatically or allows for explicit index specification. Nodes are named in <code>vspreview</code> as <code>{index}: {variable_name}</code>. When debug=True, node name is overlayed onto the video.</p> <p>Parameters:</p> Name Type Description Default <p>A variable number of arguments representing the clips to output. Each argument can be: - A single <code>vs.VideoNode</code>: This clip will be assigned the next available automatic output index. - A list or tuple of <code>vs.VideoNode</code> objects: Each node in the sequence will be assigned the next available automatic output index. - A tuple in the format <code>(vs.VideoNode, int)</code>: The specified node will be assigned the given integer index. The index must be non-negative. - A list or tuple containing any combination of the above formats, including mixtures of <code>vs.VideoNode</code> and <code>(vs.VideoNode, int)</code> tuples.</p> <code>()</code> <code>bool</code> <p>If True, overlays the inferred variable name onto the output clip for identification during previews.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>debug</code> is True when the script is run for encoding (i.e., <code>__name__ == '__vapoursynth__'</code>).</p> <code>ValueError</code> <p>If an explicitly provided output index in a <code>(clip, index)</code> tuple is negative.</p> <code>ValueError</code> <p>If an explicitly provided output index is already assigned by a prior call to <code>output</code> in the same script execution (unless <code>reset_output_index</code> has been called).</p> <code>TypeError</code> <p>If any provided argument or an element within a passed list/tuple is not a <code>vs.VideoNode</code> or a <code>(vs.VideoNode, int)</code> tuple.</p> Note <p>This function uses global variables (<code>_output_index</code>, <code>used_indices</code>) to track assigned indices across multiple calls within a single script run. Use <code>reset_output_index()</code> to clear this state if you need to reuse indices or manage output sets independently.</p> Source code in <code>y5gfunc/preview/output.py</code> <pre><code>def set_preview(*args, debug: bool = True) -&gt; None:\n    \"\"\"\n    Outputs VapourSynth clips in vspreview.\n\n    This function handles assigning output indices automatically or allows for explicit index specification.\n    Nodes are named in `vspreview` as `{index}: {variable_name}`. When debug=True, node name is overlayed onto the video.\n\n    Args:\n        *args: A variable number of arguments representing the clips to output.\n            Each argument can be:\n            - A single `vs.VideoNode`: This clip will be assigned the next available automatic output index.\n            - A list or tuple of `vs.VideoNode` objects: Each node in the sequence will be assigned the next available automatic output index.\n            - A tuple in the format `(vs.VideoNode, int)`: The specified node will be assigned the given integer index. The index must be non-negative.\n            - A list or tuple containing any combination of the above formats, including mixtures of `vs.VideoNode` and `(vs.VideoNode, int)` tuples.\n        debug: If True, overlays the inferred variable name onto the output clip for identification during previews.\n\n    Raises:\n        ValueError: If `debug` is True when the script is run for encoding (i.e., `__name__ == '__vapoursynth__'`).\n        ValueError: If an explicitly provided output index in a `(clip, index)` tuple is negative.\n        ValueError: If an explicitly provided output index is already assigned by a prior call to `output` in the same script execution (unless `reset_output_index` has been called).\n        TypeError: If any provided argument or an element within a passed list/tuple is not a `vs.VideoNode` or a `(vs.VideoNode, int)` tuple.\n\n    Note:\n        This function uses global variables (`_output_index`, `used_indices`) to track assigned indices across multiple calls within a single script run.\n        Use `reset_output_index()` to clear this state if you need to reuse indices or manage output sets independently.\n    \"\"\"\n    if debug and __name__ == \"__vapoursynth__\":\n        raise ValueError(\"output: Do not set debug=True when encoding!\")\n\n    frame: FrameType = inspect.currentframe().f_back  # type: ignore\n\n    global _output_index\n    global used_indices\n    clips_to_process: list[tuple[vs.VideoNode, Optional[int]]] = []\n\n    for arg in args:\n        if isinstance(arg, (list, tuple)):\n            for item in arg:\n                if isinstance(item, tuple) and len(item) == 2:\n                    clip, index = item\n                    if not isinstance(clip, vs.VideoNode) or not isinstance(index, int):\n                        raise TypeError(\n                            \"output: Expected a tuple of (VideoNode, int) for explicit indexing.\"\n                        )\n                    if index &lt; 0:\n                        raise ValueError(\"output: Output index must be non-negative.\")\n                    clips_to_process.append((clip, index))\n                elif isinstance(item, vs.VideoNode):\n                    clips_to_process.append((item, None))\n                else:\n                    raise TypeError(\n                        f\"output: Invalid element type in list/tuple: {type(item)}. Expected VideoNode or (VideoNode, int).\"\n                    )\n        elif isinstance(arg, vs.VideoNode):\n            clips_to_process.append((arg, None))\n        elif isinstance(arg, tuple) and len(arg) == 2:\n            clip, index = arg\n            if not isinstance(clip, vs.VideoNode) or not isinstance(index, int):\n                raise TypeError(\n                    \"output: Expected a tuple of (VideoNode, int) for explicit indexing.\"\n                )\n            if index &lt; 0:\n                raise ValueError(\"output: Output index must be non-negative.\")\n            clips_to_process.append((clip, index))\n        else:\n            raise TypeError(\n                f\"output: Invalid argument type: {type(arg)}. Expected VideoNode, list/tuple of VideoNodes, or (VideoNode, int).\"\n            )\n\n    # Explicitly Indexed Clips\n    for clip, index in clips_to_process:\n        if index is not None:\n            if index in used_indices:\n                raise ValueError(\n                    f\"output: Output index {index} is already in use. Reset with reset_output_index() or choose another index.\"\n                )\n            variable_name = _get_variable_name(frame, clip)\n            processed_clip = _add_text(clip, f\"{index}: {variable_name}\", debug)\n            set_output(processed_clip, index, name=f\"{index}: {variable_name}\")\n            used_indices.add(index)\n\n    # Automatically Indexed Clips\n    for clip, index in clips_to_process:\n        if index is None:\n            while _output_index in used_indices:\n                _output_index += 1\n            current_auto_index = _output_index\n            variable_name = _get_variable_name(frame, clip)\n            processed_clip = _add_text(\n                clip, f\"{current_auto_index}: {variable_name}\", debug\n            )\n            set_output(\n                processed_clip,\n                current_auto_index,\n                name=f\"{current_auto_index}: {variable_name}\",\n            )\n            used_indices.add(current_auto_index)\n            _output_index += 1\n</code></pre>"},{"location":"API/preview/output/#y5gfunc.preview.output.set_preview(*args)","title":"<code>*args</code>","text":""},{"location":"API/preview/output/#y5gfunc.preview.output.set_preview(debug)","title":"<code>debug</code>","text":""},{"location":"API/preview/screen_shot/","title":"<code>y5gfunc.preview.screen_shot</code>","text":""},{"location":"API/preview/screen_shot/#y5gfunc.preview.screen_shot","title":"screen_shot","text":"<p>Functions:</p> Name Description <code>screen_shot</code> <p>Takes screenshots of specified frames from a VapourSynth clip.</p>"},{"location":"API/preview/screen_shot/#y5gfunc.preview.screen_shot.screen_shot","title":"screen_shot","text":"<pre><code>screen_shot(clip: VideoNode, frames: Union[list[int], int], path: Union[Path, str], file_name: str, overwrite: bool = True) -&gt; None\n</code></pre> <p>Takes screenshots of specified frames from a VapourSynth clip.</p> <p>This function selects one or more frames from the input video clip, and saves each selected frame as a PNG image using the <code>fpng</code> writer.</p> <p>The output filenames are generated based on the <code>file_name</code> format string, where a format specifier (like %d) is replaced by the corresponding frame number.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>The input VapourSynth video node.</p> required <code>Union[list[int], int]</code> <p>The frame number or list of frame numbers to capture. If an integer is provided, it's treated as a single-element list.</p> required <code>Union[Path, str]</code> <p>The directory path where the screenshots will be saved. Can be a string or a pathlib.Path object.</p> required <code>str</code> <p>A format string for the output filename. Must contain a C-style format specifier that will be replaced by the frame number. Example: 'screenshot_%05d' will produce filenames like 'screenshot_00100.png' for frame 100.</p> required <code>bool</code> <p>overwrite parameter for <code>fpng.Write</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>y5gfunc/preview/screen_shot.py</code> <pre><code>def screen_shot(\n    clip: vs.VideoNode,\n    frames: Union[list[int], int],\n    path: Union[Path, str],\n    file_name: str,\n    overwrite: bool = True,\n) -&gt; None:\n    \"\"\"\n    Takes screenshots of specified frames from a VapourSynth clip.\n\n    This function selects one or more frames from the input video clip, and saves each selected frame as a PNG image using the `fpng` writer.\n\n    The output filenames are generated based on the `file_name` format string, where a format specifier (like %d) is replaced by the corresponding frame number.\n\n    Args:\n        clip: The input VapourSynth video node.\n        frames: The frame number or list of frame numbers to capture. If an integer is provided, it's treated as a single-element list.\n        path: The directory path where the screenshots will be saved. Can be a string or a pathlib.Path object.\n        file_name: A format string for the output filename. Must contain a C-style format specifier that will be replaced by the frame number.\n            Example: 'screenshot_%05d' will produce filenames like 'screenshot_00100.png' for frame 100.\n        overwrite: overwrite parameter for `fpng.Write`.\n\n    Returns:\n        None\n    \"\"\"\n    if isinstance(frames, int):\n        frames = [frames]\n\n    output_path = resolve_path(path)\n\n    clip = clip.resize2.Spline36(format=vs.RGB24)\n    clip = PickFrames(clip=clip, indices=frames)\n\n    for i, _ in enumerate(clip.frames()):\n        tmp = clip.std.Trim(first=i, last=i).fpng.Write(\n            filename=(output_path / (file_name % frames[i])).with_suffix(\".png\"),  # type: ignore\n            overwrite=overwrite,\n            compression=2,\n        )\n        for f in tmp.frames():\n            pass\n</code></pre>"},{"location":"API/preview/screen_shot/#y5gfunc.preview.screen_shot.screen_shot(clip)","title":"<code>clip</code>","text":""},{"location":"API/preview/screen_shot/#y5gfunc.preview.screen_shot.screen_shot(frames)","title":"<code>frames</code>","text":""},{"location":"API/preview/screen_shot/#y5gfunc.preview.screen_shot.screen_shot(path)","title":"<code>path</code>","text":""},{"location":"API/preview/screen_shot/#y5gfunc.preview.screen_shot.screen_shot(file_name)","title":"<code>file_name</code>","text":""},{"location":"API/preview/screen_shot/#y5gfunc.preview.screen_shot.screen_shot(overwrite)","title":"<code>overwrite</code>","text":""},{"location":"API/shader/chroma/","title":"<code>y5gfunc.shader.chroma</code>","text":""},{"location":"API/shader/chroma/#y5gfunc.shader.chroma","title":"chroma","text":"<p>Attributes:</p> Name Type Description <code>cfl_shader</code> <code>KrigBilateral</code>"},{"location":"API/shader/chroma/#y5gfunc.shader.chroma.cfl_shader","title":"cfl_shader  <code>module-attribute</code>","text":"<pre><code>cfl_shader = LazyVariable('https://raw.githubusercontent.com/Artoriuz/glsl-chroma-from-luma-prediction/refs/heads/main/CfL_Prediction.glsl')\n</code></pre>"},{"location":"API/shader/chroma/#y5gfunc.shader.chroma.KrigBilateral","title":"KrigBilateral  <code>module-attribute</code>","text":"<pre><code>KrigBilateral = LazyVariable('https://raw.githubusercontent.com/awused/dotfiles/refs/heads/master/mpv/.config/mpv/shaders/KrigBilateral.glsl')\n</code></pre>"},{"location":"API/shader/superes/","title":"<code>y5gfunc.shader.superes</code>","text":""},{"location":"API/shader/superes/#y5gfunc.shader.superes","title":"superes","text":"<p>Attributes:</p> Name Type Description <code>fsrcnnx_x2</code> <code>artcnn_c4f16</code> <code>artcnn_c4f32</code> <code>artcnn_c4f16_DS</code> <code>artcnn_c4f32_DS</code>"},{"location":"API/shader/superes/#y5gfunc.shader.superes.fsrcnnx_x2","title":"fsrcnnx_x2  <code>module-attribute</code>","text":"<pre><code>fsrcnnx_x2 = LazyVariable('https://raw.githubusercontent.com/awused/dotfiles/refs/heads/master/mpv/.config/mpv/shaders/fsrcnnx/FSRCNNX_x2_16-0-4-1.glsl')\n</code></pre>"},{"location":"API/shader/superes/#y5gfunc.shader.superes.artcnn_c4f16","title":"artcnn_c4f16  <code>module-attribute</code>","text":"<pre><code>artcnn_c4f16 = LazyVariable('https://raw.githubusercontent.com/Artoriuz/ArtCNN/refs/heads/main/GLSL/ArtCNN_C4F16.glsl')\n</code></pre>"},{"location":"API/shader/superes/#y5gfunc.shader.superes.artcnn_c4f32","title":"artcnn_c4f32  <code>module-attribute</code>","text":"<pre><code>artcnn_c4f32 = LazyVariable('https://raw.githubusercontent.com/Artoriuz/ArtCNN/refs/heads/main/GLSL/ArtCNN_C4F32.glsl')\n</code></pre>"},{"location":"API/shader/superes/#y5gfunc.shader.superes.artcnn_c4f16_DS","title":"artcnn_c4f16_DS  <code>module-attribute</code>","text":"<pre><code>artcnn_c4f16_DS = LazyVariable('https://raw.githubusercontent.com/Artoriuz/ArtCNN/refs/heads/main/GLSL/ArtCNN_C4F16_DS.glsl')\n</code></pre>"},{"location":"API/shader/superes/#y5gfunc.shader.superes.artcnn_c4f32_DS","title":"artcnn_c4f32_DS  <code>module-attribute</code>","text":"<pre><code>artcnn_c4f32_DS = LazyVariable('https://raw.githubusercontent.com/Artoriuz/ArtCNN/refs/heads/main/GLSL/ArtCNN_C4F32_DS.glsl')\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/","title":"<code>y5gfunc.shader.lazy_loader.lazy_loader</code>","text":""},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader","title":"lazy_loader","text":"<p>Classes:</p> Name Description <code>LazyVariable</code>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable","title":"LazyVariable","text":"<pre><code>LazyVariable(url: str, binary: bool = False, timeout: int = 10, max_retries: int = 5, retry_delay: int = 2, cache_ttl: int = 3600)\n</code></pre> <p>Methods:</p> Name Description <code>__str__</code> <code>__bytes__</code> <code>refresh</code> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <code>binary</code> <code>bool</code> <code>timeout</code> <code>int</code> <code>max_retries</code> <code>int</code> <code>retry_delay</code> <code>int</code> <code>cache_ttl</code> <code>int</code> Source code in <code>y5gfunc/shader/lazy_loader/lazy_loader.py</code> <pre><code>def __init__(\n    self,\n    url: str,\n    binary: bool = False,\n    timeout: int = 10,\n    max_retries: int = 5,\n    retry_delay: int = 2,\n    cache_ttl: int = 3600,\n):\n    self.url: str = url\n    self.binary: bool = binary\n    self.timeout: int = timeout\n    self.max_retries: int = max_retries\n    self.retry_delay: int = retry_delay\n    self.cache_ttl: int = cache_ttl\n\n    self._cached_content: Optional[Union[str, bytes]] = None\n    self._cache_timestamp: Optional[float] = None\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable.url","title":"url  <code>instance-attribute</code>","text":"<pre><code>url: str = url\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable.binary","title":"binary  <code>instance-attribute</code>","text":"<pre><code>binary: bool = binary\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable.timeout","title":"timeout  <code>instance-attribute</code>","text":"<pre><code>timeout: int = timeout\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable.max_retries","title":"max_retries  <code>instance-attribute</code>","text":"<pre><code>max_retries: int = max_retries\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable.retry_delay","title":"retry_delay  <code>instance-attribute</code>","text":"<pre><code>retry_delay: int = retry_delay\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable.cache_ttl","title":"cache_ttl  <code>instance-attribute</code>","text":"<pre><code>cache_ttl: int = cache_ttl\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> Source code in <code>y5gfunc/shader/lazy_loader/lazy_loader.py</code> <pre><code>def __str__(self) -&gt; str:\n    content = self._download()\n    return content.decode() if self.binary else content  # type: ignore\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable.__bytes__","title":"__bytes__","text":"<pre><code>__bytes__() -&gt; bytes\n</code></pre> Source code in <code>y5gfunc/shader/lazy_loader/lazy_loader.py</code> <pre><code>def __bytes__(self) -&gt; bytes:\n    content = self._download()\n    return content if self.binary else content.encode()  # type: ignore\n</code></pre>"},{"location":"API/shader/lazy_loader/lazy_loader/#y5gfunc.shader.lazy_loader.lazy_loader.LazyVariable.refresh","title":"refresh","text":"<pre><code>refresh() -&gt; None\n</code></pre> Source code in <code>y5gfunc/shader/lazy_loader/lazy_loader.py</code> <pre><code>def refresh(self) -&gt; None:\n    self._cached_content = None\n    self._cache_timestamp = None\n</code></pre>"},{"location":"API/source/source/","title":"<code>y5gfunc.source.source</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source","title":"source","text":"<p>Functions:</p> Name Description <code>wobbly_source</code> <p>Loads a video from a wobbly .wob project file.</p> <code>bestsource</code> <p>Loads a video source using bestsource (bs.VideoSource).</p> <code>load_source</code> <p>Bestsource and Wobbly wrapper to load a video source.</p>"},{"location":"API/source/source/#y5gfunc.source.source.wobbly_source","title":"wobbly_source","text":"<pre><code>wobbly_source(wob_project_path: Union[str, Path], timecodes_v2_path: Optional[Union[str, Path]] = None) -&gt; VideoNode\n</code></pre> <p>Loads a video from a wobbly .wob project file.</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, Path]</code> <p>Path to the .wob project file.</p> required <code>Optional[Union[str, Path]]</code> <p>Optional path to a V2 timecodes file.</p> <code>None</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>A VapourSynth VideoNode representing the processed video clip.</p> Source code in <code>y5gfunc/source/source.py</code> <pre><code>def wobbly_source(\n    wob_project_path: Union[str, Path],\n    timecodes_v2_path: Optional[Union[str, Path]] = None,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Loads a video from a wobbly .wob project file.\n\n    Args:\n        wob_project_path: Path to the .wob project file.\n        timecodes_v2_path: Optional path to a V2 timecodes file.\n\n    Returns:\n        A VapourSynth VideoNode representing the processed video clip.\n    \"\"\"\n    clip = load_and_process(\n        wob_project_path, timecodes_v2_path, timecode_version=\"v2\"\n    ).std.SetFieldBased(False)\n    return clip\n</code></pre>"},{"location":"API/source/source/#y5gfunc.source.source.wobbly_source(wob_project_path)","title":"<code>wob_project_path</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.wobbly_source(timecodes_v2_path)","title":"<code>timecodes_v2_path</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.bestsource","title":"bestsource","text":"<pre><code>bestsource(file_path: Union[Path, str], track: int = 0, timecodes_v2_path: Optional[Union[Path, str]] = None, variableformat: int = -1, rff: bool = False) -&gt; VideoNode\n</code></pre> <p>Loads a video source using bestsource (bs.VideoSource).</p> <p>Parameters:</p> Name Type Description Default <code>Union[Path, str]</code> <p>Path to the video file.</p> required <code>int</code> <p>Index of the video track to load.</p> <code>0</code> <code>Optional[Union[Path, str]]</code> <p>Path to a V2 timecodes file.</p> <code>None</code> <code>int</code> <p>See bestsource documentation.</p> <code>-1</code> <code>bool</code> <p>See bestsource documentation.</p> <code>False</code> <p>Returns:     A VapourSynth VideoNode loaded by bestsource.</p> Source code in <code>y5gfunc/source/source.py</code> <pre><code>def bestsource(\n    file_path: Union[Path, str],\n    track: int = 0,\n    timecodes_v2_path: Optional[Union[Path, str]] = None,\n    variableformat: int = -1,\n    rff: bool = False,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Loads a video source using bestsource (bs.VideoSource).\n\n    Args:\n        file_path: Path to the video file.\n        track: Index of the video track to load.\n        timecodes_v2_path: Path to a V2 timecodes file.\n        variableformat: See bestsource documentation.\n        rff: See bestsource documentation.\n    Returns:\n        A VapourSynth VideoNode loaded by bestsource.\n    \"\"\"\n    if timecodes_v2_path:\n        return BestSource.source(\n            file=str(file_path),\n            track=track,\n            variableformat=variableformat,\n            timecodes=str(timecodes_v2_path),\n            rff=rff,\n        )\n    else:\n        return BestSource.source(\n            file=str(file_path),\n            track=track,\n            variableformat=variableformat,\n            rff=rff,\n        )\n</code></pre>"},{"location":"API/source/source/#y5gfunc.source.source.bestsource(file_path)","title":"<code>file_path</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.bestsource(track)","title":"<code>track</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.bestsource(timecodes_v2_path)","title":"<code>timecodes_v2_path</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.bestsource(variableformat)","title":"<code>variableformat</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.bestsource(rff)","title":"<code>rff</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.load_source","title":"load_source","text":"<pre><code>load_source(file_path: Union[Path, str], track: int = 0, matrix: Optional[Matrix] = None, matrix_in: Optional[Matrix] = None, timecodes_v2_path: Optional[Union[Path, str]] = None) -&gt; VideoNode\n</code></pre> <p>Bestsource and Wobbly wrapper to load a video source.</p> <p>This function acts as a primary interface for loading video sources. It checks the file extension:     - If it's a \".wob\" file, it uses <code>_wobbly_source</code>.     - Otherwise, it uses <code>_bestsource</code>, attempting to automatically detect if the source uses RFF (Repeat First Field) based on frame counts.</p> <p>After loading, it applies a color matrix conversion.</p> <p>Parameters:</p> Name Type Description Default <code>Union[Path, str]</code> <p>Path to the video file or .wob project file.</p> required <code>int</code> <p>Index of the video track to load. Ignored for .wob files.</p> <code>0</code> <p>Target color matrix.</p> required <p>Input color matrix.</p> required <code>Optional[Union[Path, str]]</code> <p>Path to a V2 timecodes file.</p> <code>None</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>A VapourSynth VideoNode representing the loaded and matrix-converted video clip.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the resolved <code>file_path</code> does not exist.</p> <code>AssertionError</code> <p>If a <code>.wob</code> file is specified but <code>track</code> is not 0.</p> Source code in <code>y5gfunc/source/source.py</code> <pre><code>def load_source(\n    file_path: Union[Path, str],\n    track: int = 0,\n    matrix: Optional[Matrix] = None,\n    matrix_in: Optional[Matrix] = None,\n    timecodes_v2_path: Optional[Union[Path, str]] = None,\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Bestsource and Wobbly wrapper to load a video source.\n\n    This function acts as a primary interface for loading video sources.\n    It checks the file extension:\n        - If it's a \".wob\" file, it uses `_wobbly_source`.\n        - Otherwise, it uses `_bestsource`, attempting to automatically detect if the source uses RFF (Repeat First Field) based on frame counts.\n\n    After loading, it applies a color matrix conversion.\n\n    Args:\n        file_path: Path to the video file or .wob project file.\n        track: Index of the video track to load. Ignored for .wob files.\n        matrix_s: Target color matrix.\n        matrix_in_s: Input color matrix.\n        timecodes_v2_path: Path to a V2 timecodes file.\n\n    Returns:\n        A VapourSynth VideoNode representing the loaded and matrix-converted video clip.\n\n    Raises:\n        FileNotFoundError: If the resolved `file_path` does not exist.\n        AssertionError: If a `.wob` file is specified but `track` is not 0.\n    \"\"\"\n    file_path = resolve_path(file_path)\n\n    if not file_path.exists():\n        raise FileNotFoundError(f\"load_source: File {file_path} does not exist.\")\n\n    if file_path.suffix.lower() == \".wob\":\n        assert track == 0\n        clip = wobbly_source(file_path, timecodes_v2_path)\n    else:\n        # modified from https://guides.vcb-s.com/basic-guide-10/#%E6%A3%80%E6%B5%8B%E6%98%AF%E5%90%A6%E4%B8%BA%E5%85%A8%E7%A8%8B-soft-pulldownpure-film\n        a = bestsource(file_path, rff=False)\n        b = bestsource(file_path, rff=True)\n        rff = False if abs(b.num_frames * 0.8 - a.num_frames) &lt; 1 else True\n\n        clip = bestsource(file_path, track, timecodes_v2_path, rff=rff)\n\n    if matrix is None:\n        matrix = Matrix.from_res(clip)\n\n    if matrix_in is None:\n        matrix_in = Matrix.from_res(clip)\n\n    primaries = Primaries.from_matrix(matrix)\n    primaries_in = Primaries.from_matrix(matrix_in)\n    transfer = Transfer.from_matrix(matrix)\n    transfer_in = Transfer.from_matrix(matrix)\n\n    return clip.resize2.Spline36(\n        matrix=matrix,\n        matrix_in=matrix_in,\n        primaries=primaries,\n        primaries_in=primaries_in,\n        transfer=transfer,\n        transfer_in=transfer_in,\n    )\n</code></pre>"},{"location":"API/source/source/#y5gfunc.source.source.load_source(file_path)","title":"<code>file_path</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.load_source(track)","title":"<code>track</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.load_source(matrix_s)","title":"<code>matrix_s</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.load_source(matrix_in_s)","title":"<code>matrix_in_s</code>","text":""},{"location":"API/source/source/#y5gfunc.source.source.load_source(timecodes_v2_path)","title":"<code>timecodes_v2_path</code>","text":""},{"location":"API/source/timecodes/","title":"<code>y5gfunc.source.timecodes</code>","text":""},{"location":"API/source/timecodes/#y5gfunc.source.timecodes","title":"timecodes","text":"<p>Functions:</p> Name Description <code>get_frame_timestamp</code> <code>clip_to_timecodes</code>"},{"location":"API/source/timecodes/#y5gfunc.source.timecodes.get_frame_timestamp","title":"get_frame_timestamp","text":"<pre><code>get_frame_timestamp(frame_num: int, clip: VideoNode, precision: Literal['second', 'millisecond', 'microsecond', 'nanosecond'] = 'millisecond', timecodes_v2_file: Optional[str] = None) -&gt; str\n</code></pre> Source code in <code>y5gfunc/source/timecodes.py</code> <pre><code>def get_frame_timestamp(\n    frame_num: int,\n    clip: vs.VideoNode,\n    precision: Literal['second', 'millisecond', 'microsecond' ,'nanosecond'] = 'millisecond',\n    timecodes_v2_file: Optional[str] = None\n)-&gt; str:    \n    assert frame_num &gt;= 0\n    assert timecodes_v2_file is None or resolve_path(timecodes_v2_file).exists()\n\n    if frame_num == 0:\n        s = 0.0\n    elif clip.fps != fractions.Fraction(0, 1):\n        t = round(float(10 ** 9 * frame_num * clip.fps ** -1))\n        s = t / 10 ** 9\n    else:\n        if timecodes_v2_file is not None:\n            timecodes = [float(x) / 1000 for x in open(timecodes_v2_file, \"r\").read().splitlines()[1:]]\n            s = timecodes[frame_num]\n        else:\n            s = clip_to_timecodes(clip)[frame_num]\n\n    m = s // 60\n    s %= 60\n    h = m // 60\n    m %= 60\n\n    if precision == 'second':\n        return f\"{h:02.0f}:{m:02.0f}:{round(s):02}\"\n    elif precision == 'millisecond':\n        return f\"{h:02.0f}:{m:02.0f}:{s:06.3f}\"\n    elif precision == 'microsecond':\n        return f\"{h:02.0f}:{m:02.0f}:{s:09.6f}\"\n    elif precision == 'nanosecond':\n        return f\"{h:02.0f}:{m:02.0f}:{s:012.9f}\"\n</code></pre>"},{"location":"API/source/timecodes/#y5gfunc.source.timecodes.clip_to_timecodes","title":"clip_to_timecodes  <code>cached</code>","text":"<pre><code>clip_to_timecodes(clip: VideoNode, path: Optional[str] = None) -&gt; deque[float]\n</code></pre> Source code in <code>y5gfunc/source/timecodes.py</code> <pre><code>@functools.lru_cache\ndef clip_to_timecodes(clip: vs.VideoNode, path: Optional[str] = None) -&gt; deque[float]:\n    if path:\n        path = resolve_path(path) # type: ignore\n\n    timecodes = collections.deque([0.0], maxlen=clip.num_frames + 1)\n    curr_time = fractions.Fraction()\n    init_percentage = 0\n\n    with open(path, \"w\", encoding=\"utf-8\") if path else None as file: # type: ignore\n        if file:\n            file.write(\"# timecode format v2\\n\")\n\n        for i, frame in enumerate(clip.frames()):\n            num: int = frame.props[\"_DurationNum\"] # type: ignore\n            den: int = frame.props[\"_DurationDen\"] # type: ignore\n            curr_time += fractions.Fraction(num, den)\n            timecode = float(curr_time)\n            timecodes.append(timecode)\n\n            if file:\n                file.write(f\"{timecode:.6f}\\n\")\n\n            percentage_done = round(100 * len(timecodes) / clip.num_frames)\n            if percentage_done % 10 == 0 and percentage_done != init_percentage:\n                print(f\"Finding timecodes for variable-framerate clip: {percentage_done}% done\")\n                init_percentage = percentage_done\n\n    return timecodes\n</code></pre>"},{"location":"API/source/wobbly/errors/","title":"<code>y5gfunc.source.wobbly.errors</code>","text":""},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors","title":"errors","text":"<p>Error type definitions for Wobbly parser.</p> <p>Classes:</p> Name Description <code>WobblyError</code> <p>Base error type for Wobbly parser</p> <code>WobblyParseError</code> <p>Error when parsing Wobbly project files</p> <code>WobblyProcessError</code> <p>Error when processing Wobbly projects</p> <code>WobblyInputError</code> <p>Input file related errors</p>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyError","title":"WobblyError","text":"<pre><code>WobblyError(message: str, cause: Optional[Exception] = None)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Base error type for Wobbly parser</p> <p>Attributes:</p> Name Type Description <code>cause</code> Source code in <code>y5gfunc/source/wobbly/errors.py</code> <pre><code>def __init__(self, message: str, cause: Optional[Exception] = None):\n    self.cause = cause\n    super().__init__(f\"{message}\" + (f\" Caused by: {cause}\" if cause else \"\"))\n</code></pre>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyError.cause","title":"cause  <code>instance-attribute</code>","text":"<pre><code>cause = cause\n</code></pre>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyParseError","title":"WobblyParseError","text":"<pre><code>WobblyParseError(message: str, cause: Optional[Exception] = None)\n</code></pre> <p>               Bases: <code>WobblyError</code></p> <p>Error when parsing Wobbly project files</p> <p>Attributes:</p> Name Type Description <code>cause</code> Source code in <code>y5gfunc/source/wobbly/errors.py</code> <pre><code>def __init__(self, message: str, cause: Optional[Exception] = None):\n    self.cause = cause\n    super().__init__(f\"{message}\" + (f\" Caused by: {cause}\" if cause else \"\"))\n</code></pre>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyParseError.cause","title":"cause  <code>instance-attribute</code>","text":"<pre><code>cause = cause\n</code></pre>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyProcessError","title":"WobblyProcessError","text":"<pre><code>WobblyProcessError(message: str, stage: str = 'unknown', details: Optional[Any] = None, cause: Optional[Exception] = None)\n</code></pre> <p>               Bases: <code>WobblyError</code></p> <p>Error when processing Wobbly projects</p> <p>Attributes:</p> Name Type Description <code>stage</code> <code>details</code> <code>cause</code> Source code in <code>y5gfunc/source/wobbly/errors.py</code> <pre><code>def __init__(\n    self, \n    message: str, \n    stage: str = \"unknown\", \n    details: Optional[Any] = None, \n    cause: Optional[Exception] = None\n):\n    self.stage = stage\n    self.details = details\n    super_msg = f\"{message} (stage: {stage})\"\n    super().__init__(super_msg, cause)\n</code></pre>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyProcessError.stage","title":"stage  <code>instance-attribute</code>","text":"<pre><code>stage = stage\n</code></pre>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyProcessError.details","title":"details  <code>instance-attribute</code>","text":"<pre><code>details = details\n</code></pre>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyProcessError.cause","title":"cause  <code>instance-attribute</code>","text":"<pre><code>cause = cause\n</code></pre>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyInputError","title":"WobblyInputError","text":"<pre><code>WobblyInputError(message: str, cause: Optional[Exception] = None)\n</code></pre> <p>               Bases: <code>WobblyError</code></p> <p>Input file related errors</p> <p>Attributes:</p> Name Type Description <code>cause</code> Source code in <code>y5gfunc/source/wobbly/errors.py</code> <pre><code>def __init__(self, message: str, cause: Optional[Exception] = None):\n    self.cause = cause\n    super().__init__(f\"{message}\" + (f\" Caused by: {cause}\" if cause else \"\"))\n</code></pre>"},{"location":"API/source/wobbly/errors/#y5gfunc.source.wobbly.errors.WobblyInputError.cause","title":"cause  <code>instance-attribute</code>","text":"<pre><code>cause = cause\n</code></pre>"},{"location":"API/source/wobbly/types/","title":"<code>y5gfunc.source.wobbly.types</code>","text":""},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types","title":"types","text":"<p>Advanced type definitions for Wobbly parser.</p> <p>Classes:</p> Name Description <code>FieldMatchOrder</code> <p>Field match order enumeration</p> <code>ProcessPosition</code> <p>Processing position enumeration</p> <code>VideoFormat</code> <p>Video format types</p> <code>ResizeFilterType</code> <p>Resize filter type</p> <code>FrameProperties</code> <p>Frame property dictionary type</p> <code>ProjectKey</code> <p>Project key constants</p> <code>VFMParametersKey</code> <p>VFM parameters key constants</p> <code>SectionsKey</code> <p>Sections key constants</p> <code>PresetsKey</code> <p>Presets key constants</p> <code>CustomListsKey</code> <p>Custom lists key constants</p> <code>ResizeKey</code> <p>Resize key constants</p> <code>CropKey</code> <p>Crop key constants</p> <code>DepthKey</code> <p>Depth key constants</p> <code>InterlacedFadesKey</code> <p>Interlaced fades key constants</p> <code>WobblyKeys</code> <p>Key constant collection for Wobbly project JSON structure</p> <code>InterlacedFade</code> <p>Interlaced fade information</p> <code>CropSettings</code> <p>Crop settings</p> <code>ResizeSettings</code> <p>Resize settings</p> <code>DepthSettings</code> <p>Depth settings</p> <code>SectionInfo</code> <p>Section information</p> <code>PresetInfo</code> <p>Preset information</p> <code>CustomListInfo</code> <p>Custom list information</p> <code>FrozenFrameInfo</code> <p>Frozen frame information</p> <code>DecimationRange</code> <p>Decimation range</p> <code>OrphanFieldInfo</code> <p>Orphan field information</p> <code>TimecodeVersion</code> <code>VideoResult</code> <p>Video processing result protocol</p> <code>Result</code> <p>Operation result container</p> <p>Attributes:</p> Name Type Description <code>T</code> <code>R</code> <code>PathLike</code> <code>PresetFunction</code> <code>ProjectData</code> <code>FrameMap</code> <code>FramePropertyMap</code> <code>DecimatedFrameSet</code> <code>MatchString</code> <code>PresetDict</code> <code>OrphanFieldDict</code> <code>CycleDecimationDict</code> <code>DecimationRangeList</code> <code>CustomListRanges</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.T","title":"T  <code>module-attribute</code>","text":"<pre><code>T = TypeVar('T')\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.R","title":"R  <code>module-attribute</code>","text":"<pre><code>R = TypeVar('R')\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.PathLike","title":"PathLike  <code>module-attribute</code>","text":"<pre><code>PathLike = Union[str, Path]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.PresetFunction","title":"PresetFunction  <code>module-attribute</code>","text":"<pre><code>PresetFunction = Callable[[VideoNode], VideoNode]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectData","title":"ProjectData  <code>module-attribute</code>","text":"<pre><code>ProjectData = Dict[str, Any]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameMap","title":"FrameMap  <code>module-attribute</code>","text":"<pre><code>FrameMap = Dict[int, int]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FramePropertyMap","title":"FramePropertyMap  <code>module-attribute</code>","text":"<pre><code>FramePropertyMap = Dict[int, FrameProperties]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DecimatedFrameSet","title":"DecimatedFrameSet  <code>module-attribute</code>","text":"<pre><code>DecimatedFrameSet = Set[int]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.MatchString","title":"MatchString  <code>module-attribute</code>","text":"<pre><code>MatchString = str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.PresetDict","title":"PresetDict  <code>module-attribute</code>","text":"<pre><code>PresetDict = Dict[str, PresetFunction]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.OrphanFieldDict","title":"OrphanFieldDict  <code>module-attribute</code>","text":"<pre><code>OrphanFieldDict = Dict[int, OrphanFieldInfo]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CycleDecimationDict","title":"CycleDecimationDict  <code>module-attribute</code>","text":"<pre><code>CycleDecimationDict = Dict[int, Set[int]]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DecimationRangeList","title":"DecimationRangeList  <code>module-attribute</code>","text":"<pre><code>DecimationRangeList = List[DecimationRange]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListRanges","title":"CustomListRanges  <code>module-attribute</code>","text":"<pre><code>CustomListRanges = List[Tuple[int, int, str, str]]\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FieldMatchOrder","title":"FieldMatchOrder","text":"<p>               Bases: <code>Enum</code></p> <p>Field match order enumeration</p> <p>Attributes:</p> Name Type Description <code>TFF</code> <code>BFF</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FieldMatchOrder.TFF","title":"TFF  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>TFF = 1\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FieldMatchOrder.BFF","title":"BFF  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BFF = 0\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProcessPosition","title":"ProcessPosition","text":"<p>               Bases: <code>Enum</code></p> <p>Processing position enumeration</p> <p>Attributes:</p> Name Type Description <code>POST_SOURCE</code> <code>POST_FIELD_MATCH</code> <code>POST_DECIMATE</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProcessPosition.POST_SOURCE","title":"POST_SOURCE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>POST_SOURCE = 'post source'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProcessPosition.POST_FIELD_MATCH","title":"POST_FIELD_MATCH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>POST_FIELD_MATCH = 'post field match'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProcessPosition.POST_DECIMATE","title":"POST_DECIMATE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>POST_DECIMATE = 'post decimate'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.VideoFormat","title":"VideoFormat","text":"<p>               Bases: <code>Enum</code></p> <p>Video format types</p> <p>Attributes:</p> Name Type Description <code>INTEGER</code> <code>FLOAT</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.VideoFormat.INTEGER","title":"INTEGER  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INTEGER = INTEGER\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.VideoFormat.FLOAT","title":"FLOAT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FLOAT = FLOAT\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeFilterType","title":"ResizeFilterType","text":"<p>               Bases: <code>Enum</code></p> <p>Resize filter type</p> <p>Attributes:</p> Name Type Description <code>BILINEAR</code> <code>BICUBIC</code> <code>LANCZOS</code> <code>SPLINE16</code> <code>SPLINE36</code> <code>POINT</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeFilterType.BILINEAR","title":"BILINEAR  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BILINEAR = 'Bilinear'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeFilterType.BICUBIC","title":"BICUBIC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>BICUBIC = 'Bicubic'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeFilterType.LANCZOS","title":"LANCZOS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LANCZOS = 'Lanczos'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeFilterType.SPLINE16","title":"SPLINE16  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SPLINE16 = 'Spline16'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeFilterType.SPLINE36","title":"SPLINE36  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SPLINE36 = 'Spline36'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeFilterType.POINT","title":"POINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>POINT = 'Point'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties","title":"FrameProperties","text":"<p>               Bases: <code>TypedDict</code></p> <p>Frame property dictionary type</p> <p>Attributes:</p> Name Type Description <code>WobblyProject</code> <code>str</code> <code>WobblyVersion</code> <code>str</code> <code>WobblySourceFilter</code> <code>str</code> <code>WobblyCustomList</code> <code>str</code> <code>WobblyCustomListPreset</code> <code>str</code> <code>WobblyCustomListPosition</code> <code>str</code> <code>WobblySectionStart</code> <code>int</code> <code>WobblySectionEnd</code> <code>int</code> <code>WobblySectionPresets</code> <code>str</code> <code>WobblyMatch</code> <code>str</code> <code>WobblyCombed</code> <code>bool</code> <code>WobblyInterlacedFade</code> <code>bool</code> <code>WobblyFieldDifference</code> <code>float</code> <code>WobblyOrphan</code> <code>bool</code> <code>WobblyOrphanType</code> <code>str</code> <code>WobblyOrphanDecimated</code> <code>bool</code> <code>WobblyFrozenFrame</code> <code>bool</code> <code>WobblyFrozenSource</code> <code>int</code> <code>WobblyDecimated</code> <code>bool</code> <code>WobblyCropEarly</code> <code>bool</code> <code>WobblyCropLeft</code> <code>int</code> <code>WobblyCropTop</code> <code>int</code> <code>WobblyCropRight</code> <code>int</code> <code>WobblyCropBottom</code> <code>int</code> <code>WobblyResizeEnabled</code> <code>bool</code> <code>WobblyResizeWidth</code> <code>int</code> <code>WobblyResizeHeight</code> <code>int</code> <code>WobblyResizeFilter</code> <code>str</code> <code>WobblyDepthEnabled</code> <code>bool</code> <code>WobblyDepthBits</code> <code>int</code> <code>WobblyDepthFloat</code> <code>bool</code> <code>WobblyDepthDither</code> <code>str</code> <code>WobblyTrimStart</code> <code>int</code> <code>WobblyTrimEnd</code> <code>int</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyProject","title":"WobblyProject  <code>instance-attribute</code>","text":"<pre><code>WobblyProject: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyVersion","title":"WobblyVersion  <code>instance-attribute</code>","text":"<pre><code>WobblyVersion: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblySourceFilter","title":"WobblySourceFilter  <code>instance-attribute</code>","text":"<pre><code>WobblySourceFilter: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyCustomList","title":"WobblyCustomList  <code>instance-attribute</code>","text":"<pre><code>WobblyCustomList: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyCustomListPreset","title":"WobblyCustomListPreset  <code>instance-attribute</code>","text":"<pre><code>WobblyCustomListPreset: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyCustomListPosition","title":"WobblyCustomListPosition  <code>instance-attribute</code>","text":"<pre><code>WobblyCustomListPosition: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblySectionStart","title":"WobblySectionStart  <code>instance-attribute</code>","text":"<pre><code>WobblySectionStart: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblySectionEnd","title":"WobblySectionEnd  <code>instance-attribute</code>","text":"<pre><code>WobblySectionEnd: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblySectionPresets","title":"WobblySectionPresets  <code>instance-attribute</code>","text":"<pre><code>WobblySectionPresets: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyMatch","title":"WobblyMatch  <code>instance-attribute</code>","text":"<pre><code>WobblyMatch: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyCombed","title":"WobblyCombed  <code>instance-attribute</code>","text":"<pre><code>WobblyCombed: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyInterlacedFade","title":"WobblyInterlacedFade  <code>instance-attribute</code>","text":"<pre><code>WobblyInterlacedFade: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyFieldDifference","title":"WobblyFieldDifference  <code>instance-attribute</code>","text":"<pre><code>WobblyFieldDifference: float\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyOrphan","title":"WobblyOrphan  <code>instance-attribute</code>","text":"<pre><code>WobblyOrphan: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyOrphanType","title":"WobblyOrphanType  <code>instance-attribute</code>","text":"<pre><code>WobblyOrphanType: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyOrphanDecimated","title":"WobblyOrphanDecimated  <code>instance-attribute</code>","text":"<pre><code>WobblyOrphanDecimated: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyFrozenFrame","title":"WobblyFrozenFrame  <code>instance-attribute</code>","text":"<pre><code>WobblyFrozenFrame: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyFrozenSource","title":"WobblyFrozenSource  <code>instance-attribute</code>","text":"<pre><code>WobblyFrozenSource: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyDecimated","title":"WobblyDecimated  <code>instance-attribute</code>","text":"<pre><code>WobblyDecimated: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyCropEarly","title":"WobblyCropEarly  <code>instance-attribute</code>","text":"<pre><code>WobblyCropEarly: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyCropLeft","title":"WobblyCropLeft  <code>instance-attribute</code>","text":"<pre><code>WobblyCropLeft: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyCropTop","title":"WobblyCropTop  <code>instance-attribute</code>","text":"<pre><code>WobblyCropTop: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyCropRight","title":"WobblyCropRight  <code>instance-attribute</code>","text":"<pre><code>WobblyCropRight: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyCropBottom","title":"WobblyCropBottom  <code>instance-attribute</code>","text":"<pre><code>WobblyCropBottom: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyResizeEnabled","title":"WobblyResizeEnabled  <code>instance-attribute</code>","text":"<pre><code>WobblyResizeEnabled: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyResizeWidth","title":"WobblyResizeWidth  <code>instance-attribute</code>","text":"<pre><code>WobblyResizeWidth: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyResizeHeight","title":"WobblyResizeHeight  <code>instance-attribute</code>","text":"<pre><code>WobblyResizeHeight: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyResizeFilter","title":"WobblyResizeFilter  <code>instance-attribute</code>","text":"<pre><code>WobblyResizeFilter: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyDepthEnabled","title":"WobblyDepthEnabled  <code>instance-attribute</code>","text":"<pre><code>WobblyDepthEnabled: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyDepthBits","title":"WobblyDepthBits  <code>instance-attribute</code>","text":"<pre><code>WobblyDepthBits: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyDepthFloat","title":"WobblyDepthFloat  <code>instance-attribute</code>","text":"<pre><code>WobblyDepthFloat: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyDepthDither","title":"WobblyDepthDither  <code>instance-attribute</code>","text":"<pre><code>WobblyDepthDither: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyTrimStart","title":"WobblyTrimStart  <code>instance-attribute</code>","text":"<pre><code>WobblyTrimStart: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrameProperties.WobblyTrimEnd","title":"WobblyTrimEnd  <code>instance-attribute</code>","text":"<pre><code>WobblyTrimEnd: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey","title":"ProjectKey  <code>dataclass</code>","text":"<pre><code>ProjectKey(wobbly_version: str = 'wobbly version', project_format_version: str = 'project format version', input_file: str = 'input file', input_frame_rate: str = 'input frame rate', input_resolution: str = 'input resolution', trim: str = 'trim', source_filter: str = 'source filter', user_interface: str = 'user interface', vfm_parameters: str = 'vfm parameters', matches: str = 'matches', original_matches: str = 'original matches', sections: str = 'sections', presets: str = 'presets', frozen_frames: str = 'frozen frames', combed_frames: str = 'combed frames', interlaced_fades: str = 'interlaced fades', decimated_frames: str = 'decimated frames', custom_lists: str = 'custom lists', resize: str = 'resize', crop: str = 'crop', depth: str = 'depth')\n</code></pre> <p>Project key constants</p> <p>Attributes:</p> Name Type Description <code>wobbly_version</code> <code>str</code> <code>project_format_version</code> <code>str</code> <code>input_file</code> <code>str</code> <code>input_frame_rate</code> <code>str</code> <code>input_resolution</code> <code>str</code> <code>trim</code> <code>str</code> <code>source_filter</code> <code>str</code> <code>user_interface</code> <code>str</code> <code>vfm_parameters</code> <code>str</code> <code>matches</code> <code>str</code> <code>original_matches</code> <code>str</code> <code>sections</code> <code>str</code> <code>presets</code> <code>str</code> <code>frozen_frames</code> <code>str</code> <code>combed_frames</code> <code>str</code> <code>interlaced_fades</code> <code>str</code> <code>decimated_frames</code> <code>str</code> <code>custom_lists</code> <code>str</code> <code>resize</code> <code>str</code> <code>crop</code> <code>str</code> <code>depth</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.wobbly_version","title":"wobbly_version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>wobbly_version: str = 'wobbly version'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.project_format_version","title":"project_format_version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>project_format_version: str = 'project format version'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.input_file","title":"input_file  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>input_file: str = 'input file'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.input_frame_rate","title":"input_frame_rate  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>input_frame_rate: str = 'input frame rate'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.input_resolution","title":"input_resolution  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>input_resolution: str = 'input resolution'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.trim","title":"trim  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>trim: str = 'trim'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.source_filter","title":"source_filter  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>source_filter: str = 'source filter'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.user_interface","title":"user_interface  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>user_interface: str = 'user interface'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.vfm_parameters","title":"vfm_parameters  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>vfm_parameters: str = 'vfm parameters'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.matches","title":"matches  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>matches: str = 'matches'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.original_matches","title":"original_matches  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>original_matches: str = 'original matches'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.sections","title":"sections  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sections: str = 'sections'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.presets","title":"presets  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>presets: str = 'presets'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.frozen_frames","title":"frozen_frames  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>frozen_frames: str = 'frozen frames'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.combed_frames","title":"combed_frames  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>combed_frames: str = 'combed frames'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.interlaced_fades","title":"interlaced_fades  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>interlaced_fades: str = 'interlaced fades'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.decimated_frames","title":"decimated_frames  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>decimated_frames: str = 'decimated frames'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.custom_lists","title":"custom_lists  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>custom_lists: str = 'custom lists'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.resize","title":"resize  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>resize: str = 'resize'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.crop","title":"crop  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>crop: str = 'crop'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ProjectKey.depth","title":"depth  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>depth: str = 'depth'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.VFMParametersKey","title":"VFMParametersKey  <code>dataclass</code>","text":"<pre><code>VFMParametersKey(order: str = 'order')\n</code></pre> <p>VFM parameters key constants</p> <p>Attributes:</p> Name Type Description <code>order</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.VFMParametersKey.order","title":"order  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>order: str = 'order'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.SectionsKey","title":"SectionsKey  <code>dataclass</code>","text":"<pre><code>SectionsKey(start: str = 'start', presets: str = 'presets')\n</code></pre> <p>Sections key constants</p> <p>Attributes:</p> Name Type Description <code>start</code> <code>str</code> <code>presets</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.SectionsKey.start","title":"start  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>start: str = 'start'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.SectionsKey.presets","title":"presets  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>presets: str = 'presets'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.PresetsKey","title":"PresetsKey  <code>dataclass</code>","text":"<pre><code>PresetsKey(name: str = 'name', contents: str = 'contents')\n</code></pre> <p>Presets key constants</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <code>contents</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.PresetsKey.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: str = 'name'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.PresetsKey.contents","title":"contents  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>contents: str = 'contents'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListsKey","title":"CustomListsKey  <code>dataclass</code>","text":"<pre><code>CustomListsKey(name: str = 'name', preset: str = 'preset', position: str = 'position', frames: str = 'frames')\n</code></pre> <p>Custom lists key constants</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <code>preset</code> <code>str</code> <code>position</code> <code>str</code> <code>frames</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListsKey.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: str = 'name'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListsKey.preset","title":"preset  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>preset: str = 'preset'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListsKey.position","title":"position  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>position: str = 'position'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListsKey.frames","title":"frames  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>frames: str = 'frames'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeKey","title":"ResizeKey  <code>dataclass</code>","text":"<pre><code>ResizeKey(width: str = 'width', height: str = 'height', filter: str = 'filter', enabled: str = 'enabled')\n</code></pre> <p>Resize key constants</p> <p>Attributes:</p> Name Type Description <code>width</code> <code>str</code> <code>height</code> <code>str</code> <code>filter</code> <code>str</code> <code>enabled</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeKey.width","title":"width  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>width: str = 'width'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeKey.height","title":"height  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>height: str = 'height'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeKey.filter","title":"filter  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>filter: str = 'filter'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeKey.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled: str = 'enabled'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropKey","title":"CropKey  <code>dataclass</code>","text":"<pre><code>CropKey(early: str = 'early', left: str = 'left', top: str = 'top', right: str = 'right', bottom: str = 'bottom', enabled: str = 'enabled')\n</code></pre> <p>Crop key constants</p> <p>Attributes:</p> Name Type Description <code>early</code> <code>str</code> <code>left</code> <code>str</code> <code>top</code> <code>str</code> <code>right</code> <code>str</code> <code>bottom</code> <code>str</code> <code>enabled</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropKey.early","title":"early  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>early: str = 'early'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropKey.left","title":"left  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>left: str = 'left'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropKey.top","title":"top  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>top: str = 'top'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropKey.right","title":"right  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>right: str = 'right'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropKey.bottom","title":"bottom  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bottom: str = 'bottom'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropKey.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled: str = 'enabled'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthKey","title":"DepthKey  <code>dataclass</code>","text":"<pre><code>DepthKey(bits: str = 'bits', float_samples: str = 'float samples', dither: str = 'dither', enabled: str = 'enabled')\n</code></pre> <p>Depth key constants</p> <p>Attributes:</p> Name Type Description <code>bits</code> <code>str</code> <code>float_samples</code> <code>str</code> <code>dither</code> <code>str</code> <code>enabled</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthKey.bits","title":"bits  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bits: str = 'bits'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthKey.float_samples","title":"float_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>float_samples: str = 'float samples'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthKey.dither","title":"dither  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>dither: str = 'dither'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthKey.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled: str = 'enabled'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.InterlacedFadesKey","title":"InterlacedFadesKey  <code>dataclass</code>","text":"<pre><code>InterlacedFadesKey(frame: str = 'frame', field_difference: str = 'field difference')\n</code></pre> <p>Interlaced fades key constants</p> <p>Attributes:</p> Name Type Description <code>frame</code> <code>str</code> <code>field_difference</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.InterlacedFadesKey.frame","title":"frame  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>frame: str = 'frame'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.InterlacedFadesKey.field_difference","title":"field_difference  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>field_difference: str = 'field difference'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys","title":"WobblyKeys  <code>dataclass</code>","text":"<pre><code>WobblyKeys(project: ProjectKey = ProjectKey(), vfm_parameters: VFMParametersKey = VFMParametersKey(), sections: SectionsKey = SectionsKey(), presets: PresetsKey = PresetsKey(), custom_lists: CustomListsKey = CustomListsKey(), resize: ResizeKey = ResizeKey(), crop: CropKey = CropKey(), depth: DepthKey = DepthKey(), interlaced_fades: InterlacedFadesKey = InterlacedFadesKey())\n</code></pre> <p>Key constant collection for Wobbly project JSON structure</p> <p>Attributes:</p> Name Type Description <code>project</code> <code>ProjectKey</code> <code>vfm_parameters</code> <code>VFMParametersKey</code> <code>sections</code> <code>SectionsKey</code> <code>presets</code> <code>PresetsKey</code> <code>custom_lists</code> <code>CustomListsKey</code> <code>resize</code> <code>ResizeKey</code> <code>crop</code> <code>CropKey</code> <code>depth</code> <code>DepthKey</code> <code>interlaced_fades</code> <code>InterlacedFadesKey</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys.project","title":"project  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>project: ProjectKey = field(default_factory=ProjectKey)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys.vfm_parameters","title":"vfm_parameters  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>vfm_parameters: VFMParametersKey = field(default_factory=VFMParametersKey)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys.sections","title":"sections  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sections: SectionsKey = field(default_factory=SectionsKey)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys.presets","title":"presets  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>presets: PresetsKey = field(default_factory=PresetsKey)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys.custom_lists","title":"custom_lists  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>custom_lists: CustomListsKey = field(default_factory=CustomListsKey)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys.resize","title":"resize  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>resize: ResizeKey = field(default_factory=ResizeKey)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys.crop","title":"crop  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>crop: CropKey = field(default_factory=CropKey)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys.depth","title":"depth  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>depth: DepthKey = field(default_factory=DepthKey)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.WobblyKeys.interlaced_fades","title":"interlaced_fades  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>interlaced_fades: InterlacedFadesKey = field(default_factory=InterlacedFadesKey)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.InterlacedFade","title":"InterlacedFade  <code>dataclass</code>","text":"<pre><code>InterlacedFade(frame: int, field_difference: float = 0.0)\n</code></pre> <p>Interlaced fade information</p> <p>Attributes:</p> Name Type Description <code>frame</code> <code>int</code> <code>field_difference</code> <code>float</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.InterlacedFade.frame","title":"frame  <code>instance-attribute</code>","text":"<pre><code>frame: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.InterlacedFade.field_difference","title":"field_difference  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>field_difference: float = 0.0\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropSettings","title":"CropSettings  <code>dataclass</code>","text":"<pre><code>CropSettings(enabled: bool = False, early: bool = False, left: int = 0, top: int = 0, right: int = 0, bottom: int = 0)\n</code></pre> <p>Crop settings</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <code>early</code> <code>bool</code> <code>left</code> <code>int</code> <code>top</code> <code>int</code> <code>right</code> <code>int</code> <code>bottom</code> <code>int</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropSettings.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled: bool = False\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropSettings.early","title":"early  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>early: bool = False\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropSettings.left","title":"left  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>left: int = 0\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropSettings.top","title":"top  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>top: int = 0\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropSettings.right","title":"right  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>right: int = 0\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CropSettings.bottom","title":"bottom  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bottom: int = 0\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeSettings","title":"ResizeSettings  <code>dataclass</code>","text":"<pre><code>ResizeSettings(enabled: bool = False, width: int = 0, height: int = 0, filter: ResizeFilterType = BICUBIC)\n</code></pre> <p>Resize settings</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <code>width</code> <code>int</code> <code>height</code> <code>int</code> <code>filter</code> <code>ResizeFilterType</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeSettings.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled: bool = False\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeSettings.width","title":"width  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>width: int = 0\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeSettings.height","title":"height  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>height: int = 0\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.ResizeSettings.filter","title":"filter  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>filter: ResizeFilterType = BICUBIC\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthSettings","title":"DepthSettings  <code>dataclass</code>","text":"<pre><code>DepthSettings(enabled: bool = False, bits: int = 8, float_samples: bool = False, dither: str = '')\n</code></pre> <p>Depth settings</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <code>bits</code> <code>int</code> <code>float_samples</code> <code>bool</code> <code>dither</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthSettings.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled: bool = False\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthSettings.bits","title":"bits  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>bits: int = 8\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthSettings.float_samples","title":"float_samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>float_samples: bool = False\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DepthSettings.dither","title":"dither  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>dither: str = ''\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.SectionInfo","title":"SectionInfo  <code>dataclass</code>","text":"<pre><code>SectionInfo(start: int, presets: List[str] = list())\n</code></pre> <p>Section information</p> <p>Attributes:</p> Name Type Description <code>start</code> <code>int</code> <code>presets</code> <code>List[str]</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.SectionInfo.start","title":"start  <code>instance-attribute</code>","text":"<pre><code>start: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.SectionInfo.presets","title":"presets  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>presets: List[str] = field(default_factory=list)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.PresetInfo","title":"PresetInfo  <code>dataclass</code>","text":"<pre><code>PresetInfo(name: str, contents: str)\n</code></pre> <p>Preset information</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <code>contents</code> <code>str</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.PresetInfo.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.PresetInfo.contents","title":"contents  <code>instance-attribute</code>","text":"<pre><code>contents: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListInfo","title":"CustomListInfo  <code>dataclass</code>","text":"<pre><code>CustomListInfo(name: str, preset: str, position: ProcessPosition, frames: List[Tuple[int, int]] = list())\n</code></pre> <p>Custom list information</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <code>preset</code> <code>str</code> <code>position</code> <code>ProcessPosition</code> <code>frames</code> <code>List[Tuple[int, int]]</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListInfo.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListInfo.preset","title":"preset  <code>instance-attribute</code>","text":"<pre><code>preset: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListInfo.position","title":"position  <code>instance-attribute</code>","text":"<pre><code>position: ProcessPosition\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.CustomListInfo.frames","title":"frames  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>frames: List[Tuple[int, int]] = field(default_factory=list)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrozenFrameInfo","title":"FrozenFrameInfo  <code>dataclass</code>","text":"<pre><code>FrozenFrameInfo(first: int, last: int, replacement: int)\n</code></pre> <p>Frozen frame information</p> <p>Attributes:</p> Name Type Description <code>first</code> <code>int</code> <code>last</code> <code>int</code> <code>replacement</code> <code>int</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrozenFrameInfo.first","title":"first  <code>instance-attribute</code>","text":"<pre><code>first: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrozenFrameInfo.last","title":"last  <code>instance-attribute</code>","text":"<pre><code>last: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.FrozenFrameInfo.replacement","title":"replacement  <code>instance-attribute</code>","text":"<pre><code>replacement: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DecimationRange","title":"DecimationRange  <code>dataclass</code>","text":"<pre><code>DecimationRange(start: int, end: int, dropped: int)\n</code></pre> <p>Decimation range</p> <p>Attributes:</p> Name Type Description <code>start</code> <code>int</code> <code>end</code> <code>int</code> <code>dropped</code> <code>int</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DecimationRange.start","title":"start  <code>instance-attribute</code>","text":"<pre><code>start: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DecimationRange.end","title":"end  <code>instance-attribute</code>","text":"<pre><code>end: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.DecimationRange.dropped","title":"dropped  <code>instance-attribute</code>","text":"<pre><code>dropped: int\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.OrphanFieldInfo","title":"OrphanFieldInfo  <code>dataclass</code>","text":"<pre><code>OrphanFieldInfo(type: str, decimated: bool)\n</code></pre> <p>Orphan field information</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <code>decimated</code> <code>bool</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.OrphanFieldInfo.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: str\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.OrphanFieldInfo.decimated","title":"decimated  <code>instance-attribute</code>","text":"<pre><code>decimated: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.TimecodeVersion","title":"TimecodeVersion","text":"<p>Methods:</p> Name Description <code>is_valid</code> <p>Attributes:</p> Name Type Description <code>V1</code> <code>V2</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.TimecodeVersion.V1","title":"V1  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>V1 = 'v1'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.TimecodeVersion.V2","title":"V2  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>V2 = 'v2'\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.TimecodeVersion.is_valid","title":"is_valid  <code>classmethod</code>","text":"<pre><code>is_valid(version: str) -&gt; bool\n</code></pre> Source code in <code>y5gfunc/source/wobbly/types.py</code> <pre><code>@classmethod\ndef is_valid(cls, version: str) -&gt; bool:\n    return version in (cls.V1, cls.V2)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.VideoResult","title":"VideoResult","text":"<p>               Bases: <code>Protocol</code></p> <p>Video processing result protocol</p> <p>Attributes:</p> Name Type Description <code>clip</code> <code>VideoNode</code> <code>frame_props</code> <code>FramePropertyMap</code> <code>frame_mapping</code> <code>FrameMap</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.VideoResult.clip","title":"clip  <code>instance-attribute</code>","text":"<pre><code>clip: VideoNode\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.VideoResult.frame_props","title":"frame_props  <code>instance-attribute</code>","text":"<pre><code>frame_props: FramePropertyMap\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.VideoResult.frame_mapping","title":"frame_mapping  <code>instance-attribute</code>","text":"<pre><code>frame_mapping: FrameMap\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.Result","title":"Result  <code>dataclass</code>","text":"<pre><code>Result(success: bool, value: Optional[T] = None, error: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> <p>Operation result container</p> <p>Methods:</p> Name Description <code>ok</code> <p>Create success result</p> <code>err</code> <p>Create error result</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>bool</code> <code>value</code> <code>Optional[T]</code> <code>error</code> <code>Optional[str]</code>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.Result.success","title":"success  <code>instance-attribute</code>","text":"<pre><code>success: bool\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.Result.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value: Optional[T] = None\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.Result.error","title":"error  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>error: Optional[str] = None\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.Result.ok","title":"ok  <code>classmethod</code>","text":"<pre><code>ok(value: T) -&gt; Result[T]\n</code></pre> <p>Create success result</p> Source code in <code>y5gfunc/source/wobbly/types.py</code> <pre><code>@classmethod\ndef ok(cls, value: T) -&gt; 'Result[T]':\n    \"\"\"Create success result\"\"\"\n    return cls(success=True, value=value)\n</code></pre>"},{"location":"API/source/wobbly/types/#y5gfunc.source.wobbly.types.Result.err","title":"err  <code>classmethod</code>","text":"<pre><code>err(error: str) -&gt; Result[T]\n</code></pre> <p>Create error result</p> Source code in <code>y5gfunc/source/wobbly/types.py</code> <pre><code>@classmethod\ndef err(cls, error: str) -&gt; 'Result[T]':\n    \"\"\"Create error result\"\"\"\n    return cls(success=False, error=error)\n</code></pre>"},{"location":"API/source/wobbly/utils/","title":"<code>y5gfunc.source.wobbly.utils</code>","text":""},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils","title":"utils","text":"<p>Utility functions for Wobbly parser.</p> <p>Classes:</p> Name Description <code>Result</code> <p>Operation result container</p> <p>Functions:</p> Name Description <code>get_decimation_info</code> <p>Get decimation cycle information from the project</p> <code>frame_number_after_decimation</code> <p>Calculate frame number after decimation</p> <p>Attributes:</p> Name Type Description <code>T</code>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.T","title":"T  <code>module-attribute</code>","text":"<pre><code>T = TypeVar('T')\n</code></pre>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.Result","title":"Result  <code>dataclass</code>","text":"<pre><code>Result(success: bool, value: Optional[T] = None, error: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> <p>Operation result container</p> <p>Methods:</p> Name Description <code>ok</code> <p>Create success result</p> <code>err</code> <p>Create error result</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>bool</code> <code>value</code> <code>Optional[T]</code> <code>error</code> <code>Optional[str]</code>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.Result.success","title":"success  <code>instance-attribute</code>","text":"<pre><code>success: bool\n</code></pre>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.Result.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value: Optional[T] = None\n</code></pre>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.Result.error","title":"error  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>error: Optional[str] = None\n</code></pre>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.Result.ok","title":"ok  <code>classmethod</code>","text":"<pre><code>ok(value: T) -&gt; Result[T]\n</code></pre> <p>Create success result</p> Source code in <code>y5gfunc/source/wobbly/utils.py</code> <pre><code>@classmethod\ndef ok(cls, value: T) -&gt; 'Result[T]':\n    \"\"\"Create success result\"\"\"\n    return cls(success=True, value=value)\n</code></pre>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.Result.err","title":"err  <code>classmethod</code>","text":"<pre><code>err(error: str) -&gt; Result[T]\n</code></pre> <p>Create error result</p> Source code in <code>y5gfunc/source/wobbly/utils.py</code> <pre><code>@classmethod\ndef err(cls, error: str) -&gt; 'Result[T]':\n    \"\"\"Create error result\"\"\"\n    return cls(success=False, error=error)\n</code></pre>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.get_decimation_info","title":"get_decimation_info","text":"<pre><code>get_decimation_info(project: ProjectData) -&gt; Tuple[CycleDecimationDict, DecimationRangeList]\n</code></pre> <p>Get decimation cycle information from the project</p> <p>Parameters:</p> Name Type Description Default <code>ProjectData</code> <p>Wobbly project data</p> required <p>Returns:</p> Type Description <code>Tuple[CycleDecimationDict, DecimationRangeList]</code> <p>Tuple of (decimated_by_cycle, ranges)</p> Source code in <code>y5gfunc/source/wobbly/utils.py</code> <pre><code>def get_decimation_info(project: ProjectData) -&gt; Tuple[CycleDecimationDict, DecimationRangeList]:\n    \"\"\"\n    Get decimation cycle information from the project\n\n    Args:\n        project: Wobbly project data\n\n    Returns:\n        Tuple of (decimated_by_cycle, ranges)\n    \"\"\"\n    # Get decimated frames and project length\n    decimated_frames: List[int] = project.get('decimated frames', [])\n\n    # Calculate total frames from trim data\n    num_frames = 0\n    if 'trim' in project:\n        for trim in project['trim']:\n            if isinstance(trim, list) and len(trim) &gt;= 2:\n                num_frames += trim[1] - trim[0] + 1\n\n    # Group decimated frames by cycle\n    decimated_by_cycle: Dict[int, Set[int]] = {}\n    for frame in decimated_frames:\n        cycle = frame // 5\n        if cycle not in decimated_by_cycle:\n            decimated_by_cycle[cycle] = set()\n        decimated_by_cycle[cycle].add(frame % 5)\n\n    # Calculate decimation ranges\n    ranges: List[DecimationRange] = []\n    current_count = -1\n    current_start = 0\n\n    for cycle in range((num_frames + 4) // 5):\n        count = len(decimated_by_cycle.get(cycle, set()))\n        if count != current_count:\n            if current_count != -1:\n                ranges.append(DecimationRange(\n                    start=current_start,\n                    end=cycle * 5,\n                    dropped=current_count\n                ))\n            current_count = count\n            current_start = cycle * 5\n\n    if current_count != -1:\n        ranges.append(DecimationRange(\n            start=current_start,\n            end=num_frames,\n            dropped=current_count\n        ))\n\n    return decimated_by_cycle, ranges\n</code></pre>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.get_decimation_info(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.frame_number_after_decimation","title":"frame_number_after_decimation","text":"<pre><code>frame_number_after_decimation(frame: int, decimated_by_cycle: CycleDecimationDict) -&gt; int\n</code></pre> <p>Calculate frame number after decimation</p> <p>Parameters:</p> Name Type Description Default <code>int</code> <p>Original frame number</p> required <code>CycleDecimationDict</code> <p>Dictionary mapping cycles to sets of decimated offsets</p> required <p>Returns:</p> Type Description <code>int</code> <p>Frame number after decimation</p> Source code in <code>y5gfunc/source/wobbly/utils.py</code> <pre><code>def frame_number_after_decimation(frame: int, decimated_by_cycle: CycleDecimationDict) -&gt; int:\n    \"\"\"\n    Calculate frame number after decimation\n\n    Args:\n        frame: Original frame number\n        decimated_by_cycle: Dictionary mapping cycles to sets of decimated offsets\n\n    Returns:\n        Frame number after decimation\n    \"\"\"\n    if frame &lt; 0:\n        return 0\n\n    cycle = frame // 5\n    offset = frame % 5\n\n    # Count decimated frames before this one\n    decimated_before = 0\n    for c in range(cycle):\n        decimated_before += len(decimated_by_cycle.get(c, set()))\n\n    for o in range(offset):\n        if o in decimated_by_cycle.get(cycle, set()):\n            decimated_before += 1\n\n    return frame - decimated_before\n</code></pre>"},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.frame_number_after_decimation(frame)","title":"<code>frame</code>","text":""},{"location":"API/source/wobbly/utils/#y5gfunc.source.wobbly.utils.frame_number_after_decimation(decimated_by_cycle)","title":"<code>decimated_by_cycle</code>","text":""},{"location":"API/source/wobbly/core/context/","title":"<code>y5gfunc.source.wobbly.core.context</code>","text":""},{"location":"API/source/wobbly/core/context/#y5gfunc.source.wobbly.core.context","title":"context","text":"<p>Processing contexts and helpers for Wobbly parser.</p> <p>Functions:</p> Name Description <code>safe_processing</code> <p>Safe processing context manager for catching and transforming exceptions</p>"},{"location":"API/source/wobbly/core/context/#y5gfunc.source.wobbly.core.context.safe_processing","title":"safe_processing","text":"<pre><code>safe_processing(stage: str, details: Optional[Dict[str, Any]] = None) -&gt; Iterator[None]\n</code></pre> <p>Safe processing context manager for catching and transforming exceptions</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Processing stage name</p> required <code>Optional[Dict[str, Any]]</code> <p>Optional details to include in error</p> <code>None</code> <p>Yields:</p> Type Description <code>None</code> <p>Nothing</p> Source code in <code>y5gfunc/source/wobbly/core/context.py</code> <pre><code>@contextmanager\ndef safe_processing(stage: str, details: Optional[Dict[str, Any]] = None) -&gt; Iterator[None]:\n    \"\"\"\n    Safe processing context manager for catching and transforming exceptions\n\n    Args:\n        stage: Processing stage name\n        details: Optional details to include in error\n\n    Yields:\n        Nothing\n    \"\"\"\n    try:\n        yield\n    except WobblyError:\n        # Already a WobblyError, re-raise\n        raise\n    except Exception as e:\n        # Convert other exceptions to WobblyProcessError\n        raise WobblyProcessError(\n            f\"Error during {stage}\",\n            stage=stage,\n            details=details,\n            cause=e\n        )\n</code></pre>"},{"location":"API/source/wobbly/core/context/#y5gfunc.source.wobbly.core.context.safe_processing(stage)","title":"<code>stage</code>","text":""},{"location":"API/source/wobbly/core/context/#y5gfunc.source.wobbly.core.context.safe_processing(details)","title":"<code>details</code>","text":""},{"location":"API/source/wobbly/core/presets/","title":"<code>y5gfunc.source.wobbly.core.presets</code>","text":""},{"location":"API/source/wobbly/core/presets/#y5gfunc.source.wobbly.core.presets","title":"presets","text":"<p>Preset handling for Wobbly parser.</p> <p>Functions:</p> Name Description <code>create_preset_functions</code> <p>Create preset functions from project data</p>"},{"location":"API/source/wobbly/core/presets/#y5gfunc.source.wobbly.core.presets.create_preset_functions","title":"create_preset_functions","text":"<pre><code>create_preset_functions(project: ProjectData, keys: WobblyKeys) -&gt; PresetDict\n</code></pre> <p>Create preset functions from project data</p> <p>Parameters:</p> Name Type Description Default <code>ProjectData</code> <p>Project data</p> required <code>WobblyKeys</code> <p>Keys for accessing project data</p> required <p>Returns:</p> Type Description <code>PresetDict</code> <p>Dictionary mapping preset names to preset functions</p> Source code in <code>y5gfunc/source/wobbly/core/presets.py</code> <pre><code>def create_preset_functions(project: ProjectData, keys: WobblyKeys) -&gt; PresetDict:\n    \"\"\"\n    Create preset functions from project data\n\n    Args:\n        project: Project data\n        keys: Keys for accessing project data\n\n    Returns:\n        Dictionary mapping preset names to preset functions\n    \"\"\"\n    presets: PresetDict = {}\n    core = vs.core\n\n    with safe_processing(\"preset_creation\"):\n        # Create preset functions\n        for preset_info in project.get(keys.project.presets, []):\n            preset_name = preset_info.get(keys.presets.name)\n            preset_contents = preset_info.get(keys.presets.contents)\n\n            if not preset_name or preset_contents is None:\n                continue\n\n            try:\n                # Create executable preset function\n                exec_globals = {'vs': vs, 'core': core, 'c': core}\n                exec(f\"def preset_{preset_name}(clip):\\n\" +\n                     \"\\n\".join(\"    \" + line for line in preset_contents.split('\\n')) +\n                     \"\\n    return clip\", exec_globals)\n\n                presets[preset_name] = exec_globals[f\"preset_{preset_name}\"]\n            except Exception as e:\n                print(f\"Warning: Error creating preset '{preset_name}': {e}\")\n\n    return presets\n</code></pre>"},{"location":"API/source/wobbly/core/presets/#y5gfunc.source.wobbly.core.presets.create_preset_functions(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/core/presets/#y5gfunc.source.wobbly.core.presets.create_preset_functions(keys)","title":"<code>keys</code>","text":""},{"location":"API/source/wobbly/core/source/","title":"<code>y5gfunc.source.wobbly.core.source</code>","text":""},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source","title":"source","text":"<p>WobblySource class implementation.</p> <p>Classes:</p> Name Description <code>WobblySource</code> <p>Wobbly source processing class</p> <p>Functions:</p> Name Description <code>load_and_process</code> <p>Load and process a Wobbly project file</p>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource","title":"WobblySource","text":"<pre><code>WobblySource(wob_project_path: PathLike, timecode_output_path: Optional[PathLike] = None, timecode_version: str = V2)\n</code></pre> <p>Wobbly source processing class</p> <p>Initialize Wobbly source processor</p> <p>Parameters:</p> Name Type Description Default <code>PathLike</code> <p>Path to Wobbly project file</p> required <code>Optional[PathLike]</code> <p>Optional path for timecode output</p> <code>None</code> <code>str</code> <p>Timecode version.</p> <code>V2</code> <p>Methods:</p> Name Description <code>load</code> <p>Load project file</p> <code>create_presets</code> <p>Create preset functions</p> <code>init_properties</code> <p>Initialize frame properties and mapping</p> <code>generate_timecodes</code> <p>Generate timecodes file if requested</p> <code>process</code> <p>Process the Wobbly project</p> <p>Attributes:</p> Name Type Description <code>project_path</code> <code>timecode_path</code> <code>timecode_version</code> <code>keys</code> <code>project</code> <code>Optional[ProjectData]</code> <code>input_file</code> <code>Optional[str]</code> <code>source_filter</code> <code>str</code> <code>frame_props</code> <code>FramePropertyMap</code> <code>frame_mapping</code> <code>FrameMap</code> <code>presets</code> <code>PresetDict</code> Source code in <code>y5gfunc/source/wobbly/core/source.py</code> <pre><code>def __init__(\n    self,\n    wob_project_path: PathLike,\n    timecode_output_path: Optional[PathLike] = None,\n    timecode_version: str = TimecodeVersion.V2\n):\n    \"\"\"\n    Initialize Wobbly source processor\n\n    Args:\n        wob_project_path: Path to Wobbly project file\n        timecode_output_path: Optional path for timecode output\n        timecode_version: Timecode version.\n    \"\"\"\n    self.project_path = resolve_path(wob_project_path)\n    self.timecode_path = resolve_path(timecode_output_path) if timecode_output_path else None\n    self.timecode_version = timecode_version\n    self.keys = WobblyKeys()\n\n    # Initialize state\n    self.project: Optional[ProjectData] = None\n    self.input_file: Optional[str] = None\n    self.source_filter: str = \"\"\n    self.frame_props: FramePropertyMap = {}\n    self.frame_mapping: FrameMap = {}\n    self.presets: PresetDict = {}\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource(wob_project_path)","title":"<code>wob_project_path</code>","text":""},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource(timecode_output_path)","title":"<code>timecode_output_path</code>","text":""},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource(timecode_version)","title":"<code>timecode_version</code>","text":""},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.project_path","title":"project_path  <code>instance-attribute</code>","text":"<pre><code>project_path = resolve_path(wob_project_path)\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.timecode_path","title":"timecode_path  <code>instance-attribute</code>","text":"<pre><code>timecode_path = resolve_path(timecode_output_path) if timecode_output_path else None\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.timecode_version","title":"timecode_version  <code>instance-attribute</code>","text":"<pre><code>timecode_version = timecode_version\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.project","title":"project  <code>instance-attribute</code>","text":"<pre><code>project: Optional[ProjectData] = None\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.input_file","title":"input_file  <code>instance-attribute</code>","text":"<pre><code>input_file: Optional[str] = None\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.source_filter","title":"source_filter  <code>instance-attribute</code>","text":"<pre><code>source_filter: str = ''\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.frame_props","title":"frame_props  <code>instance-attribute</code>","text":"<pre><code>frame_props: FramePropertyMap = {}\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.frame_mapping","title":"frame_mapping  <code>instance-attribute</code>","text":"<pre><code>frame_mapping: FrameMap = {}\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.presets","title":"presets  <code>instance-attribute</code>","text":"<pre><code>presets: PresetDict = {}\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.load","title":"load","text":"<pre><code>load() -&gt; WobblySource\n</code></pre> <p>Load project file</p> <p>Returns:</p> Type Description <code>WobblySource</code> <p>Self instance for method chaining</p> <p>Raises:</p> Type Description <code>WobblyParseError</code> <p>When project file cannot be parsed</p> <code>WobblyInputError</code> <p>When there are issues with input file</p> Source code in <code>y5gfunc/source/wobbly/core/source.py</code> <pre><code>def load(self) -&gt; 'WobblySource':\n    \"\"\"\n    Load project file\n\n    Returns:\n        Self instance for method chaining\n\n    Raises:\n        WobblyParseError: When project file cannot be parsed\n        WobblyInputError: When there are issues with input file\n    \"\"\"\n    # Load project file\n    result = load_project(self.project_path)\n    if not result.success:\n        raise WobblyParseError(result.error or \"Unknown parsing error\")\n\n    self.project = result.value\n    Keys = self.keys\n\n    assert self.project\n\n    # Get input file path\n    self.input_file = self.project.get(Keys.project.input_file)\n    self.source_filter = self.project.get(Keys.project.source_filter, \"\")\n\n    if not self.input_file:\n        raise WobblyInputError(\"No input file specified in the project\")\n\n    # Handle relative paths\n    if not os.path.isabs(self.input_file):\n        wob_dir = os.path.dirname(os.path.abspath(str(self.project_path)))\n        self.input_file = os.path.join(wob_dir, self.input_file)\n\n    return self\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.create_presets","title":"create_presets","text":"<pre><code>create_presets() -&gt; WobblySource\n</code></pre> <p>Create preset functions</p> <p>Returns:</p> Type Description <code>WobblySource</code> <p>Self instance for method chaining</p> Source code in <code>y5gfunc/source/wobbly/core/source.py</code> <pre><code>def create_presets(self) -&gt; 'WobblySource':\n    \"\"\"\n    Create preset functions\n\n    Returns:\n        Self instance for method chaining\n    \"\"\"\n    if not self.project:\n        raise WobblyProcessError(\"Project not loaded\", stage=\"create_presets\")\n\n    self.presets = create_preset_functions(self.project, self.keys)\n    return self\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.init_properties","title":"init_properties","text":"<pre><code>init_properties(src: VideoNode) -&gt; None\n</code></pre> <p>Initialize frame properties and mapping</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Source video clip</p> required Source code in <code>y5gfunc/source/wobbly/core/source.py</code> <pre><code>def init_properties(self, src: vs.VideoNode) -&gt; None:\n    \"\"\"\n    Initialize frame properties and mapping\n\n    Args:\n        src: Source video clip\n    \"\"\"\n    # Initialize basic properties for each frame\n\n    assert self.project\n\n    for n in range(src.num_frames):\n        self.frame_props[n] = {\n            \"WobblyProject\": os.path.basename(str(self.project_path)),\n            \"WobblyVersion\": self.project.get(self.keys.project.wobbly_version, \"\"),\n            \"WobblySourceFilter\": self.source_filter,\n            # Initialize empty values\n            \"WobblyCustomList\": \"\",\n            \"WobblyCustomListPreset\": \"\",\n            \"WobblyCustomListPosition\": \"\",\n            \"WobblySectionStart\": -1,\n            \"WobblySectionEnd\": -1,\n            \"WobblySectionPresets\": \"\",\n            \"WobblyMatch\": \"\"\n        }\n\n    # Prepare data for processing\n    for i in range(src.num_frames):\n        self.frame_mapping[i] = i  # Initially the mapping is identical\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.init_properties(src)","title":"<code>src</code>","text":""},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.generate_timecodes","title":"generate_timecodes","text":"<pre><code>generate_timecodes() -&gt; None\n</code></pre> <p>Generate timecodes file if requested</p> Source code in <code>y5gfunc/source/wobbly/core/source.py</code> <pre><code>def generate_timecodes(self) -&gt; None:\n    \"\"\"\n    Generate timecodes file if requested\n    \"\"\"\n    if not self.timecode_path or not self.project:\n        return\n\n    with safe_processing(\"timecode_generation\"):\n        # Use the timecode generator factory to create the appropriate generator\n        generator = TimecodeGeneratorFactory.create(\n            self.timecode_version, self.project\n        )\n        timecodes = generator.generate()\n\n        with open(str(self.timecode_path), 'w', encoding='utf-8') as f:\n            f.write(timecodes)\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.WobblySource.process","title":"process","text":"<pre><code>process() -&gt; VideoNode\n</code></pre> <p>Process the Wobbly project</p> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Processed video node</p> <p>Raises:</p> Type Description <code>WobblyProcessError</code> <p>When errors occur during processing</p> Source code in <code>y5gfunc/source/wobbly/core/source.py</code> <pre><code>def process(self) -&gt; vs.VideoNode:\n    \"\"\"\n    Process the Wobbly project\n\n    Returns:\n        Processed video node\n\n    Raises:\n        WobblyProcessError: When errors occur during processing\n    \"\"\"\n    if not self.project or not self.input_file:\n        self.load()\n\n    if not self.presets:\n        self.create_presets()\n\n    assert self.input_file\n\n    # Load source video\n    src = load_source_video(self.input_file, self.source_filter)\n\n    # Initialize properties\n    self.init_properties(src)\n\n    # Process video pipeline\n    try:\n        assert self.project\n        # Apply early crop\n        crop_processor = CropProcessor(early=True)\n        src, self.frame_props, self.frame_mapping = crop_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Apply trimming\n        trim_processor = TrimProcessor()\n        src, self.frame_props, self.frame_mapping = trim_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Apply custom lists - PostSource\n        custom_list_processor = CustomListProcessor(ProcessPosition.POST_SOURCE)\n        src, self.frame_props, self.frame_mapping = custom_list_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Process match information\n        src = self._process_match_information(src)\n\n        # Apply custom lists - PostFieldMatch\n        custom_list_processor = CustomListProcessor(ProcessPosition.POST_FIELD_MATCH)\n        src, self.frame_props, self.frame_mapping = custom_list_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Apply sections and record section info\n        section_processor = SectionProcessor()\n        src, self.frame_props, self.frame_mapping = section_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Mark special frames\n        special_frames_processor = SpecialFrameMarkProcessor()\n        src, self.frame_props, self.frame_mapping = special_frames_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Apply frozen frames\n        frozen_frames_processor = FrozenFramesProcessor()\n        src, self.frame_props, self.frame_mapping = frozen_frames_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Apply frame rate conversion (delete frames)\n        decimation_processor = DecimationProcessor()\n        src, self.frame_props, self.frame_mapping = decimation_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Apply custom lists - PostDecimate\n        custom_list_processor = CustomListProcessor(ProcessPosition.POST_DECIMATE)\n        src, self.frame_props, self.frame_mapping = custom_list_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Apply final crop\n        crop_processor = CropProcessor(early=False)\n        src, self.frame_props, self.frame_mapping = crop_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Apply resize and bit depth\n        resize_processor = ResizeProcessor()\n        src, self.frame_props, self.frame_mapping = resize_processor.process(\n            src, self.project, self.frame_props, self.frame_mapping, self.presets\n        )\n\n        # Generate timecodes if requested\n        self.generate_timecodes()\n\n        # Finally: Apply all frame properties\n        src = apply_frame_properties(src, self.frame_props)\n\n    except Exception as e:\n        if isinstance(e, WobblyError):\n            raise\n        else:\n            raise WobblyProcessError(\"Error processing Wobbly project\", \n                                    stage=\"processing\",\n                                    cause=e)\n\n    return src\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.load_and_process","title":"load_and_process","text":"<pre><code>load_and_process(wob_project_path: PathLike, timecode_output_path: Optional[PathLike] = None, timecode_version: str = V2) -&gt; VideoNode\n</code></pre> <p>Load and process a Wobbly project file</p> <p>Parameters:</p> Name Type Description Default <code>PathLike</code> <p>Path to Wobbly project file</p> required <code>Optional[PathLike]</code> <p>Optional path for timecode output</p> <code>None</code> <code>str</code> <p>Timecode version.</p> <code>V2</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>Processed video node</p> Source code in <code>y5gfunc/source/wobbly/core/source.py</code> <pre><code>def load_and_process(\n    wob_project_path: PathLike,\n    timecode_output_path: Optional[PathLike] = None,\n    timecode_version: str = TimecodeVersion.V2\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Load and process a Wobbly project file\n\n    Args:\n        wob_project_path: Path to Wobbly project file\n        timecode_output_path: Optional path for timecode output\n        timecode_version: Timecode version.\n\n    Returns:\n        Processed video node\n    \"\"\"\n    source = WobblySource(wob_project_path, timecode_output_path, timecode_version)\n    return source.process()\n</code></pre>"},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.load_and_process(wob_project_path)","title":"<code>wob_project_path</code>","text":""},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.load_and_process(timecode_output_path)","title":"<code>timecode_output_path</code>","text":""},{"location":"API/source/wobbly/core/source/#y5gfunc.source.wobbly.core.source.load_and_process(timecode_version)","title":"<code>timecode_version</code>","text":""},{"location":"API/source/wobbly/io/json/","title":"<code>y5gfunc.source.wobbly.io.json</code>","text":""},{"location":"API/source/wobbly/io/json/#y5gfunc.source.wobbly.io.json","title":"json","text":"<p>JSON handling with orjson optimization.</p> <p>Functions:</p> Name Description <code>load_json</code> <p>Load JSON file with standard json</p> <code>dump_json</code> <p>Dump data to JSON string with standard json</p> <code>load_project</code> <p>Load and parse a Wobbly project file</p>"},{"location":"API/source/wobbly/io/json/#y5gfunc.source.wobbly.io.json.load_json","title":"load_json","text":"<pre><code>load_json(file_path: Union[str, Path]) -&gt; Dict[str, Any]\n</code></pre> <p>Load JSON file with standard json</p> <p>Parameters:</p> Name Type Description Default <code>Union[str, Path]</code> <p>Path to JSON file</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Parsed JSON data</p> Source code in <code>y5gfunc/source/wobbly/io/json.py</code> <pre><code>def load_json(file_path: Union[str, Path]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Load JSON file with standard json\n\n    Args:\n        file_path: Path to JSON file\n\n    Returns:\n        Parsed JSON data\n    \"\"\"\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return json.load(f)\n</code></pre>"},{"location":"API/source/wobbly/io/json/#y5gfunc.source.wobbly.io.json.load_json(file_path)","title":"<code>file_path</code>","text":""},{"location":"API/source/wobbly/io/json/#y5gfunc.source.wobbly.io.json.dump_json","title":"dump_json","text":"<pre><code>dump_json(data: Dict[str, Any], indent: bool = False) -&gt; str\n</code></pre> <p>Dump data to JSON string with standard json</p> <p>Parameters:</p> Name Type Description Default <code>Dict[str, Any]</code> <p>Data to serialize</p> required <code>bool</code> <p>Whether to indent the output</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>JSON string</p> Source code in <code>y5gfunc/source/wobbly/io/json.py</code> <pre><code>def dump_json(data: Dict[str, Any], indent: bool = False) -&gt; str:\n    \"\"\"\n    Dump data to JSON string with standard json\n\n    Args:\n        data: Data to serialize\n        indent: Whether to indent the output\n\n    Returns:\n        JSON string\n    \"\"\"\n    indent_val = 2 if indent else None\n    return json.dumps(data, indent=indent_val)\n</code></pre>"},{"location":"API/source/wobbly/io/json/#y5gfunc.source.wobbly.io.json.dump_json(data)","title":"<code>data</code>","text":""},{"location":"API/source/wobbly/io/json/#y5gfunc.source.wobbly.io.json.dump_json(indent)","title":"<code>indent</code>","text":""},{"location":"API/source/wobbly/io/json/#y5gfunc.source.wobbly.io.json.load_project","title":"load_project","text":"<pre><code>load_project(project_path: PathLike) -&gt; Result[ProjectData]\n</code></pre> <p>Load and parse a Wobbly project file</p> <p>Parameters:</p> Name Type Description Default <code>PathLike</code> <p>Path to Wobbly project file</p> required <p>Returns:</p> Type Description <code>Result[ProjectData]</code> <p>Result containing project data if successful</p> Source code in <code>y5gfunc/source/wobbly/io/json.py</code> <pre><code>def load_project(project_path: PathLike) -&gt; Result[ProjectData]:\n    \"\"\"\n    Load and parse a Wobbly project file\n\n    Args:\n        project_path: Path to Wobbly project file\n\n    Returns:\n        Result containing project data if successful\n    \"\"\"\n    try:\n        project = load_json(project_path)\n        return Result.ok(project)\n    except Exception as e:\n        return Result.err(f\"Failed to read or parse Wobbly project file: {e}\")\n</code></pre>"},{"location":"API/source/wobbly/io/json/#y5gfunc.source.wobbly.io.json.load_project(project_path)","title":"<code>project_path</code>","text":""},{"location":"API/source/wobbly/io/video/","title":"<code>y5gfunc.source.wobbly.io.video</code>","text":""},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video","title":"video","text":"<p>Video loading and source handling.</p> <p>Functions:</p> Name Description <code>load_source_video</code> <p>Load source video based on specified filter</p> <code>query_format</code> <p>Query video format ID</p> <code>apply_frame_properties</code> <p>Apply frame properties to video frames</p> <p>Attributes:</p> Name Type Description <code>core</code>"},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.core","title":"core  <code>module-attribute</code>","text":"<pre><code>core = core\n</code></pre>"},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.load_source_video","title":"load_source_video","text":"<pre><code>load_source_video(input_file: str, source_filter: str) -&gt; VideoNode\n</code></pre> <p>Load source video based on specified filter</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Path to input video file</p> required <code>str</code> <p>Source filter to use (plugin.function)</p> required <p>Returns:</p> Type Description <code>VideoNode</code> <p>Loaded video node</p> <p>Raises:</p> Type Description <code>WobblyInputError</code> <p>If the input file doesn't exist</p> <code>WobblyProcessError</code> <p>If loading fails</p> Source code in <code>y5gfunc/source/wobbly/io/video.py</code> <pre><code>def load_source_video(input_file: str, source_filter: str) -&gt; vs.VideoNode:\n    \"\"\"\n    Load source video based on specified filter\n\n    Args:\n        input_file: Path to input video file\n        source_filter: Source filter to use (plugin.function)\n\n    Returns:\n        Loaded video node\n\n    Raises:\n        WobblyInputError: If the input file doesn't exist\n        WobblyProcessError: If loading fails\n    \"\"\"\n    if not os.path.exists(input_file):\n        raise WobblyInputError(f\"Input file does not exist: {input_file}\")\n\n    try:\n        if source_filter == \"bs.VideoSource\":\n            # BestSource loading\n            return core.bs.VideoSource(input_file, rff=True, showprogress=False)\n        else:\n            # Use specified filter\n            filter_parts = source_filter.split('.')\n            if len(filter_parts) &lt; 2:\n                raise WobblyInputError(f\"Invalid source filter: {source_filter}, expected format: plugin.function\")\n\n            plugin = getattr(core, filter_parts[0])\n            return getattr(plugin, filter_parts[1])(input_file)\n    except Exception as e:\n        raise WobblyProcessError(f\"Failed to load video: {e}\", stage=\"video_loading\", cause=e)\n</code></pre>"},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.load_source_video(input_file)","title":"<code>input_file</code>","text":""},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.load_source_video(source_filter)","title":"<code>source_filter</code>","text":""},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.query_format","title":"query_format","text":"<pre><code>query_format(clip: VideoNode, bits: int, sample_type: VideoFormat, subsampling_w: Optional[int] = None, subsampling_h: Optional[int] = None) -&gt; int\n</code></pre> <p>Query video format ID</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Reference clip</p> required <code>int</code> <p>Bit depth</p> required <code>VideoFormat</code> <p>Sample type (FLOAT or INTEGER)</p> required <code>Optional[int]</code> <p>Horizontal subsampling, or None to use reference clip's value</p> <code>None</code> <code>Optional[int]</code> <p>Vertical subsampling, or None to use reference clip's value</p> <code>None</code> <p>Returns:</p> Type Description <code>int</code> <p>Format ID</p> Source code in <code>y5gfunc/source/wobbly/io/video.py</code> <pre><code>def query_format(\n    clip: vs.VideoNode, \n    bits: int, \n    sample_type: VideoFormat,\n    subsampling_w: Optional[int] = None,\n    subsampling_h: Optional[int] = None\n) -&gt; int:\n    \"\"\"\n    Query video format ID\n\n    Args:\n        clip: Reference clip\n        bits: Bit depth\n        sample_type: Sample type (FLOAT or INTEGER)\n        subsampling_w: Horizontal subsampling, or None to use reference clip's value\n        subsampling_h: Vertical subsampling, or None to use reference clip's value\n\n    Returns:\n        Format ID\n    \"\"\"\n    if subsampling_w is None:\n        subsampling_w = clip.format.subsampling_w\n\n    if subsampling_h is None:\n        subsampling_h = clip.format.subsampling_h\n\n    return core.query_video_format(\n        clip.format.color_family,\n        sample_type.value,\n        bits,\n        subsampling_w,\n        subsampling_h\n    ).id\n</code></pre>"},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.query_format(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.query_format(bits)","title":"<code>bits</code>","text":""},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.query_format(sample_type)","title":"<code>sample_type</code>","text":""},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.query_format(subsampling_w)","title":"<code>subsampling_w</code>","text":""},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.query_format(subsampling_h)","title":"<code>subsampling_h</code>","text":""},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.apply_frame_properties","title":"apply_frame_properties","text":"<pre><code>apply_frame_properties(clip: VideoNode, frame_props: FramePropertyMap) -&gt; VideoNode\n</code></pre> <p>Apply frame properties to video frames</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input clip</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <p>Returns:</p> Type Description <code>VideoNode</code> <p>Clip with applied frame properties</p> Source code in <code>y5gfunc/source/wobbly/io/video.py</code> <pre><code>def apply_frame_properties(clip: vs.VideoNode, frame_props: FramePropertyMap) -&gt; vs.VideoNode:\n    \"\"\"\n    Apply frame properties to video frames\n\n    Args:\n        clip: Input clip\n        frame_props: Frame property mapping\n\n    Returns:\n        Clip with applied frame properties\n    \"\"\"\n    def transfer_props(n: int, f: vs.VideoFrame) -&gt; vs.VideoFrame:\n        if n in frame_props:\n            fout = f.copy()\n\n            # Add all properties\n            for key, value in frame_props[n].items():\n                if value is not None:  # Skip None values\n                    # VapourSynth doesn't accept None as frame property value\n                    fout.props[key] = value # type: ignore\n\n            return fout\n        return f\n\n    # Apply all saved frame properties\n    return core.std.ModifyFrame(clip, clip, transfer_props)\n</code></pre>"},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.apply_frame_properties(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/io/video/#y5gfunc.source.wobbly.io.video.apply_frame_properties(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/base/","title":"<code>y5gfunc.source.wobbly.processors.base</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base","title":"base","text":"<p>Processor base classes and protocol definitions.</p> <p>Classes:</p> Name Description <code>ProcessorProtocol</code> <p>Processor interface protocol</p> <code>BaseProcessor</code> <p>Base processor class</p> <code>ProcessorResult</code> <p>Processor result data class</p>"},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorProtocol","title":"ProcessorProtocol","text":"<p>               Bases: <code>Protocol</code></p> <p>Processor interface protocol</p> <p>Methods:</p> Name Description <code>process</code> <p>Process a video clip</p>"},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorProtocol.process","title":"process","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Process a video clip</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/base.py</code> <pre><code>def process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Process a video clip\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    ...\n</code></pre>"},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorProtocol.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorProtocol.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorProtocol.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorProtocol.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorProtocol.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.BaseProcessor","title":"BaseProcessor","text":"<p>               Bases: <code>ABC</code></p> <p>Base processor class</p> <p>Methods:</p> Name Description <code>process</code> <p>Abstract method for processing a video clip</p>"},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.BaseProcessor.process","title":"process  <code>abstractmethod</code>","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Abstract method for processing a video clip</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/base.py</code> <pre><code>@abstractmethod\ndef process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Abstract method for processing a video clip\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    pass\n</code></pre>"},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.BaseProcessor.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.BaseProcessor.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.BaseProcessor.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.BaseProcessor.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.BaseProcessor.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorResult","title":"ProcessorResult  <code>dataclass</code>","text":"<pre><code>ProcessorResult(clip: VideoNode, frame_props: FramePropertyMap, frame_mapping: FrameMap)\n</code></pre> <p>Processor result data class</p> <p>Attributes:</p> Name Type Description <code>clip</code> <code>VideoNode</code> <code>frame_props</code> <code>FramePropertyMap</code> <code>frame_mapping</code> <code>FrameMap</code>"},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorResult.clip","title":"clip  <code>instance-attribute</code>","text":"<pre><code>clip: VideoNode\n</code></pre>"},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorResult.frame_props","title":"frame_props  <code>instance-attribute</code>","text":"<pre><code>frame_props: FramePropertyMap\n</code></pre>"},{"location":"API/source/wobbly/processors/base/#y5gfunc.source.wobbly.processors.base.ProcessorResult.frame_mapping","title":"frame_mapping  <code>instance-attribute</code>","text":"<pre><code>frame_mapping: FrameMap\n</code></pre>"},{"location":"API/source/wobbly/processors/crop/","title":"<code>y5gfunc.source.wobbly.processors.crop</code>","text":""},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop","title":"crop","text":"<p>Crop processor implementation.</p> <p>Classes:</p> Name Description <code>CropProcessor</code> <p>Crop processor implementation</p> <p>Attributes:</p> Name Type Description <code>core</code>"},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.core","title":"core  <code>module-attribute</code>","text":"<pre><code>core = core\n</code></pre>"},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor","title":"CropProcessor","text":"<pre><code>CropProcessor(early: bool = True)\n</code></pre> <p>               Bases: <code>BaseProcessor</code></p> <p>Crop processor implementation</p> <p>Initialize crop processor</p> <p>Parameters:</p> Name Type Description Default <code>bool</code> <p>Whether this is early crop (True) or final crop (False)</p> <code>True</code> <p>Methods:</p> Name Description <code>process</code> <p>Process crop operation</p> <p>Attributes:</p> Name Type Description <code>early</code> <code>keys</code> Source code in <code>y5gfunc/source/wobbly/processors/crop.py</code> <pre><code>def __init__(self, early: bool = True):\n    \"\"\"\n    Initialize crop processor\n\n    Args:\n        early: Whether this is early crop (True) or final crop (False)\n    \"\"\"\n    self.early = early\n    self.keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor(early)","title":"<code>early</code>","text":""},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor.early","title":"early  <code>instance-attribute</code>","text":"<pre><code>early = early\n</code></pre>"},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor.process","title":"process","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Process crop operation</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/crop.py</code> <pre><code>def process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Process crop operation\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    stage_name = \"early_crop\" if self.early else \"final_crop\"\n\n    with safe_processing(stage_name):\n        Keys = self.keys\n        crop_info = project.get(Keys.project.crop, {})\n\n        # Check if crop is enabled and matches the requested phase (early or final)\n        crop_enabled = crop_info.get(Keys.crop.enabled, False)\n        crop_is_early = crop_info.get(Keys.crop.early, False)\n\n        if crop_enabled and crop_is_early == self.early:\n            # Get crop values\n            left = crop_info.get(Keys.crop.left, 0)\n            top = crop_info.get(Keys.crop.top, 0) \n            right = crop_info.get(Keys.crop.right, 0)\n            bottom = crop_info.get(Keys.crop.bottom, 0)\n\n            # Create properties to record\n            crop_props = {\n                \"WobblyCropEarly\": self.early,\n                \"WobblyCropLeft\": left,\n                \"WobblyCropTop\": top,\n                \"WobblyCropRight\": right,\n                \"WobblyCropBottom\": bottom\n            }\n\n            # Update all frame properties\n            for n in frame_props:\n                frame_props[n].update(crop_props) # type: ignore\n\n            # Apply crop\n            clip = core.std.CropRel(\n                clip=clip,\n                left=left,\n                top=top,\n                right=right,\n                bottom=bottom\n            )\n\n    return clip, frame_props, frame_mapping\n</code></pre>"},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/crop/#y5gfunc.source.wobbly.processors.crop.CropProcessor.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/processors/custom_lists/","title":"<code>y5gfunc.source.wobbly.processors.custom_lists</code>","text":""},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists","title":"custom_lists","text":"<p>Custom list processor implementation.</p> <p>Classes:</p> Name Description <code>CustomListProcessor</code> <p>Custom list processor implementation</p>"},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor","title":"CustomListProcessor","text":"<pre><code>CustomListProcessor(position: ProcessPosition)\n</code></pre> <p>               Bases: <code>BaseProcessor</code></p> <p>Custom list processor implementation</p> <p>Initialize custom list processor</p> <p>Parameters:</p> Name Type Description Default <code>ProcessPosition</code> <p>Processing position</p> required <p>Methods:</p> Name Description <code>process</code> <p>Process custom lists</p> <p>Attributes:</p> Name Type Description <code>position</code> <code>keys</code> Source code in <code>y5gfunc/source/wobbly/processors/custom_lists.py</code> <pre><code>def __init__(self, position: ProcessPosition):\n    \"\"\"\n    Initialize custom list processor\n\n    Args:\n        position: Processing position\n    \"\"\"\n    self.position = position\n    self.keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor(position)","title":"<code>position</code>","text":""},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor.position","title":"position  <code>instance-attribute</code>","text":"<pre><code>position = position\n</code></pre>"},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor.process","title":"process","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Process custom lists</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/custom_lists.py</code> <pre><code>def process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Process custom lists\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    core = vs.core\n    Keys = self.keys\n\n    try:\n        # Filter custom lists for the specified position\n        custom_lists = [cl for cl in project.get(Keys.project.custom_lists, []) \n                        if cl.get(Keys.custom_lists.position) == self.position.value]\n\n        if not custom_lists:\n            return clip, frame_props, frame_mapping\n\n        all_ranges: CustomListRanges = []  # all covered ranges\n\n        for cl_info in custom_lists:\n            cl_name = cl_info.get(Keys.custom_lists.name)\n            cl_preset = cl_info.get(Keys.custom_lists.preset)\n            cl_frames = cl_info.get(Keys.custom_lists.frames, [])\n\n            # Check if we have preset and frame ranges\n            if not cl_preset or not cl_frames:\n                continue\n\n            # Check if preset exists\n            if cl_preset not in presets:\n                continue\n\n            # Ensure cl_frames is a list of lists\n            ranges: List[Tuple[int, int]] = []\n            for frame_range in cl_frames:\n                if isinstance(frame_range, list) and len(frame_range) == 2:\n                    start, end = frame_range\n\n                    # Record all qualifying frames, and update frame properties\n                    self._update_frame_properties(\n                        frame_props, frame_mapping, start, end, cl_name, cl_preset\n                    )\n\n                    ranges.append((start, end))\n                    all_ranges.append((start, end, cl_name, cl_preset))\n\n            # Sort the ranges\n            ranges.sort()\n\n            # Apply preset to clip\n            if ranges:\n                # Create marked segments\n                marked_clips = []\n                last_end = 0\n\n                for range_start, range_end in ranges:\n                    # Ensure valid range\n                    if not (0 &lt;= range_start &lt;= range_end &lt; clip.num_frames):\n                        continue\n\n                    if range_start &gt; last_end:\n                        marked_clips.append(clip[last_end:range_start])\n\n                    # Apply preset to current range\n                    list_clip = presets[cl_preset](clip[range_start:range_end+1])\n                    marked_clips.append(list_clip)\n\n                    last_end = range_end + 1\n\n                if last_end &lt; clip.num_frames:\n                    marked_clips.append(clip[last_end:])\n\n                if marked_clips:\n                    clip = core.std.Splice(clips=marked_clips, mismatch=True)\n\n        return clip, frame_props, frame_mapping\n\n    except Exception as e:\n        raise WobblyProcessError(\n            f\"Error applying custom lists at position {self.position.value}\",\n            stage=\"custom_list_processing\", \n            details={\"position\": self.position.value},\n            cause=e\n        )\n</code></pre>"},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/custom_lists/#y5gfunc.source.wobbly.processors.custom_lists.CustomListProcessor.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/processors/resize/","title":"<code>y5gfunc.source.wobbly.processors.resize</code>","text":""},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize","title":"resize","text":"<p>Resize and bit depth processor.</p> <p>Classes:</p> Name Description <code>ResizeProcessor</code> <p>Resize and bit depth processor implementation</p> <p>Attributes:</p> Name Type Description <code>core</code>"},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize.core","title":"core  <code>module-attribute</code>","text":"<pre><code>core = core\n</code></pre>"},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize.ResizeProcessor","title":"ResizeProcessor","text":"<pre><code>ResizeProcessor()\n</code></pre> <p>               Bases: <code>BaseProcessor</code></p> <p>Resize and bit depth processor implementation</p> <p>Initialize resize processor</p> <p>Methods:</p> Name Description <code>process</code> <p>Process resize and bit depth operations</p> <p>Attributes:</p> Name Type Description <code>keys</code> Source code in <code>y5gfunc/source/wobbly/processors/resize.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize resize processor\"\"\"\n    self.keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize.ResizeProcessor.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize.ResizeProcessor.process","title":"process","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Process resize and bit depth operations</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/resize.py</code> <pre><code>def process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Process resize and bit depth operations\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    with safe_processing(\"resize_and_depth_processing\"):\n        Keys = self.keys\n        resize_info = project.get(Keys.project.resize, {})\n        depth_info = project.get(Keys.project.depth, {})\n\n        resize_enabled = resize_info.get(Keys.resize.enabled, False)\n        depth_enabled = depth_info.get(Keys.depth.enabled, False)\n\n        if not (resize_enabled or depth_enabled):\n            return clip, frame_props, frame_mapping\n\n        # Record resize and bit depth info\n        resize_props: Dict[str, Any] = {}\n\n        # Get filter name\n        resize_filter_name = resize_info.get(Keys.resize.filter, \"Bicubic\")\n        if resize_filter_name:\n            resize_filter_name = resize_filter_name[0].upper() + resize_filter_name[1:]\n        else:\n            resize_filter_name = \"Bicubic\"\n\n        if not hasattr(core.resize, resize_filter_name):\n            resize_filter_name = \"Bicubic\"\n\n        # Prepare resize arguments\n        resize_args: Dict[str, Any] = {}\n        if resize_enabled:\n            resize_width = resize_info.get(Keys.resize.width, clip.width)\n            resize_height = resize_info.get(Keys.resize.height, clip.height)\n            resize_args[\"width\"] = resize_width\n            resize_args[\"height\"] = resize_height\n\n            resize_props.update({\n                \"WobblyResizeEnabled\": True,\n                \"WobblyResizeWidth\": resize_width,\n                \"WobblyResizeHeight\": resize_height,\n                \"WobblyResizeFilter\": resize_filter_name\n            })\n\n        # Add bit depth arguments if needed\n        if depth_enabled:\n            bits = depth_info.get(Keys.depth.bits, 8)\n            float_samples = depth_info.get(Keys.depth.float_samples, False)\n            dither = depth_info.get(Keys.depth.dither, \"\")\n            sample_type = VideoFormat.FLOAT if float_samples else VideoFormat.INTEGER\n\n            format_id = query_format(\n                clip,\n                bits,\n                sample_type\n            )\n\n            resize_args[\"format\"] = format_id\n\n            resize_props.update({\n                \"WobblyDepthEnabled\": True,\n                \"WobblyDepthBits\": bits,\n                \"WobblyDepthFloat\": float_samples,\n                \"WobblyDepthDither\": dither\n            })\n\n        # Update all frame properties\n        for n in frame_props:\n            frame_props[n].update(resize_props) # type: ignore\n\n        # Apply resize\n        resize_filter = getattr(core.resize, resize_filter_name)\n        clip = resize_filter(clip=clip, **resize_args)\n\n    return clip, frame_props, frame_mapping\n</code></pre>"},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize.ResizeProcessor.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize.ResizeProcessor.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize.ResizeProcessor.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize.ResizeProcessor.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/resize/#y5gfunc.source.wobbly.processors.resize.ResizeProcessor.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/processors/sections/","title":"<code>y5gfunc.source.wobbly.processors.sections</code>","text":""},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections","title":"sections","text":"<p>Section processor implementation.</p> <p>Classes:</p> Name Description <code>SectionProcessor</code> <p>Section processor implementation</p> <p>Attributes:</p> Name Type Description <code>core</code>"},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections.core","title":"core  <code>module-attribute</code>","text":"<pre><code>core = core\n</code></pre>"},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections.SectionProcessor","title":"SectionProcessor","text":"<pre><code>SectionProcessor()\n</code></pre> <p>               Bases: <code>BaseProcessor</code></p> <p>Section processor implementation</p> <p>Initialize section processor</p> <p>Methods:</p> Name Description <code>process</code> <p>Process sections</p> <p>Attributes:</p> Name Type Description <code>keys</code> Source code in <code>y5gfunc/source/wobbly/processors/sections.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize section processor\"\"\"\n    self.keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections.SectionProcessor.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections.SectionProcessor.process","title":"process","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Process sections</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/sections.py</code> <pre><code>def process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Process sections\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    with safe_processing(\"sections_processing\"):\n        Keys = self.keys\n        sections_list = project.get(Keys.project.sections, [])\n\n        if not sections_list:\n            return clip, frame_props, frame_mapping\n\n        # Sort sections by start frame\n        sorted_sections = sorted(sections_list, key=lambda s: s.get(Keys.sections.start, 0))\n\n        # Mark each frame with its section\n        self._mark_section_frames(clip, sorted_sections, frame_props, frame_mapping, Keys)\n\n        # Apply presets and splice\n        sections = []\n        new_frame_props: Dict[int, Dict[str, Any]] = {}\n        new_frame_idx = 0\n\n        for i, section_info in enumerate(sorted_sections):\n            start = section_info.get(Keys.sections.start, 0)\n            next_start = (sorted_sections[i+1].get(Keys.sections.start, clip.num_frames) \n                         if i+1 &lt; len(sorted_sections) else clip.num_frames)\n\n            # Apply presets\n            section_clip = clip[start:next_start]\n            for preset_name in section_info.get(Keys.sections.presets, []):\n                if preset_name in presets:\n                    section_clip = presets[preset_name](section_clip)\n\n            # Update frame mapping and properties\n            for j in range(section_clip.num_frames):\n                src_idx = start + j\n                if src_idx &lt; len(frame_mapping):\n                    orig_frame = frame_mapping[src_idx]\n                    # Copy original frame properties\n                    if src_idx in frame_props:\n                        new_frame_props[new_frame_idx] = frame_props[src_idx].copy() # type: ignore\n                        # Update mapping\n                        frame_mapping[new_frame_idx] = orig_frame\n                        new_frame_idx += 1\n\n            sections.append(section_clip)\n\n        # Merge all sections\n        if sections:\n            clip = core.std.Splice(clips=sections, mismatch=True)\n            frame_props = new_frame_props  # type: ignore # Update frame properties\n\n    return clip, frame_props, frame_mapping\n</code></pre>"},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections.SectionProcessor.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections.SectionProcessor.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections.SectionProcessor.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections.SectionProcessor.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/sections/#y5gfunc.source.wobbly.processors.sections.SectionProcessor.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/","title":"<code>y5gfunc.source.wobbly.processors.special_frames</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames","title":"special_frames","text":"<p>Special frames processing (frozen frames, decimation).</p> <p>Classes:</p> Name Description <code>FrozenFramesProcessor</code> <p>Frozen frames processor implementation</p> <code>DecimationProcessor</code> <p>Decimation processor implementation</p> <code>SpecialFrameMarkProcessor</code> <p>Mark special frames processor implementation</p> <p>Attributes:</p> Name Type Description <code>core</code>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.core","title":"core  <code>module-attribute</code>","text":"<pre><code>core = core\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.FrozenFramesProcessor","title":"FrozenFramesProcessor","text":"<pre><code>FrozenFramesProcessor()\n</code></pre> <p>               Bases: <code>BaseProcessor</code></p> <p>Frozen frames processor implementation</p> <p>Initialize frozen frames processor</p> <p>Methods:</p> Name Description <code>process</code> <p>Process frozen frames</p> <p>Attributes:</p> Name Type Description <code>keys</code> Source code in <code>y5gfunc/source/wobbly/processors/special_frames.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize frozen frames processor\"\"\"\n    self.keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.FrozenFramesProcessor.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.FrozenFramesProcessor.process","title":"process","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Process frozen frames</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/special_frames.py</code> <pre><code>def process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Process frozen frames\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    with safe_processing(\"frozen_frames_processing\"):\n        Keys = self.keys\n        frozen_frames_list = project.get(Keys.project.frozen_frames, [])\n\n        if not (frozen_frames_list and hasattr(core.std, 'FreezeFrames')):\n            return clip, frame_props, frame_mapping\n\n        # Gather frame lists\n        first_frames = []\n        last_frames = []\n        replacement_frames = []\n\n        for ff_info in frozen_frames_list:\n            if len(ff_info) == 3:\n                first, last, replacement = ff_info\n                if 0 &lt;= first &lt;= last &lt; clip.num_frames and 0 &lt;= replacement &lt; clip.num_frames:\n                    first_frames.append(first)\n                    last_frames.append(last)\n                    replacement_frames.append(replacement)\n\n                    # Record frozen frame info\n                    for i in range(first, last+1):\n                        if i in frame_props:\n                            frame_props[i][\"WobblyFrozenFrame\"] = True\n                            frame_props[i][\"WobblyFrozenSource\"] = replacement\n\n        if first_frames:\n            clip = core.std.FreezeFrames(\n                clip=clip,\n                first=first_frames,\n                last=last_frames,\n                replacement=replacement_frames\n            )\n\n    return clip, frame_props, frame_mapping\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.FrozenFramesProcessor.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.FrozenFramesProcessor.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.FrozenFramesProcessor.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.FrozenFramesProcessor.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.FrozenFramesProcessor.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.DecimationProcessor","title":"DecimationProcessor","text":"<pre><code>DecimationProcessor()\n</code></pre> <p>               Bases: <code>BaseProcessor</code></p> <p>Decimation processor implementation</p> <p>Initialize decimation processor</p> <p>Methods:</p> Name Description <code>process</code> <p>Process frame decimation</p> <p>Attributes:</p> Name Type Description <code>keys</code> Source code in <code>y5gfunc/source/wobbly/processors/special_frames.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize decimation processor\"\"\"\n    self.keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.DecimationProcessor.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.DecimationProcessor.process","title":"process","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Process frame decimation</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/special_frames.py</code> <pre><code>def process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Process frame decimation\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    with safe_processing(\"decimation_processing\"):\n        Keys = self.keys\n        decimated_frames_list = project.get(Keys.project.decimated_frames, [])\n\n        if not decimated_frames_list:\n            return clip, frame_props, frame_mapping\n\n        # Filter valid frames\n        frames_to_delete = [f for f in decimated_frames_list if 0 &lt;= f &lt; clip.num_frames]\n\n        if not frames_to_delete:\n            return clip, frame_props, frame_mapping\n\n        # Create new frame property map\n        new_frame_props: Dict[int, Dict[str, Any]] = {}\n        new_idx = 0\n\n        for n in range(clip.num_frames):\n            orig_frame = frame_mapping.get(n, n)\n\n            # If not a frame to delete\n            if orig_frame not in frames_to_delete:\n                if n in frame_props:\n                    new_frame_props[new_idx] = frame_props[n].copy() # type: ignore\n                    new_idx += 1\n\n        # Delete frames\n        clip = core.std.DeleteFrames(clip=clip, frames=frames_to_delete)\n        frame_props = new_frame_props  # type: ignore # Update frame properties\n\n    return clip, frame_props, frame_mapping\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.DecimationProcessor.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.DecimationProcessor.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.DecimationProcessor.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.DecimationProcessor.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.DecimationProcessor.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.SpecialFrameMarkProcessor","title":"SpecialFrameMarkProcessor","text":"<pre><code>SpecialFrameMarkProcessor()\n</code></pre> <p>               Bases: <code>BaseProcessor</code></p> <p>Mark special frames processor implementation</p> <p>Initialize special frame marker</p> <p>Methods:</p> Name Description <code>process</code> <p>Mark special frames</p> <p>Attributes:</p> Name Type Description <code>keys</code> Source code in <code>y5gfunc/source/wobbly/processors/special_frames.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize special frame marker\"\"\"\n    self.keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.SpecialFrameMarkProcessor.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.SpecialFrameMarkProcessor.process","title":"process","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Mark special frames</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/special_frames.py</code> <pre><code>def process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Mark special frames\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    with safe_processing(\"special_frames_processing\"):\n        Keys = self.keys\n        combed_frames = set(project.get(Keys.project.combed_frames, []))\n        decimated_frames = set(project.get(Keys.project.decimated_frames, []))\n        matches = self._get_matches_string(project, Keys)\n        sections_list = project.get(Keys.project.sections, [])\n\n        # Process Interlaced Fades\n        interlaced_fades = project.get(Keys.project.interlaced_fades, [])\n        fade_dict = self._process_interlaced_fades(interlaced_fades, Keys)\n\n        # Identify orphan fields\n        orphan_fields = self._identify_orphan_fields(matches, sections_list, decimated_frames, \n                                                    clip.num_frames, Keys)\n\n        # Update special frame properties\n        for n in frame_props:\n            orig_frame = frame_mapping[n]\n            props = frame_props[n]\n\n            # Mark combed frames\n            if orig_frame in combed_frames:\n                props[\"WobblyCombed\"] = True\n\n            # Mark interlaced fades\n            if orig_frame in fade_dict:\n                props[\"WobblyInterlacedFade\"] = True\n                props[\"WobblyFieldDifference\"] = fade_dict[orig_frame]\n\n            # Mark orphan fields\n            if orig_frame in orphan_fields:\n                info = orphan_fields[orig_frame]\n                props[\"WobblyOrphan\"] = True\n                props[\"WobblyOrphanType\"] = info['type']\n                props[\"WobblyOrphanDecimated\"] = info['decimated']\n\n            # Mark decimated frames\n            if orig_frame in decimated_frames:\n                props[\"WobblyDecimated\"] = True\n\n    return clip, frame_props, frame_mapping\n</code></pre>"},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.SpecialFrameMarkProcessor.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.SpecialFrameMarkProcessor.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.SpecialFrameMarkProcessor.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.SpecialFrameMarkProcessor.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/special_frames/#y5gfunc.source.wobbly.processors.special_frames.SpecialFrameMarkProcessor.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/processors/trim/","title":"<code>y5gfunc.source.wobbly.processors.trim</code>","text":""},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim","title":"trim","text":"<p>Trim processor implementation.</p> <p>Classes:</p> Name Description <code>TrimProcessor</code> <p>Trim processor implementation</p> <p>Attributes:</p> Name Type Description <code>core</code>"},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim.core","title":"core  <code>module-attribute</code>","text":"<pre><code>core = core\n</code></pre>"},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim.TrimProcessor","title":"TrimProcessor","text":"<pre><code>TrimProcessor()\n</code></pre> <p>               Bases: <code>BaseProcessor</code></p> <p>Trim processor implementation</p> <p>Initialize trim processor</p> <p>Methods:</p> Name Description <code>process</code> <p>Process trim operation</p> <p>Attributes:</p> Name Type Description <code>keys</code> Source code in <code>y5gfunc/source/wobbly/processors/trim.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize trim processor\"\"\"\n    self.keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim.TrimProcessor.keys","title":"keys  <code>instance-attribute</code>","text":"<pre><code>keys = WobblyKeys()\n</code></pre>"},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim.TrimProcessor.process","title":"process","text":"<pre><code>process(clip: VideoNode, project: ProjectData, frame_props: FramePropertyMap, frame_mapping: FrameMap, presets: PresetDict) -&gt; Tuple[VideoNode, FramePropertyMap, FrameMap]\n</code></pre> <p>Process trim operation</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>Input video clip</p> required <code>ProjectData</code> <p>Project data</p> required <code>FramePropertyMap</code> <p>Frame property mapping</p> required <code>FrameMap</code> <p>Frame number mapping</p> required <code>PresetDict</code> <p>Preset function dictionary</p> required <p>Returns:</p> Type Description <code>Tuple[VideoNode, FramePropertyMap, FrameMap]</code> <p>Processed clip, updated frame properties and frame mapping</p> Source code in <code>y5gfunc/source/wobbly/processors/trim.py</code> <pre><code>def process(\n    self, \n    clip: vs.VideoNode, \n    project: ProjectData,\n    frame_props: FramePropertyMap,\n    frame_mapping: FrameMap,\n    presets: PresetDict\n) -&gt; Tuple[vs.VideoNode, FramePropertyMap, FrameMap]:\n    \"\"\"\n    Process trim operation\n\n    Args:\n        clip: Input video clip\n        project: Project data\n        frame_props: Frame property mapping\n        frame_mapping: Frame number mapping\n        presets: Preset function dictionary\n\n    Returns:\n        Processed clip, updated frame properties and frame mapping\n    \"\"\"\n    with safe_processing(\"trim_processing\"):\n        Keys = self.keys\n        trim_list = project.get(Keys.project.trim, [])\n\n        if not trim_list:\n            return clip, frame_props, frame_mapping\n\n        segments = []\n        new_frame_props: Dict[int, Dict[str, Any]] = {}  # Store new frame property map\n        new_frame_idx = 0\n\n        for trim in trim_list:\n            first, last = trim\n            if first &lt;= last and first &lt; clip.num_frames and last &lt; clip.num_frames:\n                # Create segment\n                segment = clip[first:last+1]\n\n                # Update frame properties and mapping\n                for i in range(first, last+1):\n                    # Update trim info\n                    if i in frame_props:\n                        props = frame_props[i].copy()\n                        props.update({\n                            \"WobblyTrimStart\": first,\n                            \"WobblyTrimEnd\": last\n                        })\n                        new_frame_props[new_frame_idx] = props # type: ignore\n                        # Update mapping\n                        frame_mapping[new_frame_idx] = i\n                        new_frame_idx += 1\n\n                segments.append(segment)\n\n        if segments:\n            clip = core.std.Splice(clips=segments)\n            frame_props = new_frame_props  # type: ignore # Update frame property map\n\n    return clip, frame_props, frame_mapping\n</code></pre>"},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim.TrimProcessor.process(clip)","title":"<code>clip</code>","text":""},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim.TrimProcessor.process(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim.TrimProcessor.process(frame_props)","title":"<code>frame_props</code>","text":""},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim.TrimProcessor.process(frame_mapping)","title":"<code>frame_mapping</code>","text":""},{"location":"API/source/wobbly/processors/trim/#y5gfunc.source.wobbly.processors.trim.TrimProcessor.process(presets)","title":"<code>presets</code>","text":""},{"location":"API/source/wobbly/timecodes/base/","title":"<code>y5gfunc.source.wobbly.timecodes.base</code>","text":""},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base","title":"base","text":"<p>Timecode generator base class and factory.</p> <p>Classes:</p> Name Description <code>TimecodeGenerator</code> <p>Timecode generator base class</p> <code>TimecodeGeneratorFactory</code> <p>Timecode generator factory</p>"},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGenerator","title":"TimecodeGenerator","text":"<pre><code>TimecodeGenerator(project: ProjectData)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Timecode generator base class</p> <p>Initialize timecode generator</p> <p>Parameters:</p> Name Type Description Default <code>ProjectData</code> <p>Project data</p> required <p>Methods:</p> Name Description <code>generate</code> <p>Generate timecode string</p> <p>Attributes:</p> Name Type Description <code>project</code> Source code in <code>y5gfunc/source/wobbly/timecodes/base.py</code> <pre><code>def __init__(self, project: ProjectData):\n    \"\"\"\n    Initialize timecode generator\n\n    Args:\n        project: Project data\n    \"\"\"\n    self.project = project\n    self.decimated_by_cycle, self.ranges = get_decimation_info(project)\n</code></pre>"},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGenerator(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGenerator.project","title":"project  <code>instance-attribute</code>","text":"<pre><code>project = project\n</code></pre>"},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGenerator.generate","title":"generate  <code>abstractmethod</code>","text":"<pre><code>generate() -&gt; str\n</code></pre> <p>Generate timecode string</p> <p>Returns:</p> Type Description <code>str</code> <p>Timecode string</p> Source code in <code>y5gfunc/source/wobbly/timecodes/base.py</code> <pre><code>@abstractmethod\ndef generate(self) -&gt; str:\n    \"\"\"\n    Generate timecode string\n\n    Returns:\n        Timecode string\n    \"\"\"\n    pass\n</code></pre>"},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGeneratorFactory","title":"TimecodeGeneratorFactory","text":"<p>Timecode generator factory</p> <p>Methods:</p> Name Description <code>register</code> <p>Decorator for registering timecode generator classes</p> <code>create</code> <p>Create timecode generator instance</p>"},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGeneratorFactory.register","title":"register  <code>classmethod</code>","text":"<pre><code>register(version: str) -&gt; Callable\n</code></pre> <p>Decorator for registering timecode generator classes</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Timecode version</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>Decorator function</p> Source code in <code>y5gfunc/source/wobbly/timecodes/base.py</code> <pre><code>@classmethod\ndef register(cls, version: str) -&gt; Callable:\n    \"\"\"\n    Decorator for registering timecode generator classes\n\n    Args:\n        version: Timecode version\n\n    Returns:\n        Decorator function\n    \"\"\"\n    def decorator(generator_cls: Type[TimecodeGenerator]) -&gt; Type[TimecodeGenerator]:\n        cls._generators[version] = generator_cls\n        return generator_cls\n    return decorator\n</code></pre>"},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGeneratorFactory.register(version)","title":"<code>version</code>","text":""},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGeneratorFactory.create","title":"create  <code>classmethod</code>","text":"<pre><code>create(version: str, project: ProjectData) -&gt; TimecodeGenerator\n</code></pre> <p>Create timecode generator instance</p> <p>Parameters:</p> Name Type Description Default <code>str</code> <p>Timecode version</p> required <code>ProjectData</code> <p>Project data</p> required <p>Returns:</p> Type Description <code>TimecodeGenerator</code> <p>Timecode generator instance</p> Source code in <code>y5gfunc/source/wobbly/timecodes/base.py</code> <pre><code>@classmethod\ndef create(cls, version: str, project: ProjectData) -&gt; TimecodeGenerator:\n    \"\"\"\n    Create timecode generator instance\n\n    Args:\n        version: Timecode version\n        project: Project data\n\n    Returns:\n        Timecode generator instance\n    \"\"\"\n\n    if version not in cls._generators:\n        raise ValueError(f\"Unsupported timecode version: {version}\")\n\n    generator_cls = cls._generators[version]\n    return generator_cls(project)\n</code></pre>"},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGeneratorFactory.create(version)","title":"<code>version</code>","text":""},{"location":"API/source/wobbly/timecodes/base/#y5gfunc.source.wobbly.timecodes.base.TimecodeGeneratorFactory.create(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/timecodes/v1/","title":"<code>y5gfunc.source.wobbly.timecodes.v1</code>","text":""},{"location":"API/source/wobbly/timecodes/v1/#y5gfunc.source.wobbly.timecodes.v1","title":"v1","text":"<p>V1 version timecode generator.</p> <p>Classes:</p> Name Description <code>TimecodesV1Generator</code> <p>V1 version timecode generator</p>"},{"location":"API/source/wobbly/timecodes/v1/#y5gfunc.source.wobbly.timecodes.v1.TimecodesV1Generator","title":"TimecodesV1Generator","text":"<pre><code>TimecodesV1Generator(project: ProjectData)\n</code></pre> <p>               Bases: <code>TimecodeGenerator</code></p> <p>V1 version timecode generator</p> <p>Initialize timecode generator</p> <p>Parameters:</p> Name Type Description Default <code>ProjectData</code> <p>Project data</p> required <p>Methods:</p> Name Description <code>generate</code> <p>Generate V1 format timecode</p> <p>Attributes:</p> Name Type Description <code>project</code> Source code in <code>y5gfunc/source/wobbly/timecodes/base.py</code> <pre><code>def __init__(self, project: ProjectData):\n    \"\"\"\n    Initialize timecode generator\n\n    Args:\n        project: Project data\n    \"\"\"\n    self.project = project\n    self.decimated_by_cycle, self.ranges = get_decimation_info(project)\n</code></pre>"},{"location":"API/source/wobbly/timecodes/v1/#y5gfunc.source.wobbly.timecodes.v1.TimecodesV1Generator(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/timecodes/v1/#y5gfunc.source.wobbly.timecodes.v1.TimecodesV1Generator.project","title":"project  <code>instance-attribute</code>","text":"<pre><code>project = project\n</code></pre>"},{"location":"API/source/wobbly/timecodes/v1/#y5gfunc.source.wobbly.timecodes.v1.TimecodesV1Generator.generate","title":"generate","text":"<pre><code>generate() -&gt; str\n</code></pre> <p>Generate V1 format timecode</p> <p>Returns:</p> Type Description <code>str</code> <p>V1 format timecode string</p> Source code in <code>y5gfunc/source/wobbly/timecodes/v1.py</code> <pre><code>def generate(self) -&gt; str:\n    \"\"\"\n    Generate V1 format timecode\n\n    Returns:\n        V1 format timecode string\n    \"\"\"\n    DEFAULT_FPS = 24000 / 1001\n\n    tc = \"# timecode format v1\\n\"\n    tc += f\"Assume {DEFAULT_FPS:.12f}\\n\"\n\n    numerators = [30000, 24000, 18000, 12000, 6000]\n    denominator = 1001\n\n    for range_info in self.ranges:\n        dropped = range_info.dropped\n\n        if numerators[dropped] != 24000:\n            start_frame = frame_number_after_decimation(\n                range_info.start, self.decimated_by_cycle\n            )\n            end_frame = frame_number_after_decimation(\n                range_info.end - 1, self.decimated_by_cycle\n            )\n\n            fps = numerators[dropped] / denominator\n            tc += f\"{start_frame},{end_frame},{fps:.12f}\\n\"\n\n    return tc\n</code></pre>"},{"location":"API/source/wobbly/timecodes/v2/","title":"<code>y5gfunc.source.wobbly.timecodes.v2</code>","text":""},{"location":"API/source/wobbly/timecodes/v2/#y5gfunc.source.wobbly.timecodes.v2","title":"v2","text":"<p>V2 version timecode generator.</p> <p>Classes:</p> Name Description <code>TimecodesV2Generator</code> <p>V2 version timecode generator</p>"},{"location":"API/source/wobbly/timecodes/v2/#y5gfunc.source.wobbly.timecodes.v2.TimecodesV2Generator","title":"TimecodesV2Generator","text":"<pre><code>TimecodesV2Generator(project: ProjectData)\n</code></pre> <p>               Bases: <code>TimecodeGenerator</code></p> <p>V2 version timecode generator</p> <p>Initialize timecode generator</p> <p>Parameters:</p> Name Type Description Default <code>ProjectData</code> <p>Project data</p> required <p>Methods:</p> Name Description <code>generate</code> <p>Generate V2 format timecode</p> <p>Attributes:</p> Name Type Description <code>project</code> Source code in <code>y5gfunc/source/wobbly/timecodes/base.py</code> <pre><code>def __init__(self, project: ProjectData):\n    \"\"\"\n    Initialize timecode generator\n\n    Args:\n        project: Project data\n    \"\"\"\n    self.project = project\n    self.decimated_by_cycle, self.ranges = get_decimation_info(project)\n</code></pre>"},{"location":"API/source/wobbly/timecodes/v2/#y5gfunc.source.wobbly.timecodes.v2.TimecodesV2Generator(project)","title":"<code>project</code>","text":""},{"location":"API/source/wobbly/timecodes/v2/#y5gfunc.source.wobbly.timecodes.v2.TimecodesV2Generator.project","title":"project  <code>instance-attribute</code>","text":"<pre><code>project = project\n</code></pre>"},{"location":"API/source/wobbly/timecodes/v2/#y5gfunc.source.wobbly.timecodes.v2.TimecodesV2Generator.generate","title":"generate","text":"<pre><code>generate() -&gt; str\n</code></pre> <p>Generate V2 format timecode</p> <p>Returns:</p> Type Description <code>str</code> <p>V2 format timecode string</p> Source code in <code>y5gfunc/source/wobbly/timecodes/v2.py</code> <pre><code>def generate(self) -&gt; str:\n    \"\"\"\n    Generate V2 format timecode\n\n    Returns:\n        V2 format timecode string\n    \"\"\"\n    tc = \"# timecode format v2\\n\"\n\n    numerators = [30000, 24000, 18000, 12000, 6000]\n    denominator = 1001\n\n    # Calculate total output frames\n    total_frames = 0\n    for range_info in self.ranges:\n        start = range_info.start\n        end = range_info.end\n        total_frames += (\n            frame_number_after_decimation(end - 1, self.decimated_by_cycle) - \n            frame_number_after_decimation(start, self.decimated_by_cycle) + 1\n        )\n\n    current_frame = 0\n    current_time_ms = 0.0\n\n    for range_info in self.ranges:\n        dropped = range_info.dropped\n        fps = numerators[dropped] / denominator\n        frame_duration_ms = 1000.0 / fps\n\n        start_frame = frame_number_after_decimation(\n            range_info.start, self.decimated_by_cycle\n        )\n        end_frame = frame_number_after_decimation(\n            range_info.end - 1, self.decimated_by_cycle\n        )\n\n        for _ in range(start_frame, end_frame + 1):\n            tc += f\"{current_time_ms:.6f}\\n\"\n            current_time_ms += frame_duration_ms\n            current_frame += 1\n\n    return tc\n</code></pre>"},{"location":"API/vfx/draw_2d/","title":"<code>y5gfunc.vfx.draw_2d</code>","text":""},{"location":"API/vfx/draw_2d/#y5gfunc.vfx.draw_2d","title":"draw_2d","text":"<p>Functions:</p> Name Description <code>draw_line</code> <code>draw_circle</code> <code>draw_ellipse</code> <code>draw_bezier_curve</code> <code>draw_mandelbrot_zoomer</code> <code>draw_spiral</code>"},{"location":"API/vfx/draw_2d/#y5gfunc.vfx.draw_2d.draw_line","title":"draw_line","text":"<pre><code>draw_line(clip: VideoNode, sx: str, sy: str, ex: str, ey: str, thickness: str, color: str, factor: str = '1') -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/vfx/draw_2d.py</code> <pre><code>def draw_line(\n    clip: vs.VideoNode,\n    sx: str,\n    sy: str,\n    ex: str,\n    ey: str,\n    thickness: str,\n    color: str,\n    factor: str = \"1\",\n) -&gt; vs.VideoNode:\n    assert clip.format.num_planes == 1\n\n    expr = infix2postfix(f\"\"\"\n            sx = {sx}\n            sy = {sy}\n            ex = {ex}\n            ey = {ey}\n            thickness = {thickness}\n            color = {color}\n            factor = {factor}\n            dx = ex - sx\n            dy = ey - sy\n            L2 = (ex - sx) * dx + dy ** 2\n            half_thickness = thickness / 2\n            half_thickness_sq = half_thickness ** 2\n            tt = ((X - sx) * dx + (Y - sy) * dy) / L2\n            tt = clamp(tt, 0, 1)\n            proj_x = sx + tt * dx\n            proj_y = sy + tt * dy\n            d2 = (X - proj_x) * (X - proj_x) + (Y - proj_y) * (Y - proj_y)\n            do = d2 &lt;= half_thickness_sq\n            RESULT = do ? ((1 - factor) * src0 + factor * color) : src0\n            \"\"\")\n\n    return clip.akarin.Expr(expr)\n</code></pre>"},{"location":"API/vfx/draw_2d/#y5gfunc.vfx.draw_2d.draw_circle","title":"draw_circle","text":"<pre><code>draw_circle(clip: VideoNode, cx: str, cy: str, radius: str, thickness: str, color: str, factor: str = '1') -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/vfx/draw_2d.py</code> <pre><code>def draw_circle(\n    clip: vs.VideoNode,\n    cx: str,\n    cy: str,\n    radius: str,\n    thickness: str,\n    color: str,\n    factor: str = \"1\",\n) -&gt; vs.VideoNode:\n    assert clip.format.num_planes == 1\n\n    expr = infix2postfix(f\"\"\"\n            cx = {cx}\n            cy = {cy}\n            radius = {radius}\n            thickness = {thickness}\n            color = {color}\n            factor = {factor}\n            half_thickness = thickness / 2\n            dx = X - cx\n            dy = Y - cy\n            distance_sq = dx ** 2 + dy ** 2\n            radius_minus_half = radius - half_thickness\n            lower_sq = radius_minus_half ** 2\n            lower_sq = max(lower_sq, 0)\n            upper_sq = (radius + half_thickness) ** 2\n            do = distance_sq &gt;= lower_sq &amp;&amp; distance_sq &lt;= upper_sq\n            RESULT = do ? ((1 - factor) * src0 + factor * color) : src0\n            \"\"\")\n\n    return clip.akarin.Expr(expr)\n</code></pre>"},{"location":"API/vfx/draw_2d/#y5gfunc.vfx.draw_2d.draw_ellipse","title":"draw_ellipse","text":"<pre><code>draw_ellipse(clip: VideoNode, f1x: str, f1y: str, f2x: str, f2y: str, ellipse_sum: str, thickness: str, color: str, factor: str = '1') -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/vfx/draw_2d.py</code> <pre><code>def draw_ellipse(\n    clip: vs.VideoNode,\n    f1x: str,\n    f1y: str,\n    f2x: str,\n    f2y: str,\n    ellipse_sum: str,\n    thickness: str,\n    color: str,\n    factor: str = \"1\",\n) -&gt; vs.VideoNode:\n    assert clip.format.num_planes == 1\n\n    expr = infix2postfix(f\"\"\"\n            f1x = {f1x}\n            f1y = {f1y}\n            f2x = {f2x}\n            f2y = {f2y}\n            ellipse_sum = {ellipse_sum}\n            thickness = {thickness}\n            color = {color}\n            factor = {factor}\n            cx = (f1x + f2x) / 2\n            cy = (f1y + f2y) / 2\n            aa = ellipse_sum / 2\n            a2 = aa ** 2\n            dx = f2x - f1x\n            dy = f2y - f1y\n            c2 = (dx ** 2 + dy ** 2) / 4\n            b2 = a2 - c2\n            value = ((X - cx) ** 2) / a2 + ((Y - cy) ** 2) / b2\n            norm_thresh = thickness / ellipse_sum\n            do = abs(value - 1) &lt;= norm_thresh\n            RESULT = do ? ((1 - factor) * src0 + factor * color) : src0\n            \"\"\")\n\n    return clip.akarin.Expr(expr)\n</code></pre>"},{"location":"API/vfx/draw_2d/#y5gfunc.vfx.draw_2d.draw_bezier_curve","title":"draw_bezier_curve","text":"<pre><code>draw_bezier_curve(clip: VideoNode, controlPoint0X: str, controlPoint0Y: str, controlPoint1X: str, controlPoint1Y: str, controlPoint2X: str, controlPoint2Y: str, controlPoint3X: str, controlPoint3Y: str, thickness: str, color: str, sample_count: int = 100, factor: str = '1') -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/vfx/draw_2d.py</code> <pre><code>def draw_bezier_curve(\n    clip: vs.VideoNode,\n    controlPoint0X: str,\n    controlPoint0Y: str,\n    controlPoint1X: str,\n    controlPoint1Y: str,\n    controlPoint2X: str,\n    controlPoint2Y: str,\n    controlPoint3X: str,\n    controlPoint3Y: str,\n    thickness: str,\n    color: str,\n    sample_count: int = 100,\n    factor: str = \"1\",\n) -&gt; vs.VideoNode:\n    assert sample_count &gt;= 2\n    assert clip.format.num_planes == 1\n\n    expr_lines = []\n\n    expr_lines.append(f\"controlPoint0X = {controlPoint0X}\")\n    expr_lines.append(f\"controlPoint0Y = {controlPoint0Y}\")\n    expr_lines.append(f\"controlPoint1X = {controlPoint1X}\")\n    expr_lines.append(f\"controlPoint1Y = {controlPoint1Y}\")\n    expr_lines.append(f\"controlPoint2X = {controlPoint2X}\")\n    expr_lines.append(f\"controlPoint2Y = {controlPoint2Y}\")\n    expr_lines.append(f\"controlPoint3X = {controlPoint3X}\")\n    expr_lines.append(f\"controlPoint3Y = {controlPoint3Y}\")\n    expr_lines.append(f\"thickness = {thickness}\")\n    expr_lines.append(f\"color = {color}\")\n    expr_lines.append(f\"factor = {factor}\")\n    expr_lines.append(\"halfThickness = thickness / 2\")\n    expr_lines.append(\"halfThicknessSquared = halfThickness ** 2\")\n\n    total_samples = sample_count\n    for sample_index in range(total_samples):\n        t_value = sample_index / (total_samples - 1)\n        expr_lines.append(f\"parameterT_{sample_index} = {t_value}\")\n        expr_lines.append(f\"oneMinusT_{sample_index} = 1 - parameterT_{sample_index}\")\n        expr_lines.append(\n            f\"oneMinusT_squared_{sample_index} = oneMinusT_{sample_index} ** 2\"\n        )\n        expr_lines.append(\n            f\"oneMinusT_cubed_{sample_index} = oneMinusT_{sample_index} ** 3\"\n        )\n        expr_lines.append(\n            f\"parameterT_squared_{sample_index} = parameterT_{sample_index} ** 2\"\n        )\n        expr_lines.append(\n            f\"parameterT_cubed_{sample_index} = parameterT_{sample_index} ** 3\"\n        )\n        expr_lines.append(\n            f\"bezierX_{sample_index} = oneMinusT_cubed_{sample_index} * controlPoint0X + \"\n            f\"3 * oneMinusT_squared_{sample_index} * parameterT_{sample_index} * controlPoint1X + \"\n            f\"3 * oneMinusT_{sample_index} * parameterT_squared_{sample_index} * controlPoint2X + \"\n            f\"parameterT_cubed_{sample_index} * controlPoint3X\"\n        )\n        expr_lines.append(\n            f\"bezierY_{sample_index} = oneMinusT_cubed_{sample_index} * controlPoint0Y + \"\n            f\"3 * oneMinusT_squared_{sample_index} * parameterT_{sample_index} * controlPoint1Y + \"\n            f\"3 * oneMinusT_{sample_index} * parameterT_squared_{sample_index} * controlPoint2Y + \"\n            f\"parameterT_cubed_{sample_index} * controlPoint3Y\"\n        )\n\n    segment_distance_squared_expressions = []\n    for seg_index in range(total_samples - 1):\n        expr_lines.append(\n            f\"deltaX_{seg_index} = bezierX_{seg_index+1} - bezierX_{seg_index}\"\n        )\n        expr_lines.append(\n            f\"deltaY_{seg_index} = bezierY_{seg_index+1} - bezierY_{seg_index}\"\n        )\n        expr_lines.append(\n            f\"segmentLengthSquared_{seg_index} = deltaX_{seg_index} * deltaX_{seg_index} + deltaY_{seg_index} * deltaY_{seg_index}\"\n        )\n        expr_lines.append(\n            f\"tSegment_{seg_index} = ((X - bezierX_{seg_index}) * deltaX_{seg_index} + (Y - bezierY_{seg_index}) * deltaY_{seg_index}) / segmentLengthSquared_{seg_index}\"\n        )\n        expr_lines.append(f\"tClamped_{seg_index} = clamp(tSegment_{seg_index}, 0, 1)\")\n        expr_lines.append(\n            f\"projectionX_{seg_index} = bezierX_{seg_index} + tClamped_{seg_index} * deltaX_{seg_index}\"\n        )\n        expr_lines.append(\n            f\"projectionY_{seg_index} = bezierY_{seg_index} + tClamped_{seg_index} * deltaY_{seg_index}\"\n        )\n        expr_lines.append(\n            f\"distanceSquared_{seg_index} = (X - projectionX_{seg_index}) ** 2 + (Y - projectionY_{seg_index}) ** 2)\"\n        )\n        segment_distance_squared_expressions.append(f\"distanceSquared_{seg_index}\")\n\n    distance_arguments = \", \".join(segment_distance_squared_expressions)\n    expr_lines.append(f\"finalMinDistanceSquared = nth_1({distance_arguments})\")\n\n    expr_lines.append(\"doDraw = finalMinDistanceSquared &lt;= halfThicknessSquared\")\n    expr_lines.append(\"RESULT = doDraw ? ((1 - factor) * src0 + factor * color) : src0\")\n\n    full_expression = \"\\n\".join(expr_lines)\n\n    converted_expression = infix2postfix(full_expression)\n    return clip.akarin.Expr(converted_expression)\n</code></pre>"},{"location":"API/vfx/draw_2d/#y5gfunc.vfx.draw_2d.draw_mandelbrot_zoomer","title":"draw_mandelbrot_zoomer","text":"<pre><code>draw_mandelbrot_zoomer(clip: VideoNode, centerX: str, centerY: str, color: str, initialZoom: str = '0.005', zoomSpeed: str = '0.01', centerMoveSpeed: str = '0.01', fractalC0_re: str = '-0.75', fractalC0_im: str = '0.1', fractalC1_re: str = '-0.743643887037158704', fractalC1_im: str = '0.131825904205311130', maxIter: int = 350, escapeRadius: str = '2') -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/vfx/draw_2d.py</code> <pre><code>def draw_mandelbrot_zoomer(\n    clip: vs.VideoNode,\n    centerX: str,\n    centerY: str,\n    color: str,\n    initialZoom: str = \"0.005\",\n    zoomSpeed: str = \"0.01\",\n    centerMoveSpeed: str = \"0.01\",\n    fractalC0_re: str = \"-0.75\",\n    fractalC0_im: str = \"0.1\",\n    fractalC1_re: str = \"-0.743643887037158704\",\n    fractalC1_im: str = \"0.131825904205311130\",\n    maxIter: int = 350,\n    escapeRadius: str = \"2\",\n) -&gt; vs.VideoNode:\n    assert maxIter &gt;= 1\n\n    expr_lines = []\n\n    expr_lines.append(f\"centerX = {centerX}\")\n    expr_lines.append(f\"centerY = {centerY}\")\n    expr_lines.append(f\"color = {color}\")\n    expr_lines.append(f\"initialZoom = {initialZoom}\")\n    expr_lines.append(f\"zoomSpeed = {zoomSpeed}\")\n    expr_lines.append(f\"centerMoveSpeed = {centerMoveSpeed}\")\n    expr_lines.append(f\"maxIter = {maxIter}\")\n    expr_lines.append(f\"escapeRadius = {escapeRadius}\")\n    expr_lines.append(\"escapeSq = escapeRadius ** 2\")\n\n    expr_lines.append(\"scale = initialZoom * exp(-zoomSpeed * N)\")\n\n    expr_lines.append(\"ff = 1 - exp(-centerMoveSpeed * N)\")\n    expr_lines.append(f\"C0_re = {fractalC0_re}\")\n    expr_lines.append(f\"C0_im = {fractalC0_im}\")\n    expr_lines.append(f\"C1_re = {fractalC1_re}\")\n    expr_lines.append(f\"C1_im = {fractalC1_im}\")\n    expr_lines.append(\"dC_re = C0_re + (C1_re - C0_re) * ff\")\n    expr_lines.append(\"dC_im = C0_im + (C1_im - C0_im) * ff\")\n\n    expr_lines.append(\"c_re = (X - centerX) * scale + dC_re\")\n    expr_lines.append(\"c_im = (Y - centerY) * scale + dC_im\")\n\n    expr_lines.append(\"z_re_0 = 0\")\n    expr_lines.append(\"z_im_0 = 0\")\n    for i in range(1, maxIter + 1):\n        prev = i - 1\n        expr_lines.append(\n            f\"z_re_{i} = (z_re_{prev} * z_re_{prev} - z_im_{prev} * z_im_{prev} + c_re)\"\n        )\n        expr_lines.append(f\"z_im_{i} = (2 * z_re_{prev} * z_im_{prev} + c_im)\")\n        expr_lines.append(f\"r2_{i} = (z_re_{i} * z_re_{i} + z_im_{i} * z_im_{i})\")\n\n    iter_expr = str(maxIter)\n    for i in range(maxIter, 0, -1):\n        iter_expr = f\"(r2_{i} &gt; escapeSq ? {i} : {iter_expr})\"\n    expr_lines.append(\"iterResult = \" + iter_expr)\n\n    expr_lines.append(\"RESULT = (iterResult / maxIter) * color\")\n\n    full_expr = \"\\n\".join(expr_lines)\n    converted_expr = infix2postfix(full_expr)\n    return clip.akarin.Expr(converted_expr)\n</code></pre>"},{"location":"API/vfx/draw_2d/#y5gfunc.vfx.draw_2d.draw_spiral","title":"draw_spiral","text":"<pre><code>draw_spiral(clip: VideoNode, centerX: str, centerY: str, a: str, b: str, startAngle: str, endAngle: str, thickness: str, color: str, factor: str = '1', sample_count=500) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/vfx/draw_2d.py</code> <pre><code>def draw_spiral(\n    clip: vs.VideoNode,\n    centerX: str,\n    centerY: str,\n    a: str,\n    b: str,\n    startAngle: str,\n    endAngle: str,\n    thickness: str,\n    color: str,\n    factor: str = \"1\",\n    sample_count=500,\n) -&gt; vs.VideoNode:\n    assert clip.format.num_planes == 1\n\n    expr_lines = []\n    expr_lines.append(f\"centerX = {centerX}\")\n    expr_lines.append(f\"centerY = {centerY}\")\n    expr_lines.append(f\"aa = {a}\")\n    expr_lines.append(f\"bb = {b}\")\n    expr_lines.append(f\"startAngle = {startAngle}\")\n    expr_lines.append(f\"endAngle = {endAngle}\")\n    expr_lines.append(f\"thickness = {thickness}\")\n    expr_lines.append(f\"color = {color}\")\n    expr_lines.append(f\"factor = {factor}\")\n    expr_lines.append(\"halfThickness = thickness / 2\")\n    expr_lines.append(\"halfThicknessSquared = halfThickness ** 2\")\n\n    for i in range(sample_count):\n        expr_lines.append(f\"tt = {i} / ({sample_count} - 1)\")\n        expr_lines.append(\"theta = startAngle + tt * (endAngle - startAngle)\")\n        expr_lines.append(\"rr = aa + bb * theta\")\n        expr_lines.append(\"spiralX = centerX + rr * cos(theta)\")\n        expr_lines.append(\"spiralY = centerY + rr * sin(theta)\")\n        expr_lines.append(f\"spiralX_{i} = spiralX\")\n        expr_lines.append(f\"spiralY_{i} = spiralY\")\n\n    segment_distance_exprs = []\n    for i in range(sample_count - 1):\n        expr_lines.append(f\"deltaX_{i} = spiralX_{i+1} - spiralX_{i}\")\n        expr_lines.append(f\"deltaY_{i} = spiralY_{i+1} - spiralY_{i}\")\n        expr_lines.append(\n            f\"segmentLengthSquared_{i} = deltaX_{i} * deltaX_{i} + deltaY_{i} * deltaY_{i}\"\n        )\n        expr_lines.append(\n            f\"t_{i} = ((X - spiralX_{i}) * deltaX_{i} + (Y - spiralY_{i}) * deltaY_{i}) / segmentLengthSquared_{i}\"\n        )\n        expr_lines.append(f\"tClamped_{i} = clamp(t_{i}, 0, 1)\")\n        expr_lines.append(f\"projectionX_{i} = spiralX_{i} + tClamped_{i} * deltaX_{i}\")\n        expr_lines.append(f\"projectionY_{i} = spiralY_{i} + tClamped_{i} * deltaY_{i}\")\n        expr_lines.append(\n            f\"distanceSquared_{i} = (X - projectionX_{i}) ** 2 + (Y - projectionY_{i}) ** 2\"\n        )\n        segment_distance_exprs.append(f\"distanceSquared_{i}\")\n\n    expr_lines.append(\n        \"finalMinDistanceSquared = nth_1(\" + \", \".join(segment_distance_exprs) + \")\"\n    )\n    expr_lines.append(\"doDraw = finalMinDistanceSquared &lt;= halfThicknessSquared\")\n    expr_lines.append(\"RESULT = doDraw ? ((1 - factor) * src0 + factor * color) : src0\")\n\n    full_expr = \"\\n\".join(expr_lines)\n    converted_expr = infix2postfix(full_expr)\n    return clip.akarin.Expr(converted_expr)\n</code></pre>"},{"location":"API/vfx/draw_3d/","title":"<code>y5gfunc.vfx.draw_3d</code>","text":""},{"location":"API/vfx/draw_3d/#y5gfunc.vfx.draw_3d","title":"draw_3d","text":"<p>Functions:</p> Name Description <code>draw_3d_cube</code> <code>render_triangle_scene</code> <p>Example:</p> <code>load_mesh</code> <code>render_model_scene</code>"},{"location":"API/vfx/draw_3d/#y5gfunc.vfx.draw_3d.draw_3d_cube","title":"draw_3d_cube","text":"<pre><code>draw_3d_cube(clip: VideoNode, centerX: str, centerY: str, cubeSize: str, color: str, rotationX: str, rotationY: str, thickness: str, translateZ: str = '500', focal: str = '500', factor: str = '1') -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/vfx/draw_3d.py</code> <pre><code>def draw_3d_cube(\n    clip: vs.VideoNode,\n    centerX: str,\n    centerY: str,\n    cubeSize: str,\n    color: str,\n    rotationX: str,\n    rotationY: str,\n    thickness: str,\n    translateZ: str = \"500\",\n    focal: str = \"500\",\n    factor: str = \"1\",\n) -&gt; vs.VideoNode:\n    assert clip.format.num_planes == 1\n\n    expr = infix2postfix(f\"\"\"\n            centerX = {centerX}\n            centerY = {centerY}\n            cubeSize = {cubeSize}\n            rotationX = {rotationX}\n            rotationY = {rotationY}\n            translateZ = {translateZ}\n            focal = {focal}\n            thickness = {thickness}\n            color = {color}\n            factor = {factor}\n\n            half = cubeSize / 2\n            cos_rotationX = cos(rotationX)\n            sin_rotationX = sin(rotationX)\n            cos_rotationY = cos(rotationY)\n            sin_rotationY = sin(rotationY)\n\n            &lt;global&lt;cos_rotationX&gt;&lt;sin_rotationX&gt;&lt;cos_rotationY&gt;&lt;sin_rotationY&gt;&lt;translateZ&gt;&lt;centerX&gt;&lt;focal&gt;&gt;\n            function project3d_x(vx, vy, vz) {{\n                vy1 = vy * cos_rotationX - vz * sin_rotationX\n                vz1 = vy * sin_rotationX + vz * cos_rotationX\n                vx1 = vx\n                vx2 = vx1 * cos_rotationY + vz1 * sin_rotationY\n                vz2 = -vx1 * sin_rotationY + vz1 * cos_rotationY\n                vy2 = vy1\n                vz_final = vz2 + translateZ\n                return centerX + (vx2 * focal) / vz_final\n            }}\n\n            &lt;global&lt;cos_rotationX&gt;&lt;sin_rotationX&gt;&lt;cos_rotationY&gt;&lt;sin_rotationY&gt;&lt;translateZ&gt;&lt;centerY&gt;&lt;focal&gt;&gt;\n            function project3d_y(vx, vy, vz) {{\n                vy1 = vy * cos_rotationX - vz * sin_rotationX\n                vz1 = vy * sin_rotationX + vz * cos_rotationX\n                vx1 = vx\n                vx2 = vx1 * cos_rotationY + vz1 * sin_rotationY\n                vz2 = -vx1 * sin_rotationY + vz1 * cos_rotationY\n                vy2 = vy1\n                vz_final = vz2 + translateZ\n                return centerY + (vy2 * focal) / vz_final\n            }}\n\n            function distSqToSegment(x0, y0, x1, y1) {{\n                dx = x1 - x0\n                dy = y1 - y0\n                segLenSq = dx * dx + dy * dy\n                tt = ((X - x0) * dx + (Y - y0) * dy) / segLenSq\n                t_clamped = clamp(tt, 0, 1)\n                projX = x0 + t_clamped * dx\n                projY = y0 + t_clamped * dy\n                return (X - projX) ** 2 + (Y - projY) ** 2\n            }}\n\n            v0projX = project3d_x(-half, -half, -half)\n            v0projY = project3d_y(-half, -half, -half)\n\n            v1projX = project3d_x(half, -half, -half)\n            v1projY = project3d_y(half, -half, -half)\n\n            v2projX = project3d_x(half, half, -half)\n            v2projY = project3d_y(half, half, -half)\n\n            v3projX = project3d_x(-half, half, -half)\n            v3projY = project3d_y(-half, half, -half)\n\n            v4projX = project3d_x(-half, -half, half)\n            v4projY = project3d_y(-half, -half, half)\n\n            v5projX = project3d_x(half, -half, half)\n            v5projY = project3d_y(half, -half, half)\n\n            v6projX = project3d_x(half, half, half)\n            v6projY = project3d_y(half, half, half)\n\n            v7projX = project3d_x(-half, half, half)\n            v7projY = project3d_y(-half, half, half)\n\n            d0  = distSqToSegment(v0projX, v0projY, v1projX, v1projY)\n            d1  = distSqToSegment(v1projX, v1projY, v2projX, v2projY)\n            d2  = distSqToSegment(v2projX, v2projY, v3projX, v3projY)\n            d3  = distSqToSegment(v3projX, v3projY, v0projX, v0projY)\n            d4  = distSqToSegment(v4projX, v4projY, v5projX, v5projY)\n            d5  = distSqToSegment(v5projX, v5projY, v6projX, v6projY)\n            d6  = distSqToSegment(v6projX, v6projY, v7projX, v7projY)\n            d7  = distSqToSegment(v7projX, v7projY, v4projX, v4projY)\n            d8  = distSqToSegment(v0projX, v0projY, v4projX, v4projY)\n            d9  = distSqToSegment(v1projX, v1projY, v5projX, v5projY)\n            d10 = distSqToSegment(v2projX, v2projY, v6projX, v6projY)\n            d11 = distSqToSegment(v3projX, v3projY, v7projX, v7projY)\n\n            finalMinDistanceSquared = nth_1(d0, d1, d2, d3, d4, d5, d6, d7, d8, d9, d10, d11)\n\n            halfThickness = thickness / 2\n            halfThicknessSq = halfThickness ** 2\n            doDraw = finalMinDistanceSquared &lt;= halfThicknessSq\n\n            RESULT = doDraw ? ((1 - factor) * src0 + factor * color) : src0\n            \"\"\")\n\n    return clip.akarin.Expr(expr)\n</code></pre>"},{"location":"API/vfx/draw_3d/#y5gfunc.vfx.draw_3d.render_triangle_scene","title":"render_triangle_scene","text":"<pre><code>render_triangle_scene(clip: VideoNode, points: list, faces: list, lights: list, camX: str, camY: str, camZ: str, rotationX: str, rotationY: str, focal: str, background: str = '0') -&gt; VideoNode\n</code></pre> <p>Example:</p> <pre><code>clip = core.std.BlankClip(width=640, height=480, format=vs.GRAYS, length=12000)\n\norig_points = [\n    { \"x\" : \"-100\", \"y\" : \"-100\", \"z\" : \"100\"  },\n    { \"x\" : \"100\",  \"y\" : \"-100\", \"z\" : \"100\"  },\n    { \"x\" : \"100\",  \"y\" : \"100\",  \"z\" : \"100\"  },\n    { \"x\" : \"-100\", \"y\" : \"100\",  \"z\" : \"100\"  },\n    { \"x\" : \"-100\", \"y\" : \"-100\", \"z\" : \"-100\" },\n    { \"x\" : \"100\",  \"y\" : \"-100\", \"z\" : \"-100\" },\n    { \"x\" : \"100\",  \"y\" : \"100\",  \"z\" : \"-100\" },\n    { \"x\" : \"-100\", \"y\" : \"100\",  \"z\" : \"-100\" }\n]\n\ntransformed_points = []\nfor pt in orig_points:\n    new_pt = {\n        \"x\": f\"(({pt['x']}) * cos(N * 0.02) - ({pt['z']}) * sin(N * 0.02) + 20 * sin(N * 0.015))\",\n        \"y\": f\"(({pt['y']}) + 20 * cos(N * 0.015))\",\n        \"z\": f\"(({pt['x']}) * sin(N * 0.02) + ({pt['z']}) * cos(N * 0.02))\"\n    }\n    transformed_points.append(new_pt)\n\nfaces = [\n    { \"a\" : 0, \"b\" : 1, \"c\" : 2, \"color\" : \"1\"   },\n    { \"a\" : 0, \"b\" : 2, \"c\" : 3, \"color\" : \"1\"   },\n    { \"a\" : 4, \"b\" : 6, \"c\" : 5, \"color\" : \"0.8\" },\n    { \"a\" : 4, \"b\" : 7, \"c\" : 6, \"color\" : \"0.8\" },\n    { \"a\" : 0, \"b\" : 3, \"c\" : 7, \"color\" : \"0.9\" },\n    { \"a\" : 0, \"b\" : 7, \"c\" : 4, \"color\" : \"0.9\" },\n    { \"a\" : 1, \"b\" : 5, \"c\" : 6, \"color\" : \"1.0\" },\n    { \"a\" : 1, \"b\" : 6, \"c\" : 2, \"color\" : \"1.0\" },\n    { \"a\" : 3, \"b\" : 2, \"c\" : 6, \"color\" : \"1.1\" },\n    { \"a\" : 3, \"b\" : 6, \"c\" : 7, \"color\" : \"1.1\" },\n    { \"a\" : 0, \"b\" : 4, \"c\" : 5, \"color\" : \"0.7\" },\n    { \"a\" : 0, \"b\" : 5, \"c\" : 1, \"color\" : \"0.7\" }\n]\n\nlights = [\n    { \"lx\" : \"cos(N * 0.02)\", \"ly\" : \"0.5\", \"lz\" : \"sin(N * 0.02)\", \"intensity\" : \"0.8\" },\n    { \"lx\" : \"-0.5\",          \"ly\" : \"1\",   \"lz\" : \"0.5\",           \"intensity\" : \"0.6\" }\n]\n\ncamX = \"20 * sin(241 * 0.015) + 500 * cos(241 * 0.01)\"\ncamY = \"20 * cos(241 * 0.015) + 200 + 4 - 2 * abs(N % 8 - 4)\"\ncamZ = \"500 * sin(241 * 0.01) - 4 - 2 * abs(N % 8 - 4)\"\n\nrotationX = \"0.38 + (40 - 2 * abs(N % 80 - 40)) / 500\"\nrotationY = \"-2.41\"\n\nfocal = \"500\"\n\nclip_result = render_triangle_scene(\n    clip,\n    points=transformed_points,\n    faces=faces,\n    lights=lights,\n    camX=camX,\n    camY=camY,\n    camZ=camZ,\n    rotationX=rotationX,\n    rotationY=rotationY,\n    focal=focal,\n    background=\"0\"\n)\n</code></pre> <p>Renders a rotating and vibrating cubic.</p> Source code in <code>y5gfunc/vfx/draw_3d.py</code> <pre><code>def render_triangle_scene(\n    clip: vs.VideoNode,\n    points: list,\n    faces: list,\n    lights: list,\n    camX: str,\n    camY: str,\n    camZ: str,\n    rotationX: str,\n    rotationY: str,\n    focal: str,\n    background: str = \"0\",\n) -&gt; vs.VideoNode:\n    \"\"\"\n\n    Example:\n\n    ```python\n    clip = core.std.BlankClip(width=640, height=480, format=vs.GRAYS, length=12000)\n\n    orig_points = [\n        { \"x\" : \"-100\", \"y\" : \"-100\", \"z\" : \"100\"  },\n        { \"x\" : \"100\",  \"y\" : \"-100\", \"z\" : \"100\"  },\n        { \"x\" : \"100\",  \"y\" : \"100\",  \"z\" : \"100\"  },\n        { \"x\" : \"-100\", \"y\" : \"100\",  \"z\" : \"100\"  },\n        { \"x\" : \"-100\", \"y\" : \"-100\", \"z\" : \"-100\" },\n        { \"x\" : \"100\",  \"y\" : \"-100\", \"z\" : \"-100\" },\n        { \"x\" : \"100\",  \"y\" : \"100\",  \"z\" : \"-100\" },\n        { \"x\" : \"-100\", \"y\" : \"100\",  \"z\" : \"-100\" }\n    ]\n\n    transformed_points = []\n    for pt in orig_points:\n        new_pt = {\n            \"x\": f\"(({pt['x']}) * cos(N * 0.02) - ({pt['z']}) * sin(N * 0.02) + 20 * sin(N * 0.015))\",\n            \"y\": f\"(({pt['y']}) + 20 * cos(N * 0.015))\",\n            \"z\": f\"(({pt['x']}) * sin(N * 0.02) + ({pt['z']}) * cos(N * 0.02))\"\n        }\n        transformed_points.append(new_pt)\n\n    faces = [\n        { \"a\" : 0, \"b\" : 1, \"c\" : 2, \"color\" : \"1\"   },\n        { \"a\" : 0, \"b\" : 2, \"c\" : 3, \"color\" : \"1\"   },\n        { \"a\" : 4, \"b\" : 6, \"c\" : 5, \"color\" : \"0.8\" },\n        { \"a\" : 4, \"b\" : 7, \"c\" : 6, \"color\" : \"0.8\" },\n        { \"a\" : 0, \"b\" : 3, \"c\" : 7, \"color\" : \"0.9\" },\n        { \"a\" : 0, \"b\" : 7, \"c\" : 4, \"color\" : \"0.9\" },\n        { \"a\" : 1, \"b\" : 5, \"c\" : 6, \"color\" : \"1.0\" },\n        { \"a\" : 1, \"b\" : 6, \"c\" : 2, \"color\" : \"1.0\" },\n        { \"a\" : 3, \"b\" : 2, \"c\" : 6, \"color\" : \"1.1\" },\n        { \"a\" : 3, \"b\" : 6, \"c\" : 7, \"color\" : \"1.1\" },\n        { \"a\" : 0, \"b\" : 4, \"c\" : 5, \"color\" : \"0.7\" },\n        { \"a\" : 0, \"b\" : 5, \"c\" : 1, \"color\" : \"0.7\" }\n    ]\n\n    lights = [\n        { \"lx\" : \"cos(N * 0.02)\", \"ly\" : \"0.5\", \"lz\" : \"sin(N * 0.02)\", \"intensity\" : \"0.8\" },\n        { \"lx\" : \"-0.5\",          \"ly\" : \"1\",   \"lz\" : \"0.5\",           \"intensity\" : \"0.6\" }\n    ]\n\n    camX = \"20 * sin(241 * 0.015) + 500 * cos(241 * 0.01)\"\n    camY = \"20 * cos(241 * 0.015) + 200 + 4 - 2 * abs(N % 8 - 4)\"\n    camZ = \"500 * sin(241 * 0.01) - 4 - 2 * abs(N % 8 - 4)\"\n\n    rotationX = \"0.38 + (40 - 2 * abs(N % 80 - 40)) / 500\"\n    rotationY = \"-2.41\"\n\n    focal = \"500\"\n\n    clip_result = render_triangle_scene(\n        clip,\n        points=transformed_points,\n        faces=faces,\n        lights=lights,\n        camX=camX,\n        camY=camY,\n        camZ=camZ,\n        rotationX=rotationX,\n        rotationY=rotationY,\n        focal=focal,\n        background=\"0\"\n    )\n    ```\n\n    Renders a rotating and vibrating cubic.\n    \"\"\"\n\n    expr_lines = []\n\n    expr_lines.append(\n        \"&lt;global&lt;camX&gt;&lt;camY&gt;&lt;camZ&gt;&lt;rotationX&gt;&lt;rotationY&gt;&lt;focal&gt;&lt;screenCenterX&gt;&lt;screenCenterY&gt;&lt;epsilon&gt;&gt;\"\n    )\n    expr_lines.append(\"function cam_coord_x(x, y, z) {\")\n    expr_lines.append(\"    tx = x - camX\")\n    expr_lines.append(\"    ty = y - camY\")\n    expr_lines.append(\"    tz = z - camZ\")\n    expr_lines.append(\"    ty1 = ty * cos(rotationX) - tz * sin(rotationX)\")\n    expr_lines.append(\"    tz1 = ty * sin(rotationX) + tz * cos(rotationX)\")\n    expr_lines.append(\"    cx = tx * cos(rotationY) + tz1 * sin(rotationY)\")\n    expr_lines.append(\"    return cx\")\n    expr_lines.append(\"}\")\n\n    expr_lines.append(\n        \"&lt;global&lt;camX&gt;&lt;camY&gt;&lt;camZ&gt;&lt;rotationX&gt;&lt;rotationY&gt;&lt;focal&gt;&lt;screenCenterX&gt;&lt;screenCenterY&gt;&lt;epsilon&gt;&gt;\"\n    )\n    expr_lines.append(\"function cam_coord_y(x, y, z) {\")\n    expr_lines.append(\"    ty = y - camY\")\n    expr_lines.append(\"    tz = z - camZ\")\n    expr_lines.append(\"    cy = ty * cos(rotationX) - tz * sin(rotationX)\")\n    expr_lines.append(\"    return cy\")\n    expr_lines.append(\"}\")\n\n    expr_lines.append(\"&lt;global&lt;camX&gt;&lt;camY&gt;&lt;camZ&gt;&lt;rotationX&gt;&lt;rotationY&gt;&lt;epsilon&gt;&lt;huge&gt;&gt;\")\n    expr_lines.append(\"function cam_coord_z(x, y, z) {\")\n    expr_lines.append(\"    tx = x - camX\")\n    expr_lines.append(\"    ty = y - camY\")\n    expr_lines.append(\"    tz = z - camZ\")\n    expr_lines.append(\"    ty1 = ty * cos(rotationX) - tz * sin(rotationX)\")\n    expr_lines.append(\"    tz1 = ty * sin(rotationX) + tz * cos(rotationX)\")\n    expr_lines.append(\"    cz = -tx * sin(rotationY) + tz1 * cos(rotationY)\")\n    expr_lines.append(\"    return cz &lt; 0 ? huge : cz\")\n    expr_lines.append(\"}\")\n\n    expr_lines.append(\"&lt;global&lt;focal&gt;&lt;screenCenterX&gt;&gt;\")\n    expr_lines.append(\"function projectX(x, y, z) {\")\n    expr_lines.append(\"    px = cam_coord_x(x, y, z)\")\n    expr_lines.append(\"    pz = cam_coord_z(x, y, z)\")\n    expr_lines.append(\"    return screenCenterX + (px * focal) / pz\")\n    expr_lines.append(\"}\")\n\n    expr_lines.append(\"&lt;global&lt;focal&gt;&lt;screenCenterY&gt;&gt;\")\n    expr_lines.append(\"function projectY(x, y, z) {\")\n    expr_lines.append(\"    py = cam_coord_y(x, y, z)\")\n    expr_lines.append(\"    pz = cam_coord_z(x, y, z)\")\n    expr_lines.append(\"    return screenCenterY + (py * focal) / pz\")\n    expr_lines.append(\"}\")\n\n    expr_lines.append(f\"camX = {camX}\")\n    expr_lines.append(f\"camY = {camY}\")\n    expr_lines.append(f\"camZ = {camZ}\")\n    expr_lines.append(f\"rotationX = {rotationX}\")\n    expr_lines.append(f\"rotationY = {rotationY}\")\n    expr_lines.append(f\"focal = {focal}\")\n    expr_lines.append(f\"background = {background}\")\n    expr_lines.append(\"screenCenterX = width / 2\")\n    expr_lines.append(\"screenCenterY = height / 2\")\n    expr_lines.append(\"epsilon = 0.0001\")\n    expr_lines.append(\"huge = 1e9\")\n    expr_lines.append(\"ambient = 0.2\")\n\n    for idx, light in enumerate(lights):\n        expr_lines.append(f\"light{idx}_raw_x = {light['lx']}\")\n        expr_lines.append(f\"light{idx}_raw_y = {light['ly']}\")\n        expr_lines.append(f\"light{idx}_raw_z = {light['lz']}\")\n        expr_lines.append(f\"light{idx}_intensity = {light['intensity']}\")\n        expr_lines.append(\n            f\"mag_{idx} = sqrt(light{idx}_raw_x ** 2 + light{idx}_raw_y ** 2 + light{idx}_raw_z ** 2)\"\n        )\n        expr_lines.append(f\"light{idx}_nx = light{idx}_raw_x / mag_{idx}\")\n        expr_lines.append(f\"light{idx}_ny = light{idx}_raw_y / mag_{idx}\")\n        expr_lines.append(f\"light{idx}_nz = light{idx}_raw_z / mag_{idx}\")\n        expr_lines.append(\n            f\"temp_ty_{idx} = light{idx}_ny * cos(rotationX) - light{idx}_nz * sin(rotationX)\"\n        )\n        expr_lines.append(\n            f\"temp_tz_{idx} = light{idx}_ny * sin(rotationX) + light{idx}_nz * cos(rotationX)\"\n        )\n        expr_lines.append(\n            f\"light{idx}_lx = light{idx}_nx * cos(rotationY) + temp_tz_{idx} * sin(rotationY)\"\n        )\n        expr_lines.append(f\"light{idx}_ly = temp_ty_{idx}\")\n        expr_lines.append(\n            f\"light{idx}_lz = -light{idx}_nx * sin(rotationY) + temp_tz_{idx} * cos(rotationY)\"\n        )\n\n    for i, pt in enumerate(points):\n        expr_lines.append(f\"point{i}_x = {pt['x']}\")\n        expr_lines.append(f\"point{i}_y = {pt['y']}\")\n        expr_lines.append(f\"point{i}_z = {pt['z']}\")\n        expr_lines.append(f\"projX_{i} = projectX(point{i}_x, point{i}_y, point{i}_z)\")\n        expr_lines.append(f\"projY_{i} = projectY(point{i}_x, point{i}_y, point{i}_z)\")\n        expr_lines.append(\n            f\"cam_x_{i} = cam_coord_x(point{i}_x, point{i}_y, point{i}_z)\"\n        )\n        expr_lines.append(\n            f\"cam_y_{i} = cam_coord_y(point{i}_x, point{i}_y, point{i}_z)\"\n        )\n        expr_lines.append(\n            f\"cam_z_{i} = cam_coord_z(point{i}_x, point{i}_y, point{i}_z)\"\n        )\n\n    face_t_names = []\n    face_shading_names = []\n    face_count = len(faces)\n    for f_idx, face in enumerate(faces):\n        a_idx = face[\"a\"]\n        b_idx = face[\"b\"]\n        c_idx = face[\"c\"]\n        face_color = face.get(\"color\", \"1\")\n        expr_lines.append(\n            f\"E0_{f_idx} = (X - projX_{a_idx}) * (projY_{b_idx} - projY_{a_idx}) - (Y - projY_{a_idx}) * (projX_{b_idx} - projX_{a_idx})\"\n        )\n        expr_lines.append(\n            f\"E1_{f_idx} = (X - projX_{b_idx}) * (projY_{c_idx} - projY_{b_idx}) - (Y - projY_{b_idx}) * (projX_{c_idx} - projX_{b_idx})\"\n        )\n        expr_lines.append(\n            f\"E2_{f_idx} = (X - projX_{c_idx}) * (projY_{a_idx} - projY_{c_idx}) - (Y - projY_{c_idx}) * (projX_{a_idx} - projX_{c_idx})\"\n        )\n        expr_lines.append(\n            f\"inside_pos_{f_idx} = E0_{f_idx} &gt;= 0 &amp;&amp; E1_{f_idx} &gt;= 0 &amp;&amp; E2_{f_idx} &gt;= 0\"\n        )\n        expr_lines.append(\n            f\"inside_neg_{f_idx} = E0_{f_idx} &lt;= 0 &amp;&amp; E1_{f_idx} &lt;= 0 &amp;&amp; E2_{f_idx} &lt;= 0\"\n        )\n        expr_lines.append(\n            f\"valid_{f_idx} = (cam_z_{a_idx} &lt; huge) &amp;&amp; (cam_z_{b_idx} &lt; huge) &amp;&amp; (cam_z_{c_idx} &lt; huge)\"\n        )\n        expr_lines.append(\n            f\"inside_{f_idx} = (inside_pos_{f_idx} || inside_neg_{f_idx}) &amp;&amp; valid_{f_idx}\"\n        )\n\n        expr_lines.append(\n            f\"area_{f_idx} = (projX_{b_idx} - projX_{a_idx}) * (projY_{c_idx} - projY_{a_idx}) - (projX_{c_idx} - projX_{a_idx}) * (projY_{b_idx} - projY_{a_idx})\"\n        )\n        expr_lines.append(\n            f\"alpha_{f_idx} = ((projX_{b_idx} - X) * (projY_{c_idx} - Y) - (projX_{c_idx} - X) * (projY_{b_idx} - Y)) / area_{f_idx}\"\n        )\n        expr_lines.append(\n            f\"beta_{f_idx} = ((projX_{c_idx} - X) * (projY_{a_idx} - Y) - (projX_{a_idx} - X) * (projY_{c_idx} - Y)) / area_{f_idx}\"\n        )\n        expr_lines.append(f\"gamma_{f_idx} = 1 - alpha_{f_idx} - beta_{f_idx}\")\n        expr_lines.append(\n            f\"depth_{f_idx} = alpha_{f_idx} * cam_z_{a_idx} + beta_{f_idx} * cam_z_{b_idx} + gamma_{f_idx} * cam_z_{c_idx}\"\n        )\n\n        expr_lines.append(f\"ex1_{f_idx} = cam_x_{b_idx} - cam_x_{a_idx}\")\n        expr_lines.append(f\"ey1_{f_idx} = cam_y_{b_idx} - cam_y_{a_idx}\")\n        expr_lines.append(f\"ez1_{f_idx} = cam_z_{b_idx} - cam_z_{a_idx}\")\n        expr_lines.append(f\"ex2_{f_idx} = cam_x_{c_idx} - cam_x_{a_idx}\")\n        expr_lines.append(f\"ey2_{f_idx} = cam_y_{c_idx} - cam_y_{a_idx}\")\n        expr_lines.append(f\"ez2_{f_idx} = cam_z_{c_idx} - cam_z_{a_idx}\")\n        expr_lines.append(\n            f\"nx_{f_idx} = ey1_{f_idx} * ez2_{f_idx} - ez1_{f_idx} * ey2_{f_idx}\"\n        )\n        expr_lines.append(\n            f\"ny_{f_idx} = ez1_{f_idx} * ex2_{f_idx} - ex1_{f_idx} * ez2_{f_idx}\"\n        )\n        expr_lines.append(\n            f\"nz_{f_idx} = ex1_{f_idx} * ey2_{f_idx} - ey1_{f_idx} * ex2_{f_idx}\"\n        )\n        expr_lines.append(\n            f\"norm_{f_idx} = sqrt(nx_{f_idx} ** 2 + ny_{f_idx} ** 2 + nz_{f_idx} ** 2)\"\n        )\n        expr_lines.append(f\"nx_{f_idx} = nx_{f_idx} / norm_{f_idx}\")\n        expr_lines.append(f\"ny_{f_idx} = ny_{f_idx} / norm_{f_idx}\")\n        expr_lines.append(f\"nz_{f_idx} = nz_{f_idx} / norm_{f_idx}\")\n\n        for l_idx in range(len(lights)):\n            dot_expr = f\"nx_{f_idx} * light{l_idx}_lx + ny_{f_idx} * light{l_idx}_ly + nz_{f_idx} * light{l_idx}_lz\"\n            expr_lines.append(f\"dot_{f_idx}_{l_idx} = {dot_expr}\")\n            expr_lines.append(f\"diffuse_{f_idx}_{l_idx} = max(dot_{f_idx}_{l_idx}, 0)\")\n            expr_lines.append(\n                f\"contrib_{f_idx}_{l_idx} = diffuse_{f_idx}_{l_idx} * light{l_idx}_intensity\"\n            )\n\n        expr_lines.append(f\"sum_diffuse_{f_idx} = ambient\")\n        for l_idx in range(len(lights)):\n            expr_lines.append(\n                f\"sum_diffuse_{f_idx} = sum_diffuse_{f_idx} + contrib_{f_idx}_{l_idx}\"\n            )\n\n        expr_lines.append(\n            f\"lighting_{f_idx} = sum_diffuse_{f_idx} &gt; 1 ? 1 : sum_diffuse_{f_idx}\"\n        )\n\n        expr_lines.append(f\"faceColor_{f_idx} = {face_color}\")\n        expr_lines.append(f\"shading_{f_idx} = lighting_{f_idx} * faceColor_{f_idx}\")\n\n        expr_lines.append(\n            f\"t_face_{f_idx} = inside_{f_idx} == 1 ? depth_{f_idx} : huge\"\n        )\n        expr_lines.append(\n            f\"shading_face_{f_idx} = inside_{f_idx} == 1 ? shading_{f_idx} : 0\"\n        )\n\n        face_t_names.append(f\"t_face_{f_idx}\")\n        face_shading_names.append(f\"shading_face_{f_idx}\")\n\n    if face_t_names:\n        face_t_args = \", \".join(face_t_names)\n        expr_lines.append(f\"final_t = nth_1 ({face_t_args})\")\n    else:\n        expr_lines.append(\"final_t = huge\")\n\n    select_terms = []\n    for f_idx in range(face_count):\n        expr_lines.append(\n            f\"select_{f_idx} = abs(t_face_{f_idx} - final_t) &lt; epsilon ? shading_face_{f_idx} : 0\"\n        )\n        select_terms.append(f\"select_{f_idx}\")\n    selects_sum = \" + \".join(select_terms)\n    expr_lines.append(f\"final_shading = final_t &lt; huge ? ({selects_sum}) : background\")\n    expr_lines.append(\"RESULT = final_shading\")\n\n    full_expr = \"\\n\".join(expr_lines)\n    converted_expr = infix2postfix(full_expr)\n\n    return clip.akarin.Expr(converted_expr)\n</code></pre>"},{"location":"API/vfx/draw_3d/#y5gfunc.vfx.draw_3d.load_mesh","title":"load_mesh","text":"<pre><code>load_mesh(file_path: str, default_color: str = '1', axis_transform: str = '+xz-y', rotation: tuple[float, float, float] = (0.0, 0.0, 0.0)) -&gt; tuple[list[dict], list[dict]]\n</code></pre> Source code in <code>y5gfunc/vfx/draw_3d.py</code> <pre><code>def load_mesh(\n    file_path: str,\n    default_color: str = \"1\",\n    axis_transform: str = \"+xz-y\",\n    rotation: tuple[float, float, float] = (0.0, 0.0, 0.0),\n) -&gt; tuple[list[dict], list[dict]]:\n    mesh = trimesh.load_mesh(file_path, force=\"mesh\", process=True)\n\n    if axis_transform == \"+xz-y\":\n        mesh.vertices[:, [1, 2]] = mesh.vertices[:, [2, 1]]\n        mesh.vertices[:, 2] *= -1\n    elif axis_transform == \"xyz\":\n        pass\n\n    if rotation != (0.0, 0.0, 0.0):\n        rx, ry, rz = [np.deg2rad(angle) for angle in rotation]\n        R_x = trimesh.transformations.rotation_matrix(rx, [1, 0, 0])\n        R_y = trimesh.transformations.rotation_matrix(ry, [0, 1, 0])\n        R_z = trimesh.transformations.rotation_matrix(rz, [0, 0, 1])\n        R = trimesh.transformations.concatenate_matrices(R_z, R_y, R_x)\n        mesh.apply_transform(R)\n\n    points = [\n        {\"x\": f\"{v[0]:.6f}\", \"y\": f\"{v[1]:.6f}\", \"z\": f\"{v[2]:.6f}\"}\n        for v in mesh.vertices\n    ]\n\n    faces = []\n    for face in mesh.faces:\n        faces.append(\n            {\n                \"a\": int(face[0]),\n                \"b\": int(face[1]),\n                \"c\": int(face[2]),\n                \"color\": default_color,\n            }\n        )\n\n    return points, faces\n</code></pre>"},{"location":"API/vfx/draw_3d/#y5gfunc.vfx.draw_3d.render_model_scene","title":"render_model_scene","text":"<pre><code>render_model_scene(clip: VideoNode, model_path: str, lights: list, camX: str, camY: str, camZ: str, rotationX: str, rotationY: str, focal: str, background: str = '0', **mesh_kwargs) -&gt; VideoNode\n</code></pre> Source code in <code>y5gfunc/vfx/draw_3d.py</code> <pre><code>def render_model_scene(\n    clip: vs.VideoNode,\n    model_path: str,\n    lights: list,\n    camX: str,\n    camY: str,\n    camZ: str,\n    rotationX: str,\n    rotationY: str,\n    focal: str,\n    background: str = \"0\",\n    **mesh_kwargs,\n) -&gt; vs.VideoNode:\n    points, faces = load_mesh(model_path, **mesh_kwargs)\n\n    return render_triangle_scene(\n        clip=clip,\n        points=points,\n        faces=faces,\n        lights=lights,\n        camX=camX,\n        camY=camY,\n        camZ=camZ,\n        rotationX=rotationX,\n        rotationY=rotationY,\n        focal=focal,\n        background=background,\n    )\n</code></pre>"},{"location":"API/vfx/misc/","title":"<code>y5gfunc.vfx.misc</code>","text":""},{"location":"API/vfx/misc/#y5gfunc.vfx.misc","title":"misc","text":"<p>Classes:</p> Name Description <code>ZoomMode</code> <p>Controls the zoom behavior of rotate_image function</p> <p>Functions:</p> Name Description <code>rotate_image</code> <p>Rotate a video clip</p>"},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.ZoomMode","title":"ZoomMode","text":"<p>               Bases: <code>IntEnum</code></p> <p>Controls the zoom behavior of rotate_image function</p> <p>Attributes:</p> Name Type Description <code>NO_ZOOM</code> <p>Rotate the clip without any scaling; missing border pixels will be interpolated</p> <code>ZOOM_TO_FIT</code> <p>Dynamically scale the clip to ensure the entire image fits within the frame, thus avoids additional interpolation on the borders</p> <code>CONSTANT_MAX_ZOOM</code> <p>Use a constant scaling factor based on a 45\u00b0 rotation to prevent dynamic changes during rotation</p>"},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.ZoomMode.NO_ZOOM","title":"NO_ZOOM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NO_ZOOM = 0\n</code></pre>"},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.ZoomMode.ZOOM_TO_FIT","title":"ZOOM_TO_FIT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ZOOM_TO_FIT = 1\n</code></pre>"},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.ZoomMode.CONSTANT_MAX_ZOOM","title":"CONSTANT_MAX_ZOOM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CONSTANT_MAX_ZOOM = 2\n</code></pre>"},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.rotate_image","title":"rotate_image","text":"<pre><code>rotate_image(clip: VideoNode, angle_degrees: str, zoom: ZoomMode = NO_ZOOM, bicubic_b: str = '1 / 3', bicubic_c: str = '1 / 3', center_x: str = 'width / 2', center_y: str = 'height / 2') -&gt; VideoNode\n</code></pre> <p>Rotate a video clip</p> <p>This function rotates the given video clip by an angle specified in degrees. The rotation is performed around a defined center point and uses bicubic interpolation for resampling.</p> <p>Parameters:</p> Name Type Description Default <code>VideoNode</code> <p>The source video clip to rotate.</p> required <code>str</code> <p>The rotation angle in degrees, can be an expression to evaluate in run-time.</p> required <code>ZoomMode</code> <p>The zoom mode to apply.</p> <code>NO_ZOOM</code> <code>str</code> <p>The 'b' parameter for bicubic interpolation.</p> <code>'1 / 3'</code> <code>str</code> <p>The 'c' parameter for bicubic interpolation.</p> <code>'1 / 3'</code> <code>str</code> <p>The x-coordinate of the rotation center, can be an expression to evaluate in run-time</p> <code>'width / 2'</code> <code>str</code> <p>The y-coordinate of the rotation center, can be an expression to evaluate in run-time</p> <code>'height / 2'</code> <p>Returns:</p> Type Description <code>VideoNode</code> <p>The rotated video clip.</p> Source code in <code>y5gfunc/vfx/misc.py</code> <pre><code>def rotate_image(\n    clip: vs.VideoNode,\n    angle_degrees: str,\n    zoom: ZoomMode = ZoomMode.NO_ZOOM,\n    bicubic_b: str = \"1 / 3\",\n    bicubic_c: str = \"1 / 3\",\n    center_x: str = \"width / 2\",\n    center_y: str = \"height / 2\",\n) -&gt; vs.VideoNode:\n    \"\"\"\n    Rotate a video clip\n\n    This function rotates the given video clip by an angle specified in degrees. The rotation is\n    performed around a defined center point and uses bicubic interpolation for resampling.\n\n    Args:\n        clip: The source video clip to rotate.\n        angle_degrees: The rotation angle in degrees, can be an expression to evaluate in run-time.\n        zoom: The zoom mode to apply.\n        bicubic_b: The 'b' parameter for bicubic interpolation.\n        bicubic_c: The 'c' parameter for bicubic interpolation.\n        center_x: The x-coordinate of the rotation center, can be an expression to evaluate in run-time\n        center_y: The y-coordinate of the rotation center, can be an expression to evaluate in run-time\n\n    Returns:\n        The rotated video clip.\n    \"\"\"\n    setup = f\"\"\"\n        param_b  = {bicubic_b}\n        param_c = {bicubic_c}\n        &lt;global&lt;param_b&gt;&lt;param_c&gt;&gt;\n        function bicubic_weight(in) {{\n            ax = abs(in)\n            ax2 = ax ** 2\n            ax3 = ax ** 3\n\n            term3_p1 = (12 - 9 * param_b - 6 * param_c) * ax3\n            term2_p1 = (-18 + 12 * param_b + 6 * param_c) * ax2\n            term0_p1 = (6 - 2 * param_b)\n            part1 = (term3_p1 + term2_p1 + term0_p1) / 6\n\n            term3_p2 = (-param_b - 6 * param_c) * ax3\n            term2_p2 = (6 * param_b + 30 * param_c) * ax2\n            term1_p2 = (-12 * param_b - 48 * param_c) * ax\n            term0_p2 = (8 * param_b + 24 * param_c)\n            part2 = (term3_p2 + term2_p2 + term1_p2 + term0_p2) / 6\n\n            result = (ax &lt; 1) ? part1 : (ax &lt; 2) ? part2 : 0\n\n            return result\n        }}\n\n        angle_degrees = {angle_degrees}\n        angle_rad = angle_degrees * pi / 180\n        center_x = {center_x}\n        center_y = {center_y}\n        cos_a = cos(angle_rad)\n        sin_a = sin(angle_rad)\n\n        out_rel_x = X - center_x\n        out_rel_y = Y - center_y\n    \"\"\"\n\n    if zoom == ZoomMode.CONSTANT_MAX_ZOOM:\n        source_coord_calc = \"\"\"\n            qq = 0.7071067811865476\n            w_bound_const = width * qq + height * qq\n            h_bound_const = width * qq + height * qq\n            shrink_scale = min(width / max(w_bound_const, 1e-9), height / max(h_bound_const, 1e-9))\n\n            src_rel_x_unscaled = out_rel_x * cos_a + out_rel_y * sin_a\n            src_rel_y_unscaled = -out_rel_x * sin_a + out_rel_y * cos_a\n\n            final_src_rel_x = src_rel_x_unscaled * shrink_scale\n            final_src_rel_y = src_rel_y_unscaled * shrink_scale\n\n            source_x = final_src_rel_x + center_x\n            source_y = final_src_rel_y + center_y\n        \"\"\"\n    elif zoom == ZoomMode.ZOOM_TO_FIT:\n        source_coord_calc = \"\"\"\n            ca = abs(cos_a)\n            sa = abs(sin_a)\n            w_bound = width * ca + height * sa\n            h_bound = width * sa + height * ca\n            shrink_scale_x = width / max(w_bound, 1e-9)\n            shrink_scale_y = height / max(h_bound, 1e-9)\n            shrink_scale = min(shrink_scale_x, shrink_scale_y)\n\n            src_rel_x_unscaled = out_rel_x * cos_a + out_rel_y * sin_a\n            src_rel_y_unscaled = -out_rel_x * sin_a + out_rel_y * cos_a\n\n            final_src_rel_x = src_rel_x_unscaled * shrink_scale\n            final_src_rel_y = src_rel_y_unscaled * shrink_scale\n\n            source_x = final_src_rel_x + center_x\n            source_y = final_src_rel_y + center_y\n        \"\"\"\n    else:\n        source_coord_calc = \"\"\"\n            final_src_rel_x = out_rel_x * cos_a + out_rel_y * sin_a\n            final_src_rel_y = -out_rel_x * sin_a + out_rel_y * cos_a\n\n            source_x = final_src_rel_x + center_x\n            source_y = final_src_rel_y + center_y\n        \"\"\"\n\n    interpolate = \"\"\"\n        ix = floor(source_x)\n        iy = floor(source_y)\n        fx = source_x - ix\n        fy = source_y - iy\n\n        x_m1 = ix - 1\n        x0 = ix \n        x1 = ix + 1 \n        x2 = ix + 2\n        y_m1 = iy - 1 \n        y0 = iy \n        y1 = iy + 1 \n        y2 = iy + 2\n\n        wx_m1 = bicubic_weight(fx + 1) \n        wx0 = bicubic_weight(fx)\n        wx1 = bicubic_weight(fx - 1) \n        wx2 = bicubic_weight(fx - 2)\n\n        wy_m1 = bicubic_weight(fy + 1) \n        wy0 = bicubic_weight(fy)\n        wy1 = bicubic_weight(fy - 1) \n        wy2 = bicubic_weight(fy - 2)\n\n        p_m1_m1 = dyn(src0, x_m1, y_m1) \n        p0_m1 = dyn(src0, x0, y_m1)\n        p1_m1 = dyn(src0, x1, y_m1)   \n        p2_m1 = dyn(src0, x2, y_m1)\n        p_m1_0 = dyn(src0, x_m1, y0)  \n        p0_0 = dyn(src0, x0, y0)\n        p1_0 = dyn(src0, x1, y0)    \n        p2_0 = dyn(src0, x2, y0)\n        p_m1_1 = dyn(src0, x_m1, y1)  \n        p0_1 = dyn(src0, x0, y1)\n        p1_1 = dyn(src0, x1, y1)    \n        p2_1 = dyn(src0, x2, y1)\n        p_m1_2 = dyn(src0, x_m1, y2)  \n        p0_2 = dyn(src0, x0, y2)\n        p1_2 = dyn(src0, x1, y2)    \n        p2_2 = dyn(src0, x2, y2)\n\n        row_m1 = p_m1_m1 * wx_m1 + p0_m1 * wx0 + p1_m1 * wx1 + p2_m1 * wx2\n        row_0  = p_m1_0 * wx_m1 + p0_0 * wx0 + p1_0 * wx1 + p2_0 * wx2\n        row_1  = p_m1_1 * wx_m1 + p0_1 * wx0 + p1_1 * wx1 + p2_1 * wx2\n        row_2  = p_m1_2 * wx_m1 + p0_2 * wx0 + p1_2 * wx1 + p2_2 * wx2\n\n        RESULT = row_m1 * wy_m1 + row_0 * wy0 + row_1 * wy1 + row_2 * wy2\n    \"\"\"\n\n    full_expr_str = setup + source_coord_calc + interpolate\n\n    expr_postfix = infix2postfix(full_expr_str)\n    return clip.akarin.Expr(expr_postfix)\n</code></pre>"},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.rotate_image(clip)","title":"<code>clip</code>","text":""},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.rotate_image(angle_degrees)","title":"<code>angle_degrees</code>","text":""},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.rotate_image(zoom)","title":"<code>zoom</code>","text":""},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.rotate_image(bicubic_b)","title":"<code>bicubic_b</code>","text":""},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.rotate_image(bicubic_c)","title":"<code>bicubic_c</code>","text":""},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.rotate_image(center_x)","title":"<code>center_x</code>","text":""},{"location":"API/vfx/misc/#y5gfunc.vfx.misc.rotate_image(center_y)","title":"<code>center_y</code>","text":""}]}